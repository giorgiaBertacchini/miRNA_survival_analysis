{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8ddf05",
   "metadata": {},
   "source": [
    "# Cox regression and hazard ratio model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5e590",
   "metadata": {},
   "source": [
    "Cox fa analisi di ogni variabile data e predice per ognuna l'hazard ratio, ovvero una probabilità, che se >1 indica che il rischio dell'accadere dell'evento aumenta all'aumentare del valore di quella variabile (o presenza di quella variabile in caso di booleane), mentre diminuisce se l'hazard ratio è <1. \n",
    "\n",
    "\n",
    "Input : feature vectors con età del paziente alla diagnosi, last days to follow-up, evento morte booleano, miRNA-seq vector con valori normalizzati con log e quantile.\n",
    "\n",
    "Pipeline:\n",
    "   - Scaling con **Z-scaler** su campi di età e miRNA-seq\n",
    "   - Applicazione di elsatic net tramite ```scikit-survival.CoxnetSurvivalAnalysis``` da addestrare (scikit-survival at: https://scikit-survival.readthedocs.io/en/stable/user_guide/coxnet.html)\n",
    "      - Applicare grid search e K-fold cross validation per capire set di parametri migliori\n",
    "   - Calcolo di risk score con funzione di predict\n",
    "        - possibile prevedere survival function o cumulative hazard function anche, ma necessario fare fine tuning con parametro ```fit_baselin_model=True```\n",
    "\n",
    "Motivazioni:\n",
    "   - Z-scaler per portare valori predittivi su stessa scala con varianza 1 e media 0\n",
    "   - Utilizzo di Cox con penalizzazione per fare feature selection e selezionare solo miRNA con maggiore rilevanza\n",
    "   - Utilizzo Elastic Net poichè Lasso-Cox normale non ottimale per due motivi: non può selezionare più features di quanti sample ci sono e in gruppo di features con alta correlazione tra loro ne sceglie a caso solo una tra queste. Elastic net risolve questi usando combinazione di l1 e l2 e rendendo più robusto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe80a9",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ff9c7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:00.805355Z",
     "start_time": "2025-10-28T11:25:59.087457Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5054239e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:02.480314Z",
     "start_time": "2025-10-28T11:26:00.810410Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1396728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:02.510084Z",
     "start_time": "2025-10-28T11:26:02.488905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Universita\\2 anno magistrale\\Progetto BioInf\\miRNA_to_age\n"
     ]
    }
   ],
   "source": [
    "base = os.path.basename(os.getcwd())\n",
    "list = os.getcwd().split(os.sep) \n",
    "list.pop(list.index(base))\n",
    "ROOT = '\\\\'.join(list)\n",
    "print(ROOT)\n",
    "DATA_PATH = os.path.join(ROOT, 'datasets\\\\preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf89f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:03.315574Z",
     "start_time": "2025-10-28T11:26:02.516185Z"
    }
   },
   "outputs": [],
   "source": [
    "# available datasets:\n",
    "#   clinical_miRNA_normalized_log.csv\n",
    "#   clinical_miRNA_normalized_quant.csv\n",
    "#   mRNA\\\\clinical_mRNA_normalized_log.csv\n",
    "#   mRNA\\\\clinical_mRNA_normalized_tpm_log.csv\n",
    "dataset = pd.read_csv(os.path.join(DATA_PATH, 'clinical_miRNA_normalized_log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac580140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:03.335029Z",
     "start_time": "2025-10-28T11:26:03.319427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(746, 951)\n",
      "Index(['days_to_death', 'age_at_initial_pathologic_diagnosis',\n",
      "       'days_to_last_followup', 'Death', 'pathologic_stage_Stage I',\n",
      "       'pathologic_stage_Stage IA', 'pathologic_stage_Stage IIA',\n",
      "       'pathologic_stage_Stage IIB', 'pathologic_stage_Stage IIIA',\n",
      "       'pathologic_stage_Stage IIIC',\n",
      "       ...\n",
      "       'hsa-mir-934', 'hsa-mir-935', 'hsa-mir-937', 'hsa-mir-938',\n",
      "       'hsa-mir-939', 'hsa-mir-940', 'hsa-mir-942', 'hsa-mir-943',\n",
      "       'hsa-mir-944', 'hsa-mir-95'],\n",
      "      dtype='object', length=951)\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset.columns)\n",
    "# print(dataset.head())\n",
    "print(type(dataset.iloc[0]['days_to_death']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101662c",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "972c2c89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:03.346947Z",
     "start_time": "2025-10-28T11:26:03.338780Z"
    }
   },
   "outputs": [],
   "source": [
    "num_folds = 20\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588714a",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25831df3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:07.916913Z",
     "start_time": "2025-10-28T11:26:07.776175Z"
    }
   },
   "outputs": [],
   "source": [
    "y_cols = ['Death', 'days_to_death', 'days_to_last_followup']\n",
    "X_cols = [col for col in dataset.columns if col not in y_cols]\n",
    "\n",
    "custom_dtype = np.dtype([\n",
    "    ('event', np.bool_),         # O 'bool'\n",
    "    ('time', np.float64)      # O 'float'\n",
    "])\n",
    "\n",
    "y = []\n",
    "for index,row in dataset[y_cols].iterrows():\n",
    "    if row['Death'] == 1:\n",
    "        y.append(np.array((True, row['days_to_death'].item()), dtype=custom_dtype))\n",
    "    elif row['Death'] == 0:\n",
    "        tuple = (False, row['days_to_last_followup'].item())\n",
    "        y.append(np.array(tuple, dtype=custom_dtype)) \n",
    "y = np.array(y)\n",
    "\n",
    "X = dataset[X_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b445a",
   "metadata": {},
   "source": [
    "## Z-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26cab91c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:08.050709Z",
     "start_time": "2025-10-28T11:26:07.922914Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# minmax = MinMaxScaler(feature_range=(0,15))\n",
    "\n",
    "scaled_X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "# minmaxed_X = pd.DataFrame(minmax.fit_transform(scaled_X), columns = scaled_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948ea1d",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8c15736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673cc51",
   "metadata": {},
   "source": [
    "## K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9da24d3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:08.623888Z",
     "start_time": "2025-10-28T11:26:08.617234Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=SEED)\n",
    "# kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbfc3aa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Elastic net (Lasso-Cox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "660229ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(coefs):\n",
    "    _, ax = plt.subplots(figsize=(9, 6))\n",
    "    alphas = coefs.columns\n",
    "    for row in coefs.itertuples():\n",
    "        ax.semilogx(alphas, row[1:], \".-\", label=row.Index)\n",
    "\n",
    "    ax.yaxis.set_label_position(\"left\")\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel(\"alpha\")\n",
    "    ax.set_ylabel(\"coefficient\")\n",
    "    ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4bddc",
   "metadata": {},
   "source": [
    "### Gridsearch for best paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c1622c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c6b6a3",
   "metadata": {},
   "source": [
    "first random search for l1_ratio and alpha_min_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91253c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha_min_ratio': 0.05, 'l1_ratio': 0.3}\n"
     ]
    }
   ],
   "source": [
    "cen = CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.05)\n",
    "\n",
    "rcv = GridSearchCV(\n",
    "    cen,\n",
    "    param_grid={\n",
    "        \"l1_ratio\": [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        \"alpha_min_ratio\":[0.01, 0.05, 0.1]\n",
    "    },\n",
    "    cv=kfold,\n",
    "    error_score=0.5,\n",
    "    n_jobs=8,\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(rcv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9cfefa",
   "metadata": {},
   "source": [
    "then extract estimated alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "618fba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cen = make_pipeline(CoxnetSurvivalAnalysis(**rcv.best_params_))\n",
    "\n",
    "# warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FitFailedWarning)\n",
    "\n",
    "cen.fit(X_train, y_train)\n",
    "estimated_alphas = cen.named_steps[\"coxnetsurvivalanalysis\"].alphas_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd159f",
   "metadata": {},
   "source": [
    "and perform another random search for alphas values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45382981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_index_scorer(estimator, X, y):\n",
    "    # Estrai i campi 'death' e 'days' da y\n",
    "    event_indicator = y['event']\n",
    "    event_time = y['time']\n",
    "    # Predici i punteggi di rischio\n",
    "    risk_scores = estimator.predict(X)\n",
    "    # Calcola il concordance index\n",
    "    c_index = concordance_index_censored(event_indicator, event_time, risk_scores)[0]\n",
    "    return c_index\n",
    "\n",
    "cen = CoxnetSurvivalAnalysis(**rcv.best_params_)\n",
    "\n",
    "gcv = RandomizedSearchCV(\n",
    "    cen,\n",
    "    param_distributions={\n",
    "        \"alphas\":[[v] for v in map(float, estimated_alphas)]\n",
    "    },\n",
    "    cv=kfold,\n",
    "    scoring=c_index_scorer,\n",
    "    error_score=0.5,\n",
    "    n_iter=30,\n",
    "    n_jobs=8,\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "res = pd.DataFrame(gcv.cv_results_)\n",
    "print(gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d336789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alphas</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>split15_test_score</th>\n",
       "      <th>split16_test_score</th>\n",
       "      <th>split17_test_score</th>\n",
       "      <th>split18_test_score</th>\n",
       "      <th>split19_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.486383</td>\n",
       "      <td>0.034015</td>\n",
       "      <td>0.065805</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>[0.33879079031068987]</td>\n",
       "      <td>{'alphas': [0.33879079031068987]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.477849</td>\n",
       "      <td>0.035049</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>[0.30159667234442283]</td>\n",
       "      <td>{'alphas': [0.30159667234442283]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.452390</td>\n",
       "      <td>0.021966</td>\n",
       "      <td>0.071318</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>[0.7470779861101506]</td>\n",
       "      <td>{'alphas': [0.7470779861101506]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.460110</td>\n",
       "      <td>0.022397</td>\n",
       "      <td>0.069661</td>\n",
       "      <td>0.013325</td>\n",
       "      <td>[0.8791703034554935]</td>\n",
       "      <td>{'alphas': [0.8791703034554935]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.436263</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.069207</td>\n",
       "      <td>0.017275</td>\n",
       "      <td>[0.28788863812071364]</td>\n",
       "      <td>{'alphas': [0.28788863812071364]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.490521</td>\n",
       "      <td>0.043362</td>\n",
       "      <td>0.072176</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>[0.4802271919029562]</td>\n",
       "      <td>{'alphas': [0.4802271919029562]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.449189</td>\n",
       "      <td>0.034384</td>\n",
       "      <td>0.063994</td>\n",
       "      <td>0.020474</td>\n",
       "      <td>[0.4080747063362968]</td>\n",
       "      <td>{'alphas': [0.4080747063362968]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.445773</td>\n",
       "      <td>0.021571</td>\n",
       "      <td>0.062980</td>\n",
       "      <td>0.015169</td>\n",
       "      <td>[0.2335153502137659]</td>\n",
       "      <td>{'alphas': [0.2335153502137659]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.431117</td>\n",
       "      <td>0.013871</td>\n",
       "      <td>0.063491</td>\n",
       "      <td>0.012257</td>\n",
       "      <td>[0.2812700660372505]</td>\n",
       "      <td>{'alphas': [0.2812700660372505]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.439511</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.057502</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>[1.1622114006471833]</td>\n",
       "      <td>{'alphas': [1.1622114006471833]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.447903</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.060718</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>[0.427505490672921]</td>\n",
       "      <td>{'alphas': [0.427505490672921]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.441138</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.058216</td>\n",
       "      <td>0.011297</td>\n",
       "      <td>[0.371822474126399]</td>\n",
       "      <td>{'alphas': [0.371822474126399]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.428097</td>\n",
       "      <td>0.019403</td>\n",
       "      <td>0.061198</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>[0.8199171674829291]</td>\n",
       "      <td>{'alphas': [0.8199171674829291]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.429521</td>\n",
       "      <td>0.017875</td>\n",
       "      <td>0.057460</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>[0.696727430229102]</td>\n",
       "      <td>{'alphas': [0.696727430229102]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.432086</td>\n",
       "      <td>0.026081</td>\n",
       "      <td>0.066486</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>[1.3055399977480364]</td>\n",
       "      <td>{'alphas': [1.3055399977480364]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.428874</td>\n",
       "      <td>0.026313</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.014679</td>\n",
       "      <td>[0.6650600932391549]</td>\n",
       "      <td>{'alphas': [0.6650600932391549]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.432037</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>0.061772</td>\n",
       "      <td>0.013027</td>\n",
       "      <td>[0.552144573270635]</td>\n",
       "      <td>{'alphas': [0.552144573270635]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.412357</td>\n",
       "      <td>0.029108</td>\n",
       "      <td>0.060717</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>[0.7826506668113723]</td>\n",
       "      <td>{'alphas': [0.7826506668113723]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.392980</td>\n",
       "      <td>0.018060</td>\n",
       "      <td>0.062052</td>\n",
       "      <td>0.010718</td>\n",
       "      <td>[0.21777719715796526]</td>\n",
       "      <td>{'alphas': [0.21777719715796526]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.406574</td>\n",
       "      <td>0.023402</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.014302</td>\n",
       "      <td>[0.193868546175959]</td>\n",
       "      <td>{'alphas': [0.193868546175959]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.384944</td>\n",
       "      <td>0.032056</td>\n",
       "      <td>0.062964</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>[0.2030997429443652]</td>\n",
       "      <td>{'alphas': [0.2030997429443652]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.405361</td>\n",
       "      <td>0.030357</td>\n",
       "      <td>0.065925</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>[0.2390102050334048]</td>\n",
       "      <td>{'alphas': [0.2390102050334048]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.406485</td>\n",
       "      <td>0.020173</td>\n",
       "      <td>0.072422</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>[0.43756513173589945]</td>\n",
       "      <td>{'alphas': [0.43756513173589945]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.421791</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.070648</td>\n",
       "      <td>0.012669</td>\n",
       "      <td>[1.1895594225671102]</td>\n",
       "      <td>{'alphas': [1.1895594225671102]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.394426</td>\n",
       "      <td>0.015064</td>\n",
       "      <td>0.070350</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>[1.1093870988025571]</td>\n",
       "      <td>{'alphas': [1.1093870988025571]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.423034</td>\n",
       "      <td>0.021677</td>\n",
       "      <td>0.066995</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>[0.16095307294348604]</td>\n",
       "      <td>{'alphas': [0.16095307294348604]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.408407</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.071205</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>[0.2127704900960486]</td>\n",
       "      <td>{'alphas': [0.2127704900960486]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.436629</td>\n",
       "      <td>0.019579</td>\n",
       "      <td>0.056646</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>[0.5651370993156949]</td>\n",
       "      <td>{'alphas': [0.5651370993156949]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.453862</td>\n",
       "      <td>0.019328</td>\n",
       "      <td>0.067214</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>[1.3362606880251002]</td>\n",
       "      <td>{'alphas': [1.3362606880251002]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.440568</td>\n",
       "      <td>0.032229</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>[0.9648883227005598]</td>\n",
       "      <td>{'alphas': [0.9648883227005598]}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.486383      0.034015         0.065805        0.004717   \n",
       "1        0.477849      0.035049         0.065444        0.011786   \n",
       "2        0.452390      0.021966         0.071318        0.013441   \n",
       "3        0.460110      0.022397         0.069661        0.013325   \n",
       "4        0.436263      0.011682         0.069207        0.017275   \n",
       "5        0.490521      0.043362         0.072176        0.014300   \n",
       "6        0.449189      0.034384         0.063994        0.020474   \n",
       "7        0.445773      0.021571         0.062980        0.015169   \n",
       "8        0.431117      0.013871         0.063491        0.012257   \n",
       "9        0.439511      0.007694         0.057502        0.006479   \n",
       "10       0.447903      0.017544         0.060718        0.011096   \n",
       "11       0.441138      0.022540         0.058216        0.011297   \n",
       "12       0.428097      0.019403         0.061198        0.014453   \n",
       "13       0.429521      0.017875         0.057460        0.010998   \n",
       "14       0.432086      0.026081         0.066486        0.016137   \n",
       "15       0.428874      0.026313         0.062171        0.014679   \n",
       "16       0.432037      0.037245         0.061772        0.013027   \n",
       "17       0.412357      0.029108         0.060717        0.012963   \n",
       "18       0.392980      0.018060         0.062052        0.010718   \n",
       "19       0.406574      0.023402         0.060625        0.014302   \n",
       "20       0.384944      0.032056         0.062964        0.010809   \n",
       "21       0.405361      0.030357         0.065925        0.016952   \n",
       "22       0.406485      0.020173         0.072422        0.008241   \n",
       "23       0.421791      0.020837         0.070648        0.012669   \n",
       "24       0.394426      0.015064         0.070350        0.011619   \n",
       "25       0.423034      0.021677         0.066995        0.016851   \n",
       "26       0.408407      0.021173         0.071205        0.012749   \n",
       "27       0.436629      0.019579         0.056646        0.005063   \n",
       "28       0.453862      0.019328         0.067214        0.009205   \n",
       "29       0.440568      0.032229         0.060627        0.011090   \n",
       "\n",
       "             param_alphas                             params  \\\n",
       "0   [0.33879079031068987]  {'alphas': [0.33879079031068987]}   \n",
       "1   [0.30159667234442283]  {'alphas': [0.30159667234442283]}   \n",
       "2    [0.7470779861101506]   {'alphas': [0.7470779861101506]}   \n",
       "3    [0.8791703034554935]   {'alphas': [0.8791703034554935]}   \n",
       "4   [0.28788863812071364]  {'alphas': [0.28788863812071364]}   \n",
       "5    [0.4802271919029562]   {'alphas': [0.4802271919029562]}   \n",
       "6    [0.4080747063362968]   {'alphas': [0.4080747063362968]}   \n",
       "7    [0.2335153502137659]   {'alphas': [0.2335153502137659]}   \n",
       "8    [0.2812700660372505]   {'alphas': [0.2812700660372505]}   \n",
       "9    [1.1622114006471833]   {'alphas': [1.1622114006471833]}   \n",
       "10    [0.427505490672921]    {'alphas': [0.427505490672921]}   \n",
       "11    [0.371822474126399]    {'alphas': [0.371822474126399]}   \n",
       "12   [0.8199171674829291]   {'alphas': [0.8199171674829291]}   \n",
       "13    [0.696727430229102]    {'alphas': [0.696727430229102]}   \n",
       "14   [1.3055399977480364]   {'alphas': [1.3055399977480364]}   \n",
       "15   [0.6650600932391549]   {'alphas': [0.6650600932391549]}   \n",
       "16    [0.552144573270635]    {'alphas': [0.552144573270635]}   \n",
       "17   [0.7826506668113723]   {'alphas': [0.7826506668113723]}   \n",
       "18  [0.21777719715796526]  {'alphas': [0.21777719715796526]}   \n",
       "19    [0.193868546175959]    {'alphas': [0.193868546175959]}   \n",
       "20   [0.2030997429443652]   {'alphas': [0.2030997429443652]}   \n",
       "21   [0.2390102050334048]   {'alphas': [0.2390102050334048]}   \n",
       "22  [0.43756513173589945]  {'alphas': [0.43756513173589945]}   \n",
       "23   [1.1895594225671102]   {'alphas': [1.1895594225671102]}   \n",
       "24   [1.1093870988025571]   {'alphas': [1.1093870988025571]}   \n",
       "25  [0.16095307294348604]  {'alphas': [0.16095307294348604]}   \n",
       "26   [0.2127704900960486]   {'alphas': [0.2127704900960486]}   \n",
       "27   [0.5651370993156949]   {'alphas': [0.5651370993156949]}   \n",
       "28   [1.3362606880251002]   {'alphas': [1.3362606880251002]}   \n",
       "29   [0.9648883227005598]   {'alphas': [0.9648883227005598]}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                 0.5                0.5                0.5   \n",
       "1                 0.5                0.5                0.5   \n",
       "2                 0.5                0.5                0.5   \n",
       "3                 0.5                0.5                0.5   \n",
       "4                 0.5                0.5                0.5   \n",
       "5                 0.5                0.5                0.5   \n",
       "6                 0.5                0.5                0.5   \n",
       "7                 0.5                0.5                0.5   \n",
       "8                 0.5                0.5                0.5   \n",
       "9                 0.5                0.5                0.5   \n",
       "10                0.5                0.5                0.5   \n",
       "11                0.5                0.5                0.5   \n",
       "12                0.5                0.5                0.5   \n",
       "13                0.5                0.5                0.5   \n",
       "14                0.5                0.5                0.5   \n",
       "15                0.5                0.5                0.5   \n",
       "16                0.5                0.5                0.5   \n",
       "17                0.5                0.5                0.5   \n",
       "18                0.5                0.5                0.5   \n",
       "19                0.5                0.5                0.5   \n",
       "20                0.5                0.5                0.5   \n",
       "21                0.5                0.5                0.5   \n",
       "22                0.5                0.5                0.5   \n",
       "23                0.5                0.5                0.5   \n",
       "24                0.5                0.5                0.5   \n",
       "25                0.5                0.5                0.5   \n",
       "26                0.5                0.5                0.5   \n",
       "27                0.5                0.5                0.5   \n",
       "28                0.5                0.5                0.5   \n",
       "29                0.5                0.5                0.5   \n",
       "\n",
       "    split3_test_score  ...  split13_test_score  split14_test_score  \\\n",
       "0                 0.5  ...                 0.5                 0.5   \n",
       "1                 0.5  ...                 0.5                 0.5   \n",
       "2                 0.5  ...                 0.5                 0.5   \n",
       "3                 0.5  ...                 0.5                 0.5   \n",
       "4                 0.5  ...                 0.5                 0.5   \n",
       "5                 0.5  ...                 0.5                 0.5   \n",
       "6                 0.5  ...                 0.5                 0.5   \n",
       "7                 0.5  ...                 0.5                 0.5   \n",
       "8                 0.5  ...                 0.5                 0.5   \n",
       "9                 0.5  ...                 0.5                 0.5   \n",
       "10                0.5  ...                 0.5                 0.5   \n",
       "11                0.5  ...                 0.5                 0.5   \n",
       "12                0.5  ...                 0.5                 0.5   \n",
       "13                0.5  ...                 0.5                 0.5   \n",
       "14                0.5  ...                 0.5                 0.5   \n",
       "15                0.5  ...                 0.5                 0.5   \n",
       "16                0.5  ...                 0.5                 0.5   \n",
       "17                0.5  ...                 0.5                 0.5   \n",
       "18                0.5  ...                 0.5                 0.5   \n",
       "19                0.5  ...                 0.5                 0.5   \n",
       "20                0.5  ...                 0.5                 0.5   \n",
       "21                0.5  ...                 0.5                 0.5   \n",
       "22                0.5  ...                 0.5                 0.5   \n",
       "23                0.5  ...                 0.5                 0.5   \n",
       "24                0.5  ...                 0.5                 0.5   \n",
       "25                0.5  ...                 0.5                 0.5   \n",
       "26                0.5  ...                 0.5                 0.5   \n",
       "27                0.5  ...                 0.5                 0.5   \n",
       "28                0.5  ...                 0.5                 0.5   \n",
       "29                0.5  ...                 0.5                 0.5   \n",
       "\n",
       "    split15_test_score  split16_test_score  split17_test_score  \\\n",
       "0                  0.5                 0.5                 0.5   \n",
       "1                  0.5                 0.5                 0.5   \n",
       "2                  0.5                 0.5                 0.5   \n",
       "3                  0.5                 0.5                 0.5   \n",
       "4                  0.5                 0.5                 0.5   \n",
       "5                  0.5                 0.5                 0.5   \n",
       "6                  0.5                 0.5                 0.5   \n",
       "7                  0.5                 0.5                 0.5   \n",
       "8                  0.5                 0.5                 0.5   \n",
       "9                  0.5                 0.5                 0.5   \n",
       "10                 0.5                 0.5                 0.5   \n",
       "11                 0.5                 0.5                 0.5   \n",
       "12                 0.5                 0.5                 0.5   \n",
       "13                 0.5                 0.5                 0.5   \n",
       "14                 0.5                 0.5                 0.5   \n",
       "15                 0.5                 0.5                 0.5   \n",
       "16                 0.5                 0.5                 0.5   \n",
       "17                 0.5                 0.5                 0.5   \n",
       "18                 0.5                 0.5                 0.5   \n",
       "19                 0.5                 0.5                 0.5   \n",
       "20                 0.5                 0.5                 0.5   \n",
       "21                 0.5                 0.5                 0.5   \n",
       "22                 0.5                 0.5                 0.5   \n",
       "23                 0.5                 0.5                 0.5   \n",
       "24                 0.5                 0.5                 0.5   \n",
       "25                 0.5                 0.5                 0.5   \n",
       "26                 0.5                 0.5                 0.5   \n",
       "27                 0.5                 0.5                 0.5   \n",
       "28                 0.5                 0.5                 0.5   \n",
       "29                 0.5                 0.5                 0.5   \n",
       "\n",
       "    split18_test_score  split19_test_score  mean_test_score  std_test_score  \\\n",
       "0                  0.5                 0.5              0.5             0.0   \n",
       "1                  0.5                 0.5              0.5             0.0   \n",
       "2                  0.5                 0.5              0.5             0.0   \n",
       "3                  0.5                 0.5              0.5             0.0   \n",
       "4                  0.5                 0.5              0.5             0.0   \n",
       "5                  0.5                 0.5              0.5             0.0   \n",
       "6                  0.5                 0.5              0.5             0.0   \n",
       "7                  0.5                 0.5              0.5             0.0   \n",
       "8                  0.5                 0.5              0.5             0.0   \n",
       "9                  0.5                 0.5              0.5             0.0   \n",
       "10                 0.5                 0.5              0.5             0.0   \n",
       "11                 0.5                 0.5              0.5             0.0   \n",
       "12                 0.5                 0.5              0.5             0.0   \n",
       "13                 0.5                 0.5              0.5             0.0   \n",
       "14                 0.5                 0.5              0.5             0.0   \n",
       "15                 0.5                 0.5              0.5             0.0   \n",
       "16                 0.5                 0.5              0.5             0.0   \n",
       "17                 0.5                 0.5              0.5             0.0   \n",
       "18                 0.5                 0.5              0.5             0.0   \n",
       "19                 0.5                 0.5              0.5             0.0   \n",
       "20                 0.5                 0.5              0.5             0.0   \n",
       "21                 0.5                 0.5              0.5             0.0   \n",
       "22                 0.5                 0.5              0.5             0.0   \n",
       "23                 0.5                 0.5              0.5             0.0   \n",
       "24                 0.5                 0.5              0.5             0.0   \n",
       "25                 0.5                 0.5              0.5             0.0   \n",
       "26                 0.5                 0.5              0.5             0.0   \n",
       "27                 0.5                 0.5              0.5             0.0   \n",
       "28                 0.5                 0.5              0.5             0.0   \n",
       "29                 0.5                 0.5              0.5             0.0   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "5                 1  \n",
       "6                 1  \n",
       "7                 1  \n",
       "8                 1  \n",
       "9                 1  \n",
       "10                1  \n",
       "11                1  \n",
       "12                1  \n",
       "13                1  \n",
       "14                1  \n",
       "15                1  \n",
       "16                1  \n",
       "17                1  \n",
       "18                1  \n",
       "19                1  \n",
       "20                1  \n",
       "21                1  \n",
       "22                1  \n",
       "23                1  \n",
       "24                1  \n",
       "25                1  \n",
       "26                1  \n",
       "27                1  \n",
       "28                1  \n",
       "29                1  \n",
       "\n",
       "[30 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d597ed59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res.mean_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "355184dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = res['param_alphas'].map(lambda x: x[0]).sort_values()\n",
    "mean = res.mean_test_score\n",
    "std = res.std_test_score\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.plot(alphas, mean)\n",
    "ax.fill_between(alphas, mean - std, mean + std, alpha=0.15)\n",
    "# ax.set_xscale(\"log\")\n",
    "ax.set_ylabel(\"concordance index\")\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.axvline(gcv.best_params_[\"alphas\"][0], c=\"C1\")\n",
    "ax.axhline(0.5, color=\"grey\", linestyle=\"--\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fef44df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matteo Bulgarelli\\AppData\\Local\\Temp\\ipykernel_11672\\2700938266.py:2: UserWarning: all coefficients are zero, consider decreasing alpha.\n",
      "  cen_best.fit(scaled_X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished training cen_best\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Kept 0 variables for infer: Index([], dtype='object')\n",
      "\n",
      "Beginning cross validation on test\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKept \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(best_vars)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m variables for infer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBeginning cross validation on test\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m cv = \u001b[43mcross_val_score\u001b[49m(cen_best, scaled_X, y, cv=kfold, scoring=c_index_scorer)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCross validation scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCross validation average: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv.mean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "cen_best = CoxnetSurvivalAnalysis(**rcv.best_params_, alphas=gcv.best_params_['alphas'], max_iter=100000) # for predicting just the risk score\n",
    "cen_best.fit(scaled_X, y)\n",
    "print(\"\\nFinished training cen_best\\n\")\n",
    "\n",
    "pred_res = cen_best.predict(scaled_X)\n",
    "print(pred_res[:10])\n",
    "\n",
    "best_vars = X_train.columns[np.where(cen_best.coef_ != 0)[0]]\n",
    "print(f\"Kept {len(best_vars)} variables for infer: {best_vars}\\n\")\n",
    "\n",
    "print(\"Beginning cross validation on test\")\n",
    "cv = cross_val_score(cen_best, scaled_X, y, cv=kfold, scoring=c_index_scorer)\n",
    "print(f\"Cross validation scores: {cv}\")\n",
    "print(f\"Cross validation average: {cv.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed5130e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64285714, 0.8       , 0.33333333, 0.62962963, 0.89473684,\n",
       "       0.6       , 0.3125    , 0.625     , 0.53488372, 0.55737705,\n",
       "       0.43055556, 0.        , 0.36363636, 0.58333333, 0.43181818,\n",
       "       0.48888889, 0.16666667, 0.66666667, 0.43478261, 0.63636364])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "104d95f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pathologic_stage_Stage IV', 'pathologic_stage_Stage X', 'hsa-mir-1229',\n",
       "       'hsa-mir-1244-4', 'hsa-mir-129-1', 'hsa-mir-148b', 'hsa-mir-198',\n",
       "       'hsa-mir-302c', 'hsa-mir-3163', 'hsa-mir-3180-5', 'hsa-mir-325',\n",
       "       'hsa-mir-340', 'hsa-mir-3672', 'hsa-mir-4263', 'hsa-mir-4653',\n",
       "       'hsa-mir-4719', 'hsa-mir-4798', 'hsa-mir-488', 'hsa-mir-514a-3',\n",
       "       'hsa-mir-5195', 'hsa-mir-548a-1', 'hsa-mir-583', 'hsa-mir-586',\n",
       "       'hsa-mir-605', 'hsa-mir-623', 'hsa-mir-640', 'hsa-mir-6830',\n",
       "       'hsa-mir-7155', 'hsa-mir-7705', 'hsa-mir-7977', 'hsa-mir-8069-1',\n",
       "       'hsa-mir-8085'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[np.where(cen_best.named_steps[\"coxnetsurvivalanalysis\"].coef_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e777ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training cen_best_for_func\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sklearn\\pipeline.py:662: ConvergenceWarning: Optimization terminated early, you might want to increase the number of iterations (max_iter=100000).\n",
      "  self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:86: RuntimeWarning: invalid value encountered in divide\n",
      "  y = np.cumsum(n_events / divisor)\n"
     ]
    }
   ],
   "source": [
    "cen_best_for_func = make_pipeline(CoxnetSurvivalAnalysis(l1_ratio=0.9, alphas=[0.0337], fit_baseline_model=True, max_iter=100000)) # to predict the hazard function\n",
    "cen_best_for_func.fit(X_train, y_train)\n",
    "print(\"Finished training cen_best_for_func\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33b6b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished predicting\n"
     ]
    }
   ],
   "source": [
    "risk_score = cen_best.predict(X_test)\n",
    "surv_funcs = cen_best_for_func.predict_survival_function(X_test)\n",
    "print(\"Finished predicting\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tirocinio-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
