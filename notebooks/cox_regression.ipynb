{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8ddf05",
   "metadata": {},
   "source": [
    "# Cox regression and hazard ratio model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5e590",
   "metadata": {},
   "source": [
    "Cox fa analisi di ogni variabile data e predice per ognuna l'hazard ratio, ovvero una probabilità, che se >1 indica che il rischio dell'accadere dell'evento aumenta all'aumentare del valore di quella variabile (o presenza di quella variabile in caso di booleane), mentre diminuisce se l'hazard ratio è <1. \n",
    "\n",
    "\n",
    "Input : feature vectors con età del paziente alla diagnosi, last days to follow-up, evento morte booleano, miRNA-seq vector con valori normalizzati con log e quantile.\n",
    "\n",
    "Pipeline:\n",
    "   - Scaling con **Z-scaler** su campi di età e miRNA-seq\n",
    "   - Applicazione di elsatic net tramite ```scikit-survival.CoxnetSurvivalAnalysis``` da addestrare (scikit-survival at: https://scikit-survival.readthedocs.io/en/stable/user_guide/coxnet.html)\n",
    "      - Applicare grid search e K-fold cross validation per capire set di parametri migliori\n",
    "   - Calcolo di risk score con funzione di predict\n",
    "        - possibile prevedere survival function o cumulative hazard function anche, ma necessario fare fine tuning con parametro ```fit_baselin_model=True```\n",
    "\n",
    "Motivazioni:\n",
    "   - Z-scaler per portare valori predittivi su stessa scala con varianza 1 e media 0\n",
    "   - Utilizzo di Cox con penalizzazione per fare feature selection e selezionare solo miRNA con maggiore rilevanza\n",
    "   - Utilizzo Elastic Net poichè Lasso-Cox normale non ottimale per due motivi: non può selezionare più features di quanti sample ci sono e in gruppo di features con alta correlazione tra loro ne sceglie a caso solo una tra queste. Elastic net risolve questi usando combinazione di l1 e l2 e rendendo più robusto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe80a9",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ff9c7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:00.805355Z",
     "start_time": "2025-10-28T11:25:59.087457Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5054239e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:02.480314Z",
     "start_time": "2025-10-28T11:26:00.810410Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1396728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:02.510084Z",
     "start_time": "2025-10-28T11:26:02.488905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giorg\\Documents\\GitHub\\miRNA_to_age\n"
     ]
    }
   ],
   "source": [
    "base = os.path.basename(os.getcwd())\n",
    "list = os.getcwd().split(os.sep) \n",
    "list.pop(list.index(base))\n",
    "ROOT = '\\\\'.join(list)\n",
    "print(ROOT)\n",
    "DATA_PATH = os.path.join(ROOT, 'datasets\\\\preprocessed')\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2cf89f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:03.315574Z",
     "start_time": "2025-10-28T11:26:02.516185Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(os.path.join(DATA_PATH, 'clinical_miRNA_normalized_log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac580140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:03.335029Z",
     "start_time": "2025-10-28T11:26:03.319427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 1896)\n",
      "Index(['days_to_death', 'age_at_initial_pathologic_diagnosis',\n",
      "       'days_to_last_followup', 'Death', 'pathologic_stage_Stage I',\n",
      "       'pathologic_stage_Stage IA', 'pathologic_stage_Stage IB',\n",
      "       'pathologic_stage_Stage II', 'pathologic_stage_Stage IIA',\n",
      "       'pathologic_stage_Stage IIB',\n",
      "       ...\n",
      "       'hsa-mir-941-5', 'hsa-mir-942', 'hsa-mir-943', 'hsa-mir-944',\n",
      "       'hsa-mir-95', 'hsa-mir-9500', 'hsa-mir-96', 'hsa-mir-98', 'hsa-mir-99a',\n",
      "       'hsa-mir-99b'],\n",
      "      dtype='object', length=1896)\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset.columns)\n",
    "# print(dataset.head())\n",
    "print(type(dataset.iloc[0]['days_to_death']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101662c",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972c2c89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:03.346947Z",
     "start_time": "2025-10-28T11:26:03.338780Z"
    }
   },
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36263aac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:07.737627Z",
     "start_time": "2025-10-28T11:26:03.350485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from sksurv.datasets import load_breast_cancer\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis, CoxPHSurvivalAnalysis\n",
    "\n",
    "X, y = load_breast_cancer()\n",
    "Xt = OneHotEncoder().fit_transform(X)\n",
    "Xt.round(2).head()\n",
    "\n",
    "print((X.iloc[:, :-4]<0).sum().sum())\n",
    "\n",
    "# print(Xt.select_dtypes(include=['object', 'category']).columns.tolist())\n",
    "# print(Xt.var)\n",
    "\n",
    "# alphas = 10.0 ** np.linspace(-4, 4, 50)\n",
    "# coefficients = {}\n",
    "\n",
    "# cph = CoxPHSurvivalAnalysis()\n",
    "# for alpha in alphas:\n",
    "#     cph.set_params(alpha=alpha)\n",
    "#     cph.fit(Xt, y)\n",
    "#     key = round(alpha, 5)\n",
    "#     coefficients[key] = cph.coef_\n",
    "\n",
    "# coefficients = pd.DataFrame.from_dict(coefficients).rename_axis(index=\"feature\", columns=\"alpha\").set_index(Xt.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588714a",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59fe3b64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:07.771676Z",
     "start_time": "2025-10-28T11:26:07.742197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(26), np.int64(27), np.int64(30), np.int64(31), np.int64(32), np.int64(83), np.int64(85), np.int64(86), np.int64(88), np.int64(89)]\n",
      "(760, 1896)\n",
      "(739, 1896)\n"
     ]
    }
   ],
   "source": [
    "unique, count = np.unique(dataset['age_at_initial_pathologic_diagnosis'], return_counts=True)\n",
    "to_drop = [unique[u] for u in range(len(unique)) if count[u] < 5]\n",
    "print(to_drop)\n",
    "print(dataset.shape)\n",
    "\n",
    "dataset=dataset[~dataset['age_at_initial_pathologic_diagnosis'].isin(to_drop)]\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0792dafe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T10:37:39.615777Z",
     "start_time": "2025-10-28T10:37:34.086496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     days_to_death  age_at_initial_pathologic_diagnosis  \\\nmin           -1.0                                 29.0   \nmax         4456.0                                 90.0   \n\n     days_to_last_followup  Death  pathologic_stage_Stage I  \\\nmin                    0.0    0.0                       0.0   \nmax                 6796.0    1.0                       1.0   \n\n     pathologic_stage_Stage IA  pathologic_stage_Stage IB  \\\nmin                        0.0                        0.0   \nmax                        1.0                        1.0   \n\n     pathologic_stage_Stage II  pathologic_stage_Stage IIA  \\\nmin                        0.0                         0.0   \nmax                        1.0                         1.0   \n\n     pathologic_stage_Stage IIB  ...  hsa-mir-941-5  hsa-mir-942  hsa-mir-943  \\\nmin                         0.0  ...      -9.965784    -9.965784    -9.965784   \nmax                         1.0  ...      -9.965784     7.513267     0.775161   \n\n     hsa-mir-944  hsa-mir-95  hsa-mir-9500  hsa-mir-96  hsa-mir-98  \\\nmin    -9.965784   -9.965784     -9.965784   -9.965784    2.914571   \nmax     6.584363    5.177018     -9.965784    8.007995    8.624918   \n\n     hsa-mir-99a  hsa-mir-99b  \nmin     5.317549    11.759983  \nmax    13.930765    17.955206  \n\n[2 rows x 1896 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>days_to_death</th>\n      <th>age_at_initial_pathologic_diagnosis</th>\n      <th>days_to_last_followup</th>\n      <th>Death</th>\n      <th>pathologic_stage_Stage I</th>\n      <th>pathologic_stage_Stage IA</th>\n      <th>pathologic_stage_Stage IB</th>\n      <th>pathologic_stage_Stage II</th>\n      <th>pathologic_stage_Stage IIA</th>\n      <th>pathologic_stage_Stage IIB</th>\n      <th>...</th>\n      <th>hsa-mir-941-5</th>\n      <th>hsa-mir-942</th>\n      <th>hsa-mir-943</th>\n      <th>hsa-mir-944</th>\n      <th>hsa-mir-95</th>\n      <th>hsa-mir-9500</th>\n      <th>hsa-mir-96</th>\n      <th>hsa-mir-98</th>\n      <th>hsa-mir-99a</th>\n      <th>hsa-mir-99b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>min</th>\n      <td>-1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-9.965784</td>\n      <td>-9.965784</td>\n      <td>-9.965784</td>\n      <td>-9.965784</td>\n      <td>-9.965784</td>\n      <td>-9.965784</td>\n      <td>-9.965784</td>\n      <td>2.914571</td>\n      <td>5.317549</td>\n      <td>11.759983</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4456.0</td>\n      <td>90.0</td>\n      <td>6796.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>-9.965784</td>\n      <td>7.513267</td>\n      <td>0.775161</td>\n      <td>6.584363</td>\n      <td>5.177018</td>\n      <td>-9.965784</td>\n      <td>8.007995</td>\n      <td>8.624918</td>\n      <td>13.930765</td>\n      <td>17.955206</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 1896 columns</p>\n</div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25831df3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:07.916913Z",
     "start_time": "2025-10-28T11:26:07.776175Z"
    }
   },
   "outputs": [],
   "source": [
    "# y = death_event and days_to_death/last_folowup\n",
    "# X = all the rest\n",
    "y_cols = ['Death', 'days_to_death', 'days_to_last_followup']\n",
    "X_cols = [col for col in dataset.columns if col not in y_cols]\n",
    "\n",
    "custom_dtype = np.dtype([\n",
    "    ('death', np.bool_),         # O 'bool'\n",
    "    ('days', np.float64)      # O 'float'\n",
    "])\n",
    "\n",
    "y = []\n",
    "for index,row in dataset[y_cols].iterrows():\n",
    "    if row['Death'] == 1:\n",
    "        y.append(np.array((True, row['days_to_death'].item()), dtype=custom_dtype))\n",
    "    elif row['Death'] == 0:\n",
    "        tuple = (False, row['days_to_last_followup'].item())\n",
    "        y.append(np.array(tuple, dtype=custom_dtype)) \n",
    "y = np.array(y)\n",
    "\n",
    "X = dataset[X_cols]\n",
    "# remove columns with zero-variance\n",
    "# print(X.shape)\n",
    "X = X.loc[:, X.var() != 0]\n",
    "# print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b445a",
   "metadata": {},
   "source": [
    "## Z-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26cab91c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:08.050709Z",
     "start_time": "2025-10-28T11:26:07.922914Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# minmax = MinMaxScaler(feature_range=(0,15))\n",
    "\n",
    "scaled_X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "# minmaxed_X = pd.DataFrame(minmax.fit_transform(scaled_X), columns = scaled_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1272691a",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e6ee597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:08.080732Z",
     "start_time": "2025-10-28T11:26:08.054727Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, stratify=X['age_at_initial_pathologic_diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673cc51",
   "metadata": {},
   "source": [
    "## K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da24d3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:08.623888Z",
     "start_time": "2025-10-28T11:26:08.617234Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=SEED)\n",
    "#kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372efb02",
   "metadata": {},
   "source": [
    "## Linear MLP"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, r2_score\n",
    "\n",
    "class MiRNANet_3(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout, start_lr=0.001, lr_decay=0.3, patience=15):\n",
    "        super(MiRNANet_3, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, output_dim),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "        self.lr_decay = lr_decay\n",
    "        self.patience = patience\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=start_lr)\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.scheduler = ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',        # riduce LR quando la metrica (loss) smette di diminuire\n",
    "            factor=self.lr_decay,        # dimezza il learning rate\n",
    "            patience=self.patience        # aspetta 10 epoche senza miglioramenti\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)   \n",
    "    def loop(self, train_loader, test_loader, epochs=100):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            total_train_loss = 0\n",
    "            total_train_acc = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(X_batch)\n",
    "                loss = self.criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_train_loss += loss.item()\n",
    "                total_train_acc += accuracy_score(np.argmax(outputs.detach().numpy(), axis=1), np.argmax(y_batch, axis=1))\n",
    "            \n",
    "            avg_train_loss = total_train_loss / len(train_loader)\n",
    "            avg_train_acc = total_train_acc / len(train_loader)\n",
    "            \n",
    "            self.scheduler.step(avg_train_loss)\n",
    "\n",
    "            train_accs.append(avg_train_acc)\n",
    "\n",
    "            self.model.eval()\n",
    "            total_val_loss = 0\n",
    "            total_val_acc = 0\n",
    "            with torch.no_grad():\n",
    "                preds = []\n",
    "                trues = []\n",
    "                for X_batch, y_batch in test_loader:\n",
    "                    outputs = self.model(X_batch)\n",
    "                    loss = self.criterion(outputs, y_batch)\n",
    "                    preds.append(outputs.numpy())\n",
    "                    trues.append(y_batch.numpy())\n",
    "                    total_val_loss += loss.item()\n",
    "                    total_val_acc += accuracy_score(np.argmax(outputs.detach().numpy(), axis=1), np.argmax(y_batch, axis=1))\n",
    "                preds = np.vstack(preds)\n",
    "                trues = np.vstack(trues)\n",
    "            avg_val_loss = total_val_loss / len(test_loader)\n",
    "            avg_val_acc = total_val_acc / len(test_loader)\n",
    "\n",
    "            train_losses.append(avg_train_loss)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "            val_accs.append(avg_val_acc)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:03d}:\\nTrain Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\\nTrain Acc: {avg_train_acc:.4f} | Val Acc: {avg_val_acc:.4f}\")\n",
    "            mae = mean_absolute_error(trues, preds)\n",
    "            print(f\"Test MAE: {mae:.2f}\")\n",
    "\n",
    "        model_res = {\n",
    "            'params':self.model.parameters(),\n",
    "            'train_losses':train_losses,\n",
    "            'eval_losses': val_losses,\n",
    "            'train_accs': train_accs,\n",
    "            'val_accs':val_accs,\n",
    "            'preds':preds,\n",
    "            'trues':trues\n",
    "        }\n",
    "\n",
    "        return model_res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:20.887750Z",
     "start_time": "2025-10-28T11:26:10.715638Z"
    }
   },
   "id": "dc9110f6bf6a17f3",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MiRNANet_5(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout, start_lr = 0.001):\n",
    "        super(MiRNANet_5, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, output_dim)  # <--- ultimo layer lineare\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=start_lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.scheduler = ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',        # riduce LR quando la metrica (loss) smette di diminuire\n",
    "            factor=0.6,        # dimezza il learning rate\n",
    "            patience=15        # aspetta 10 epoche senza miglioramenti\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def loop(self, train_loader, test_loader, epochs=100):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            total_train_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(X_batch)\n",
    "                # print(outputs)\n",
    "                loss = self.criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = total_train_loss / len(train_loader)\n",
    "            self.scheduler.step(avg_train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            total_val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                preds = []\n",
    "                trues = []\n",
    "                for X_batch, y_batch in test_loader:\n",
    "                    outputs = self.model(X_batch)\n",
    "                    loss = self.criterion(outputs, y_batch)\n",
    "                    preds.append(outputs.numpy())\n",
    "                    trues.append(y_batch.numpy())\n",
    "                preds = np.vstack(preds)\n",
    "                trues = np.vstack(trues)\n",
    "                total_val_loss += loss.item()\n",
    "            avg_val_loss = total_val_loss / len(test_loader)\n",
    "\n",
    "            train_losses.append(avg_train_loss)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:03d} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        model_res = {\n",
    "            'params':self.model.parameters(),\n",
    "            'train_losses':train_losses,\n",
    "            'eval_losses': val_losses\n",
    "        }\n",
    "\n",
    "        return model_res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:20.918247Z",
     "start_time": "2025-10-28T11:26:20.892316Z"
    }
   },
   "id": "fc1ddef09bf6e504",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "y_train_fixed = np.array([(row['death'], row['days']) for row in y_train], dtype=[('death', np.bool_), ('days', np.float64)])\n",
    "y_test_fixed = np.array([(row['death'], row['days']) for row in y_test], dtype=[('death', np.bool_), ('days', np.float64)])\n",
    "\n",
    "X_train_mlp = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_mlp = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_mlp = torch.tensor([row for row in y_train_fixed], dtype=torch.float32)\n",
    "y_test_mlp = torch.tensor([row for row in y_test_fixed], dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-28T11:26:20.952580Z",
     "start_time": "2025-10-28T11:26:20.922799Z"
    }
   },
   "id": "55533efb93c595e3",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m368.6932\u001B[0m      \u001B[32m441.1831\u001B[0m  0.0010  0.1078\n",
      "      2      \u001B[36m368.5039\u001B[0m      \u001B[32m441.0685\u001B[0m  0.0010  0.1167\n",
      "      3      \u001B[36m368.4366\u001B[0m      \u001B[32m441.0355\u001B[0m  0.0010  0.1131\n",
      "      4      \u001B[36m368.4205\u001B[0m      \u001B[32m441.0250\u001B[0m  0.0010  0.1193\n",
      "      5      \u001B[36m368.4160\u001B[0m      \u001B[32m441.0207\u001B[0m  0.0010  0.1057\n",
      "      6      \u001B[36m368.4152\u001B[0m      \u001B[32m441.0184\u001B[0m  0.0010  0.1133\n",
      "      7      \u001B[36m368.4145\u001B[0m      \u001B[32m441.0170\u001B[0m  0.0010  0.0839\n",
      "      8      \u001B[36m368.4143\u001B[0m      \u001B[32m441.0161\u001B[0m  0.0010  0.0776\n",
      "      9      \u001B[36m368.4140\u001B[0m      \u001B[32m441.0154\u001B[0m  0.0010  0.0999\n",
      "     10      368.4140      \u001B[32m441.0146\u001B[0m  0.0010  0.0980\n",
      "     11      \u001B[36m368.4135\u001B[0m      \u001B[32m441.0140\u001B[0m  0.0010  0.0871\n",
      "     12      \u001B[36m368.4134\u001B[0m      \u001B[32m441.0137\u001B[0m  0.0010  0.0988\n",
      "     13      \u001B[36m368.4134\u001B[0m      \u001B[32m441.0133\u001B[0m  0.0010  0.0767\n",
      "     14      368.4135      \u001B[32m441.0130\u001B[0m  0.0010  0.0810\n",
      "     15      \u001B[36m368.4133\u001B[0m      \u001B[32m441.0127\u001B[0m  0.0010  0.1039\n",
      "     16      \u001B[36m368.4132\u001B[0m      \u001B[32m441.0125\u001B[0m  0.0010  0.0980\n",
      "     17      \u001B[36m368.4130\u001B[0m      \u001B[32m441.0123\u001B[0m  0.0010  0.0997\n",
      "     18      368.4131      \u001B[32m441.0122\u001B[0m  0.0010  0.1045\n",
      "     19      \u001B[36m368.4130\u001B[0m      \u001B[32m441.0120\u001B[0m  0.0010  0.0850\n",
      "     20      368.4130      \u001B[32m441.0119\u001B[0m  0.0010  0.0877\n",
      "     21      \u001B[36m368.4130\u001B[0m      \u001B[32m441.0118\u001B[0m  0.0010  0.1066\n",
      "     22      \u001B[36m368.4130\u001B[0m      \u001B[32m441.0117\u001B[0m  0.0007  0.0921\n",
      "     23      368.4130      \u001B[32m441.0116\u001B[0m  0.0007  0.0949\n",
      "     24      \u001B[36m368.4129\u001B[0m      \u001B[32m441.0115\u001B[0m  0.0007  0.0914\n",
      "     25      368.4130      \u001B[32m441.0115\u001B[0m  0.0007  0.0853\n",
      "     26      \u001B[36m368.4129\u001B[0m      \u001B[32m441.0114\u001B[0m  0.0007  0.1059\n",
      "     27      368.4130      \u001B[32m441.0113\u001B[0m  0.0007  0.0908\n",
      "     28      368.4129      \u001B[32m441.0112\u001B[0m  0.0007  0.0903\n",
      "     29      \u001B[36m368.4129\u001B[0m      \u001B[32m441.0112\u001B[0m  0.0007  0.1066\n",
      "     30      368.4129      \u001B[32m441.0111\u001B[0m  0.0007  0.0838\n",
      "     31      368.4129      \u001B[32m441.0111\u001B[0m  0.0007  0.0947\n",
      "     32      368.4129      \u001B[32m441.0111\u001B[0m  0.0007  0.0876\n",
      "     33      \u001B[36m368.4128\u001B[0m      \u001B[32m441.0110\u001B[0m  0.0007  0.0895\n",
      "     34      368.4129      \u001B[32m441.0110\u001B[0m  0.0007  0.1058\n",
      "     35      368.4129      \u001B[32m441.0109\u001B[0m  0.0007  0.0928\n",
      "     36      \u001B[36m368.4128\u001B[0m      \u001B[32m441.0108\u001B[0m  0.0007  0.0889\n",
      "     37      368.4128      \u001B[32m441.0108\u001B[0m  0.0007  0.1265\n",
      "     38      368.4129      \u001B[32m441.0108\u001B[0m  0.0005  0.1023\n",
      "     39      368.4129      \u001B[32m441.0108\u001B[0m  0.0005  0.0971\n",
      "     40      \u001B[36m368.4128\u001B[0m      \u001B[32m441.0108\u001B[0m  0.0005  0.1310\n",
      "     41      368.4128      \u001B[32m441.0108\u001B[0m  0.0005  0.1181\n",
      "     42      368.4128      \u001B[32m441.0107\u001B[0m  0.0005  0.1178\n",
      "     43      368.4128      \u001B[32m441.0107\u001B[0m  0.0005  0.1107\n",
      "     44      368.4128      \u001B[32m441.0107\u001B[0m  0.0005  0.1007\n",
      "     45      368.4128      \u001B[32m441.0107\u001B[0m  0.0005  0.0856\n",
      "     46      368.4128      \u001B[32m441.0106\u001B[0m  0.0005  0.1017\n",
      "     47      368.4128      \u001B[32m441.0106\u001B[0m  0.0005  0.1112\n",
      "     48      368.4128      \u001B[32m441.0106\u001B[0m  0.0005  0.1010\n",
      "     49      \u001B[36m368.4128\u001B[0m      \u001B[32m441.0106\u001B[0m  0.0005  0.1150\n",
      "     50      \u001B[36m368.4128\u001B[0m      \u001B[32m441.0106\u001B[0m  0.0005  0.1439\n",
      "     51      368.4128      \u001B[32m441.0106\u001B[0m  0.0005  0.1475\n",
      "     52      368.4128      \u001B[32m441.0105\u001B[0m  0.0005  0.1139\n",
      "     53      \u001B[36m368.4128\u001B[0m      \u001B[32m441.0105\u001B[0m  0.0005  0.1226\n",
      "     54      368.4128      \u001B[32m441.0105\u001B[0m  0.0003  0.1223\n",
      "     55      368.4128      \u001B[32m441.0105\u001B[0m  0.0003  0.1319\n",
      "     56      368.4128      441.0105  0.0003  0.1200\n",
      "     57      368.4128      \u001B[32m441.0105\u001B[0m  0.0003  0.1468\n",
      "     58      \u001B[36m368.4128\u001B[0m      \u001B[32m441.0105\u001B[0m  0.0003  0.1247\n",
      "     59      368.4128      441.0105  0.0003  0.1179\n",
      "     60      368.4128      \u001B[32m441.0104\u001B[0m  0.0003  0.1252\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m383.2447\u001B[0m      \u001B[32m422.5024\u001B[0m  0.0010  0.0957\n",
      "      2      \u001B[36m383.0831\u001B[0m      \u001B[32m422.3906\u001B[0m  0.0010  0.1113\n",
      "      3      \u001B[36m382.9983\u001B[0m      \u001B[32m422.3451\u001B[0m  0.0010  0.1159\n",
      "      4      \u001B[36m382.9719\u001B[0m      \u001B[32m422.3284\u001B[0m  0.0010  0.1312\n",
      "      5      \u001B[36m382.9656\u001B[0m      \u001B[32m422.3220\u001B[0m  0.0010  0.1027\n",
      "      6      \u001B[36m382.9632\u001B[0m      \u001B[32m422.3190\u001B[0m  0.0010  0.1211\n",
      "      7      \u001B[36m382.9623\u001B[0m      \u001B[32m422.3173\u001B[0m  0.0010  0.1176\n",
      "      8      \u001B[36m382.9617\u001B[0m      \u001B[32m422.3160\u001B[0m  0.0010  0.1128\n",
      "      9      \u001B[36m382.9615\u001B[0m      \u001B[32m422.3150\u001B[0m  0.0010  0.1032\n",
      "     10      \u001B[36m382.9612\u001B[0m      \u001B[32m422.3143\u001B[0m  0.0010  0.0974\n",
      "     11      \u001B[36m382.9609\u001B[0m      \u001B[32m422.3136\u001B[0m  0.0010  0.1317\n",
      "     12      \u001B[36m382.9608\u001B[0m      \u001B[32m422.3132\u001B[0m  0.0010  0.1226\n",
      "     13      \u001B[36m382.9607\u001B[0m      \u001B[32m422.3129\u001B[0m  0.0010  0.1212\n",
      "     14      \u001B[36m382.9606\u001B[0m      \u001B[32m422.3126\u001B[0m  0.0010  0.1145\n",
      "     15      \u001B[36m382.9605\u001B[0m      \u001B[32m422.3122\u001B[0m  0.0010  0.1476\n",
      "     16      382.9605      \u001B[32m422.3119\u001B[0m  0.0010  0.1138\n",
      "     17      \u001B[36m382.9604\u001B[0m      \u001B[32m422.3116\u001B[0m  0.0010  0.1081\n",
      "     18      382.9605      \u001B[32m422.3114\u001B[0m  0.0010  0.0911\n",
      "     19      \u001B[36m382.9603\u001B[0m      \u001B[32m422.3113\u001B[0m  0.0010  0.0857\n",
      "     20      382.9603      \u001B[32m422.3111\u001B[0m  0.0007  0.1010\n",
      "     21      382.9603      \u001B[32m422.3110\u001B[0m  0.0007  0.0874\n",
      "     22      \u001B[36m382.9603\u001B[0m      \u001B[32m422.3109\u001B[0m  0.0007  0.0885\n",
      "     23      \u001B[36m382.9603\u001B[0m      \u001B[32m422.3108\u001B[0m  0.0007  0.1143\n",
      "     24      \u001B[36m382.9602\u001B[0m      \u001B[32m422.3107\u001B[0m  0.0007  0.0972\n",
      "     25      \u001B[36m382.9602\u001B[0m      \u001B[32m422.3106\u001B[0m  0.0007  0.0987\n",
      "     26      382.9602      \u001B[32m422.3105\u001B[0m  0.0007  0.1001\n",
      "     27      \u001B[36m382.9602\u001B[0m      \u001B[32m422.3104\u001B[0m  0.0007  0.0939\n",
      "     28      382.9602      \u001B[32m422.3104\u001B[0m  0.0007  0.0979\n",
      "     29      \u001B[36m382.9602\u001B[0m      \u001B[32m422.3103\u001B[0m  0.0007  0.0903\n",
      "     30      \u001B[36m382.9602\u001B[0m      \u001B[32m422.3102\u001B[0m  0.0007  0.0930\n",
      "     31      382.9602      \u001B[32m422.3102\u001B[0m  0.0007  0.1258\n",
      "     32      382.9602      \u001B[32m422.3101\u001B[0m  0.0007  0.0973\n",
      "     33      382.9602      \u001B[32m422.3101\u001B[0m  0.0007  0.1041\n",
      "     34      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3100\u001B[0m  0.0007  0.0969\n",
      "     35      382.9601      \u001B[32m422.3100\u001B[0m  0.0007  0.1072\n",
      "     36      382.9602      \u001B[32m422.3100\u001B[0m  0.0005  0.1167\n",
      "     37      382.9602      \u001B[32m422.3099\u001B[0m  0.0005  0.1082\n",
      "     38      382.9601      \u001B[32m422.3099\u001B[0m  0.0005  0.1176\n",
      "     39      382.9601      \u001B[32m422.3098\u001B[0m  0.0005  0.1090\n",
      "     40      382.9601      \u001B[32m422.3098\u001B[0m  0.0005  0.1387\n",
      "     41      382.9601      422.3098  0.0005  0.1323\n",
      "     42      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3098\u001B[0m  0.0005  0.1211\n",
      "     43      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3098\u001B[0m  0.0005  0.1192\n",
      "     44      382.9601      \u001B[32m422.3097\u001B[0m  0.0005  0.1376\n",
      "     45      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3097\u001B[0m  0.0005  0.1155\n",
      "     46      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3097\u001B[0m  0.0005  0.1047\n",
      "     47      382.9601      \u001B[32m422.3097\u001B[0m  0.0005  0.1099\n",
      "     48      382.9601      \u001B[32m422.3096\u001B[0m  0.0005  0.1255\n",
      "     49      382.9601      \u001B[32m422.3096\u001B[0m  0.0005  0.1271\n",
      "     50      382.9601      \u001B[32m422.3096\u001B[0m  0.0005  0.1121\n",
      "     51      382.9601      \u001B[32m422.3095\u001B[0m  0.0005  0.1184\n",
      "     52      382.9601      422.3095  0.0003  0.1078\n",
      "     53      382.9601      422.3095  0.0003  0.1392\n",
      "     54      382.9601      \u001B[32m422.3095\u001B[0m  0.0003  0.1113\n",
      "     55      382.9601      422.3095  0.0003  0.1059\n",
      "     56      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3095\u001B[0m  0.0003  0.1187\n",
      "     57      382.9601      422.3095  0.0003  0.1164\n",
      "     58      382.9601      \u001B[32m422.3095\u001B[0m  0.0003  0.1238\n",
      "     59      382.9601      422.3095  0.0003  0.1041\n",
      "     60      382.9601      \u001B[32m422.3094\u001B[0m  0.0003  0.1047\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m378.9490\u001B[0m      \u001B[32m432.9318\u001B[0m  0.0010  0.0890\n",
      "      2      \u001B[36m378.7742\u001B[0m      \u001B[32m432.8144\u001B[0m  0.0010  0.0849\n",
      "      3      \u001B[36m378.6653\u001B[0m      \u001B[32m432.7565\u001B[0m  0.0010  0.0977\n",
      "      4      \u001B[36m378.6245\u001B[0m      \u001B[32m432.7340\u001B[0m  0.0010  0.0856\n",
      "      5      \u001B[36m378.6128\u001B[0m      \u001B[32m432.7250\u001B[0m  0.0010  0.0845\n",
      "      6      \u001B[36m378.6091\u001B[0m      \u001B[32m432.7213\u001B[0m  0.0010  0.0956\n",
      "      7      \u001B[36m378.6074\u001B[0m      \u001B[32m432.7196\u001B[0m  0.0010  0.0904\n",
      "      8      \u001B[36m378.6069\u001B[0m      \u001B[32m432.7183\u001B[0m  0.0010  0.0850\n",
      "      9      \u001B[36m378.6067\u001B[0m      \u001B[32m432.7171\u001B[0m  0.0010  0.1034\n",
      "     10      \u001B[36m378.6061\u001B[0m      \u001B[32m432.7162\u001B[0m  0.0010  0.0825\n",
      "     11      \u001B[36m378.6059\u001B[0m      \u001B[32m432.7157\u001B[0m  0.0010  0.0824\n",
      "     12      378.6060      \u001B[32m432.7151\u001B[0m  0.0010  0.0994\n",
      "     13      \u001B[36m378.6054\u001B[0m      \u001B[32m432.7147\u001B[0m  0.0010  0.0916\n",
      "     14      378.6054      \u001B[32m432.7144\u001B[0m  0.0010  0.0865\n",
      "     15      \u001B[36m378.6053\u001B[0m      \u001B[32m432.7141\u001B[0m  0.0010  0.0868\n",
      "     16      \u001B[36m378.6053\u001B[0m      \u001B[32m432.7139\u001B[0m  0.0010  0.1008\n",
      "     17      \u001B[36m378.6052\u001B[0m      \u001B[32m432.7137\u001B[0m  0.0010  0.1025\n",
      "     18      \u001B[36m378.6052\u001B[0m      \u001B[32m432.7134\u001B[0m  0.0010  0.0949\n",
      "     19      \u001B[36m378.6052\u001B[0m      \u001B[32m432.7132\u001B[0m  0.0010  0.1114\n",
      "     20      \u001B[36m378.6051\u001B[0m      \u001B[32m432.7131\u001B[0m  0.0010  0.1019\n",
      "     21      \u001B[36m378.6050\u001B[0m      \u001B[32m432.7130\u001B[0m  0.0010  0.0927\n",
      "     22      378.6051      \u001B[32m432.7128\u001B[0m  0.0010  0.1167\n",
      "     23      \u001B[36m378.6050\u001B[0m      \u001B[32m432.7127\u001B[0m  0.0010  0.1013\n",
      "     24      \u001B[36m378.6049\u001B[0m      \u001B[32m432.7126\u001B[0m  0.0010  0.0906\n",
      "     25      378.6050      \u001B[32m432.7125\u001B[0m  0.0010  0.1038\n",
      "     26      378.6050      \u001B[32m432.7125\u001B[0m  0.0010  0.0924\n",
      "     27      378.6050      \u001B[32m432.7124\u001B[0m  0.0010  0.0851\n",
      "     28      378.6049      \u001B[32m432.7123\u001B[0m  0.0010  0.1272\n",
      "     29      \u001B[36m378.6049\u001B[0m      \u001B[32m432.7123\u001B[0m  0.0010  0.1028\n",
      "     30      378.6049      \u001B[32m432.7122\u001B[0m  0.0010  0.1093\n",
      "     31      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7121\u001B[0m  0.0010  0.1043\n",
      "     32      378.6049      \u001B[32m432.7121\u001B[0m  0.0010  0.1458\n",
      "     33      378.6049      \u001B[32m432.7120\u001B[0m  0.0010  0.1268\n",
      "     34      378.6048      \u001B[32m432.7119\u001B[0m  0.0010  0.1278\n",
      "     35      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7119\u001B[0m  0.0010  0.1155\n",
      "     36      378.6048      \u001B[32m432.7119\u001B[0m  0.0007  0.1390\n",
      "     37      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7118\u001B[0m  0.0007  0.1360\n",
      "     38      378.6049      \u001B[32m432.7118\u001B[0m  0.0007  0.1236\n",
      "     39      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7118\u001B[0m  0.0007  0.1037\n",
      "     40      378.6048      \u001B[32m432.7117\u001B[0m  0.0007  0.1093\n",
      "     41      378.6048      \u001B[32m432.7117\u001B[0m  0.0007  0.1288\n",
      "     42      378.6048      \u001B[32m432.7117\u001B[0m  0.0007  0.1162\n",
      "     43      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7116\u001B[0m  0.0007  0.1256\n",
      "     44      378.6048      \u001B[32m432.7116\u001B[0m  0.0007  0.1178\n",
      "     45      378.6048      \u001B[32m432.7116\u001B[0m  0.0007  0.1586\n",
      "     46      378.6048      \u001B[32m432.7116\u001B[0m  0.0007  0.1205\n",
      "     47      378.6048      \u001B[32m432.7115\u001B[0m  0.0007  0.1276\n",
      "     48      378.6048      \u001B[32m432.7115\u001B[0m  0.0007  0.1240\n",
      "     49      378.6048      \u001B[32m432.7115\u001B[0m  0.0007  0.1153\n",
      "     50      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7115\u001B[0m  0.0007  0.0972\n",
      "     51      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7114\u001B[0m  0.0007  0.0946\n",
      "     52      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7114\u001B[0m  0.0005  0.1075\n",
      "     53      378.6048      \u001B[32m432.7114\u001B[0m  0.0005  0.1090\n",
      "     54      378.6048      432.7114  0.0005  0.1170\n",
      "     55      378.6048      \u001B[32m432.7114\u001B[0m  0.0005  0.0939\n",
      "     56      378.6048      432.7114  0.0005  0.0897\n",
      "     57      378.6048      \u001B[32m432.7114\u001B[0m  0.0005  0.1032\n",
      "     58      378.6048      \u001B[32m432.7113\u001B[0m  0.0005  0.0907\n",
      "     59      378.6048      432.7113  0.0005  0.0936\n",
      "     60      378.6048      432.7113  0.0005  0.1073\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m375.2745\u001B[0m      \u001B[32m458.8292\u001B[0m  0.0010  0.0775\n",
      "      2      \u001B[36m375.0840\u001B[0m      \u001B[32m458.6758\u001B[0m  0.0010  0.1064\n",
      "      3      \u001B[36m374.9811\u001B[0m      \u001B[32m458.6161\u001B[0m  0.0010  0.1082\n",
      "      4      \u001B[36m374.9502\u001B[0m      \u001B[32m458.5967\u001B[0m  0.0010  0.1066\n",
      "      5      \u001B[36m374.9438\u001B[0m      \u001B[32m458.5895\u001B[0m  0.0010  0.1279\n",
      "      6      \u001B[36m374.9418\u001B[0m      \u001B[32m458.5864\u001B[0m  0.0010  0.1012\n",
      "      7      \u001B[36m374.9411\u001B[0m      \u001B[32m458.5844\u001B[0m  0.0010  0.1094\n",
      "      8      \u001B[36m374.9403\u001B[0m      \u001B[32m458.5832\u001B[0m  0.0010  0.0950\n",
      "      9      \u001B[36m374.9401\u001B[0m      \u001B[32m458.5821\u001B[0m  0.0010  0.1253\n",
      "     10      \u001B[36m374.9397\u001B[0m      \u001B[32m458.5814\u001B[0m  0.0010  0.0973\n",
      "     11      374.9398      \u001B[32m458.5807\u001B[0m  0.0010  0.0854\n",
      "     12      \u001B[36m374.9396\u001B[0m      \u001B[32m458.5802\u001B[0m  0.0010  0.1040\n",
      "     13      \u001B[36m374.9394\u001B[0m      \u001B[32m458.5798\u001B[0m  0.0010  0.1064\n",
      "     14      \u001B[36m374.9394\u001B[0m      \u001B[32m458.5794\u001B[0m  0.0010  0.1036\n",
      "     15      \u001B[36m374.9393\u001B[0m      \u001B[32m458.5791\u001B[0m  0.0010  0.1027\n",
      "     16      374.9394      \u001B[32m458.5789\u001B[0m  0.0010  0.0956\n",
      "     17      \u001B[36m374.9392\u001B[0m      \u001B[32m458.5786\u001B[0m  0.0010  0.1042\n",
      "     18      374.9394      \u001B[32m458.5783\u001B[0m  0.0010  0.0945\n",
      "     19      \u001B[36m374.9392\u001B[0m      \u001B[32m458.5780\u001B[0m  0.0010  0.1012\n",
      "     20      \u001B[36m374.9391\u001B[0m      \u001B[32m458.5779\u001B[0m  0.0007  0.1198\n",
      "     21      374.9392      \u001B[32m458.5778\u001B[0m  0.0007  0.0971\n",
      "     22      \u001B[36m374.9391\u001B[0m      \u001B[32m458.5777\u001B[0m  0.0007  0.1061\n",
      "     23      374.9391      \u001B[32m458.5776\u001B[0m  0.0007  0.1086\n",
      "     24      \u001B[36m374.9391\u001B[0m      \u001B[32m458.5775\u001B[0m  0.0007  0.0914\n",
      "     25      374.9391      \u001B[32m458.5774\u001B[0m  0.0007  0.1107\n",
      "     26      \u001B[36m374.9391\u001B[0m      \u001B[32m458.5773\u001B[0m  0.0007  0.1141\n",
      "     27      \u001B[36m374.9390\u001B[0m      \u001B[32m458.5772\u001B[0m  0.0007  0.1149\n",
      "     28      \u001B[36m374.9390\u001B[0m      \u001B[32m458.5772\u001B[0m  0.0007  0.1144\n",
      "     29      374.9390      \u001B[32m458.5771\u001B[0m  0.0007  0.1173\n",
      "     30      374.9390      \u001B[32m458.5770\u001B[0m  0.0007  0.0980\n",
      "     31      374.9390      \u001B[32m458.5770\u001B[0m  0.0007  0.1097\n",
      "     32      \u001B[36m374.9390\u001B[0m      \u001B[32m458.5769\u001B[0m  0.0007  0.1143\n",
      "     33      374.9390      \u001B[32m458.5768\u001B[0m  0.0007  0.1274\n",
      "     34      374.9390      \u001B[32m458.5768\u001B[0m  0.0007  0.1148\n",
      "     35      \u001B[36m374.9390\u001B[0m      \u001B[32m458.5767\u001B[0m  0.0007  0.1031\n",
      "     36      374.9390      \u001B[32m458.5767\u001B[0m  0.0005  0.1076\n",
      "     37      \u001B[36m374.9389\u001B[0m      \u001B[32m458.5766\u001B[0m  0.0005  0.1031\n",
      "     38      374.9389      \u001B[32m458.5766\u001B[0m  0.0005  0.0975\n",
      "     39      374.9389      \u001B[32m458.5765\u001B[0m  0.0005  0.1068\n",
      "     40      374.9390      \u001B[32m458.5765\u001B[0m  0.0005  0.1005\n",
      "     41      \u001B[36m374.9389\u001B[0m      \u001B[32m458.5765\u001B[0m  0.0005  0.1051\n",
      "     42      374.9390      \u001B[32m458.5765\u001B[0m  0.0005  0.1056\n",
      "     43      374.9389      \u001B[32m458.5764\u001B[0m  0.0005  0.1194\n",
      "     44      374.9389      \u001B[32m458.5764\u001B[0m  0.0005  0.1907\n",
      "     45      \u001B[36m374.9389\u001B[0m      \u001B[32m458.5764\u001B[0m  0.0005  0.1345\n",
      "     46      374.9389      \u001B[32m458.5764\u001B[0m  0.0005  0.1103\n",
      "     47      \u001B[36m374.9389\u001B[0m      \u001B[32m458.5763\u001B[0m  0.0005  0.0991\n",
      "     48      \u001B[36m374.9389\u001B[0m      \u001B[32m458.5763\u001B[0m  0.0005  0.1078\n",
      "     49      374.9389      \u001B[32m458.5763\u001B[0m  0.0005  0.0959\n",
      "     50      374.9389      458.5763  0.0005  0.1217\n",
      "     51      374.9389      \u001B[32m458.5762\u001B[0m  0.0005  0.1107\n",
      "     52      374.9389      \u001B[32m458.5762\u001B[0m  0.0003  0.1924\n",
      "     53      \u001B[36m374.9389\u001B[0m      \u001B[32m458.5762\u001B[0m  0.0003  0.1599\n",
      "     54      374.9389      \u001B[32m458.5762\u001B[0m  0.0003  0.1483\n",
      "     55      374.9389      \u001B[32m458.5762\u001B[0m  0.0003  0.1641\n",
      "     56      374.9389      458.5762  0.0003  0.1239\n",
      "     57      374.9389      \u001B[32m458.5761\u001B[0m  0.0003  0.1196\n",
      "     58      374.9389      \u001B[32m458.5761\u001B[0m  0.0003  0.1280\n",
      "     59      374.9389      \u001B[32m458.5761\u001B[0m  0.0003  0.1218\n",
      "     60      374.9389      \u001B[32m458.5761\u001B[0m  0.0003  0.1196\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m377.7552\u001B[0m      \u001B[32m436.9493\u001B[0m  0.0010  0.1163\n",
      "      2      \u001B[36m377.5739\u001B[0m      \u001B[32m436.8126\u001B[0m  0.0010  0.1173\n",
      "      3      \u001B[36m377.4713\u001B[0m      \u001B[32m436.7563\u001B[0m  0.0010  0.1126\n",
      "      4      \u001B[36m377.4341\u001B[0m      \u001B[32m436.7356\u001B[0m  0.0010  0.1197\n",
      "      5      \u001B[36m377.4250\u001B[0m      \u001B[32m436.7282\u001B[0m  0.0010  0.1174\n",
      "      6      \u001B[36m377.4221\u001B[0m      \u001B[32m436.7249\u001B[0m  0.0010  0.1159\n",
      "      7      \u001B[36m377.4208\u001B[0m      \u001B[32m436.7232\u001B[0m  0.0010  0.1130\n",
      "      8      \u001B[36m377.4205\u001B[0m      \u001B[32m436.7221\u001B[0m  0.0010  0.0936\n",
      "      9      \u001B[36m377.4202\u001B[0m      \u001B[32m436.7212\u001B[0m  0.0010  0.1034\n",
      "     10      \u001B[36m377.4200\u001B[0m      \u001B[32m436.7204\u001B[0m  0.0010  0.0918\n",
      "     11      \u001B[36m377.4200\u001B[0m      \u001B[32m436.7198\u001B[0m  0.0010  0.0937\n",
      "     12      \u001B[36m377.4196\u001B[0m      \u001B[32m436.7193\u001B[0m  0.0010  0.0951\n",
      "     13      \u001B[36m377.4196\u001B[0m      \u001B[32m436.7189\u001B[0m  0.0010  0.0831\n",
      "     14      \u001B[36m377.4194\u001B[0m      \u001B[32m436.7185\u001B[0m  0.0010  0.0989\n",
      "     15      \u001B[36m377.4193\u001B[0m      \u001B[32m436.7183\u001B[0m  0.0010  0.1082\n",
      "     16      \u001B[36m377.4192\u001B[0m      \u001B[32m436.7181\u001B[0m  0.0010  0.0870\n",
      "     17      377.4193      \u001B[32m436.7179\u001B[0m  0.0010  0.1002\n",
      "     18      \u001B[36m377.4192\u001B[0m      \u001B[32m436.7177\u001B[0m  0.0010  0.1008\n",
      "     19      \u001B[36m377.4191\u001B[0m      \u001B[32m436.7176\u001B[0m  0.0010  0.0906\n",
      "     20      377.4192      \u001B[32m436.7174\u001B[0m  0.0007  0.1209\n",
      "     21      377.4192      \u001B[32m436.7174\u001B[0m  0.0007  0.0921\n",
      "     22      377.4192      \u001B[32m436.7173\u001B[0m  0.0007  0.1041\n",
      "     23      \u001B[36m377.4191\u001B[0m      \u001B[32m436.7172\u001B[0m  0.0007  0.0992\n",
      "     24      \u001B[36m377.4190\u001B[0m      \u001B[32m436.7171\u001B[0m  0.0007  0.1012\n",
      "     25      377.4191      \u001B[32m436.7170\u001B[0m  0.0007  0.1080\n",
      "     26      377.4191      \u001B[32m436.7170\u001B[0m  0.0007  0.1138\n",
      "     27      \u001B[36m377.4190\u001B[0m      \u001B[32m436.7169\u001B[0m  0.0007  0.1228\n",
      "     28      377.4190      \u001B[32m436.7168\u001B[0m  0.0007  0.1014\n",
      "     29      \u001B[36m377.4190\u001B[0m      \u001B[32m436.7168\u001B[0m  0.0007  0.1022\n",
      "     30      377.4190      \u001B[32m436.7168\u001B[0m  0.0007  0.0978\n",
      "     31      377.4191      \u001B[32m436.7167\u001B[0m  0.0007  0.0934\n",
      "     32      \u001B[36m377.4190\u001B[0m      \u001B[32m436.7166\u001B[0m  0.0007  0.1379\n",
      "     33      377.4190      \u001B[32m436.7166\u001B[0m  0.0007  0.1181\n",
      "     34      \u001B[36m377.4190\u001B[0m      \u001B[32m436.7165\u001B[0m  0.0007  0.1180\n",
      "     35      \u001B[36m377.4190\u001B[0m      \u001B[32m436.7165\u001B[0m  0.0007  0.1112\n",
      "     36      377.4190      \u001B[32m436.7164\u001B[0m  0.0005  0.1116\n",
      "     37      \u001B[36m377.4189\u001B[0m      \u001B[32m436.7164\u001B[0m  0.0005  0.1218\n",
      "     38      377.4190      \u001B[32m436.7164\u001B[0m  0.0005  0.1051\n",
      "     39      377.4189      436.7164  0.0005  0.1105\n",
      "     40      377.4189      \u001B[32m436.7163\u001B[0m  0.0005  0.1081\n",
      "     41      377.4189      \u001B[32m436.7163\u001B[0m  0.0005  0.1120\n",
      "     42      377.4189      \u001B[32m436.7163\u001B[0m  0.0005  0.1119\n",
      "     43      377.4189      \u001B[32m436.7162\u001B[0m  0.0005  0.1132\n",
      "     44      377.4189      \u001B[32m436.7162\u001B[0m  0.0005  0.1118\n",
      "     45      377.4189      \u001B[32m436.7162\u001B[0m  0.0005  0.1098\n",
      "     46      \u001B[36m377.4189\u001B[0m      \u001B[32m436.7162\u001B[0m  0.0005  0.1240\n",
      "     47      377.4189      \u001B[32m436.7161\u001B[0m  0.0005  0.1200\n",
      "     48      \u001B[36m377.4189\u001B[0m      \u001B[32m436.7161\u001B[0m  0.0005  0.1262\n",
      "     49      377.4190      \u001B[32m436.7161\u001B[0m  0.0005  0.1051\n",
      "     50      377.4189      \u001B[32m436.7160\u001B[0m  0.0005  0.1183\n",
      "     51      377.4189      \u001B[32m436.7160\u001B[0m  0.0005  0.1070\n",
      "     52      377.4189      \u001B[32m436.7160\u001B[0m  0.0003  0.1168\n",
      "     53      377.4189      436.7160  0.0003  0.1426\n",
      "     54      \u001B[36m377.4189\u001B[0m      \u001B[32m436.7160\u001B[0m  0.0003  0.1306\n",
      "     55      377.4189      \u001B[32m436.7160\u001B[0m  0.0003  0.1049\n",
      "     56      377.4189      436.7160  0.0003  0.1100\n",
      "     57      377.4189      \u001B[32m436.7160\u001B[0m  0.0003  0.1499\n",
      "     58      \u001B[36m377.4189\u001B[0m      \u001B[32m436.7159\u001B[0m  0.0003  0.1001\n",
      "     59      377.4189      \u001B[32m436.7159\u001B[0m  0.0003  0.1220\n",
      "     60      377.4190      436.7159  0.0003  0.1031\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m377.0981\u001B[0m      \u001B[32m426.9122\u001B[0m  0.0010  0.1006\n",
      "      2      \u001B[36m376.9364\u001B[0m      \u001B[32m426.8033\u001B[0m  0.0010  0.0901\n",
      "      3      \u001B[36m376.8513\u001B[0m      \u001B[32m426.7558\u001B[0m  0.0010  0.0942\n",
      "      4      \u001B[36m376.8249\u001B[0m      \u001B[32m426.7386\u001B[0m  0.0010  0.1249\n",
      "      5      \u001B[36m376.8169\u001B[0m      \u001B[32m426.7324\u001B[0m  0.0010  0.1048\n",
      "      6      \u001B[36m376.8149\u001B[0m      \u001B[32m426.7295\u001B[0m  0.0010  0.1131\n",
      "      7      \u001B[36m376.8139\u001B[0m      \u001B[32m426.7279\u001B[0m  0.0010  0.0952\n",
      "      8      \u001B[36m376.8136\u001B[0m      \u001B[32m426.7267\u001B[0m  0.0010  0.0904\n",
      "      9      \u001B[36m376.8132\u001B[0m      \u001B[32m426.7258\u001B[0m  0.0010  0.1078\n",
      "     10      \u001B[36m376.8130\u001B[0m      \u001B[32m426.7251\u001B[0m  0.0010  0.0886\n",
      "     11      \u001B[36m376.8129\u001B[0m      \u001B[32m426.7245\u001B[0m  0.0010  0.0956\n",
      "     12      \u001B[36m376.8126\u001B[0m      \u001B[32m426.7241\u001B[0m  0.0010  0.0956\n",
      "     13      \u001B[36m376.8125\u001B[0m      \u001B[32m426.7237\u001B[0m  0.0010  0.0825\n",
      "     14      \u001B[36m376.8124\u001B[0m      \u001B[32m426.7234\u001B[0m  0.0010  0.1066\n",
      "     15      \u001B[36m376.8123\u001B[0m      \u001B[32m426.7231\u001B[0m  0.0010  0.1177\n",
      "     16      \u001B[36m376.8122\u001B[0m      \u001B[32m426.7229\u001B[0m  0.0010  0.1070\n",
      "     17      \u001B[36m376.8121\u001B[0m      \u001B[32m426.7227\u001B[0m  0.0010  0.1056\n",
      "     18      \u001B[36m376.8121\u001B[0m      \u001B[32m426.7226\u001B[0m  0.0010  0.0940\n",
      "     19      376.8122      \u001B[32m426.7224\u001B[0m  0.0010  0.1021\n",
      "     20      \u001B[36m376.8121\u001B[0m      \u001B[32m426.7223\u001B[0m  0.0007  0.1200\n",
      "     21      \u001B[36m376.8121\u001B[0m      \u001B[32m426.7222\u001B[0m  0.0007  0.1106\n",
      "     22      376.8121      \u001B[32m426.7221\u001B[0m  0.0007  0.1171\n",
      "     23      376.8121      \u001B[32m426.7220\u001B[0m  0.0007  0.0976\n",
      "     24      \u001B[36m376.8120\u001B[0m      \u001B[32m426.7220\u001B[0m  0.0007  0.1138\n",
      "     25      \u001B[36m376.8120\u001B[0m      \u001B[32m426.7219\u001B[0m  0.0007  0.1046\n",
      "     26      \u001B[36m376.8120\u001B[0m      \u001B[32m426.7218\u001B[0m  0.0007  0.1127\n",
      "     27      376.8120      \u001B[32m426.7218\u001B[0m  0.0007  0.1115\n",
      "     28      376.8120      \u001B[32m426.7217\u001B[0m  0.0007  0.1050\n",
      "     29      \u001B[36m376.8119\u001B[0m      \u001B[32m426.7216\u001B[0m  0.0007  0.1206\n",
      "     30      376.8120      \u001B[32m426.7216\u001B[0m  0.0007  0.1066\n",
      "     31      376.8120      \u001B[32m426.7215\u001B[0m  0.0007  0.1217\n",
      "     32      \u001B[36m376.8119\u001B[0m      \u001B[32m426.7214\u001B[0m  0.0007  0.1130\n",
      "     33      376.8119      \u001B[32m426.7214\u001B[0m  0.0007  0.1275\n",
      "     34      \u001B[36m376.8119\u001B[0m      \u001B[32m426.7214\u001B[0m  0.0007  0.1132\n",
      "     35      376.8120      \u001B[32m426.7213\u001B[0m  0.0007  0.1113\n",
      "     36      \u001B[36m376.8119\u001B[0m      \u001B[32m426.7212\u001B[0m  0.0005  0.1390\n",
      "     37      376.8119      \u001B[32m426.7212\u001B[0m  0.0005  0.1207\n",
      "     38      376.8119      \u001B[32m426.7212\u001B[0m  0.0005  0.1144\n",
      "     39      376.8119      \u001B[32m426.7212\u001B[0m  0.0005  0.0999\n",
      "     40      376.8119      \u001B[32m426.7211\u001B[0m  0.0005  0.1101\n",
      "     41      376.8119      \u001B[32m426.7211\u001B[0m  0.0005  0.1000\n",
      "     42      376.8119      \u001B[32m426.7211\u001B[0m  0.0005  0.0972\n",
      "     43      376.8119      \u001B[32m426.7210\u001B[0m  0.0005  0.1051\n",
      "     44      376.8119      \u001B[32m426.7210\u001B[0m  0.0005  0.1040\n",
      "     45      \u001B[36m376.8119\u001B[0m      \u001B[32m426.7210\u001B[0m  0.0005  0.1368\n",
      "     46      \u001B[36m376.8119\u001B[0m      \u001B[32m426.7210\u001B[0m  0.0005  0.1352\n",
      "     47      \u001B[36m376.8119\u001B[0m      \u001B[32m426.7209\u001B[0m  0.0005  0.1416\n",
      "     48      376.8119      \u001B[32m426.7209\u001B[0m  0.0005  0.1446\n",
      "     49      376.8119      \u001B[32m426.7209\u001B[0m  0.0005  0.1534\n",
      "     50      376.8119      \u001B[32m426.7209\u001B[0m  0.0005  0.1529\n",
      "     51      \u001B[36m376.8118\u001B[0m      \u001B[32m426.7209\u001B[0m  0.0005  0.1494\n",
      "     52      376.8119      426.7209  0.0003  0.1636\n",
      "     53      376.8119      \u001B[32m426.7209\u001B[0m  0.0003  0.1500\n",
      "     54      376.8119      \u001B[32m426.7208\u001B[0m  0.0003  0.1395\n",
      "     55      376.8119      \u001B[32m426.7208\u001B[0m  0.0003  0.1216\n",
      "     56      376.8118      \u001B[32m426.7208\u001B[0m  0.0003  0.1517\n",
      "     57      376.8118      \u001B[32m426.7208\u001B[0m  0.0003  0.1537\n",
      "     58      \u001B[36m376.8118\u001B[0m      \u001B[32m426.7208\u001B[0m  0.0003  0.1525\n",
      "     59      376.8119      426.7208  0.0003  0.1737\n",
      "     60      376.8118      \u001B[32m426.7208\u001B[0m  0.0003  0.1496\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m378.5749\u001B[0m      \u001B[32m422.1198\u001B[0m  0.0010  0.1209\n",
      "      2      \u001B[36m378.3835\u001B[0m      \u001B[32m421.9800\u001B[0m  0.0010  0.1291\n",
      "      3      \u001B[36m378.2790\u001B[0m      \u001B[32m421.9208\u001B[0m  0.0010  0.1467\n",
      "      4      \u001B[36m378.2479\u001B[0m      \u001B[32m421.9006\u001B[0m  0.0010  0.1102\n",
      "      5      \u001B[36m378.2396\u001B[0m      \u001B[32m421.8930\u001B[0m  0.0010  0.0999\n",
      "      6      \u001B[36m378.2373\u001B[0m      \u001B[32m421.8895\u001B[0m  0.0010  0.0901\n",
      "      7      \u001B[36m378.2364\u001B[0m      \u001B[32m421.8874\u001B[0m  0.0010  0.0929\n",
      "      8      \u001B[36m378.2358\u001B[0m      \u001B[32m421.8858\u001B[0m  0.0010  0.1351\n",
      "      9      \u001B[36m378.2353\u001B[0m      \u001B[32m421.8848\u001B[0m  0.0010  0.1075\n",
      "     10      \u001B[36m378.2351\u001B[0m      \u001B[32m421.8841\u001B[0m  0.0010  0.0985\n",
      "     11      \u001B[36m378.2349\u001B[0m      \u001B[32m421.8835\u001B[0m  0.0010  0.0900\n",
      "     12      \u001B[36m378.2348\u001B[0m      \u001B[32m421.8829\u001B[0m  0.0010  0.0841\n",
      "     13      378.2349      \u001B[32m421.8824\u001B[0m  0.0010  0.0993\n",
      "     14      \u001B[36m378.2347\u001B[0m      \u001B[32m421.8821\u001B[0m  0.0010  0.0974\n",
      "     15      \u001B[36m378.2346\u001B[0m      \u001B[32m421.8818\u001B[0m  0.0010  0.1101\n",
      "     16      \u001B[36m378.2345\u001B[0m      \u001B[32m421.8815\u001B[0m  0.0010  0.1146\n",
      "     17      378.2345      \u001B[32m421.8813\u001B[0m  0.0010  0.1341\n",
      "     18      \u001B[36m378.2344\u001B[0m      \u001B[32m421.8811\u001B[0m  0.0010  0.1485\n",
      "     19      \u001B[36m378.2344\u001B[0m      \u001B[32m421.8809\u001B[0m  0.0010  0.1095\n",
      "     20      378.2344      \u001B[32m421.8808\u001B[0m  0.0007  0.1068\n",
      "     21      \u001B[36m378.2343\u001B[0m      \u001B[32m421.8807\u001B[0m  0.0007  0.1130\n",
      "     22      378.2344      \u001B[32m421.8806\u001B[0m  0.0007  0.1227\n",
      "     23      \u001B[36m378.2343\u001B[0m      \u001B[32m421.8805\u001B[0m  0.0007  0.1055\n",
      "     24      378.2343      \u001B[32m421.8805\u001B[0m  0.0007  0.0993\n",
      "     25      378.2343      \u001B[32m421.8804\u001B[0m  0.0007  0.0936\n",
      "     26      378.2343      \u001B[32m421.8803\u001B[0m  0.0007  0.0961\n",
      "     27      \u001B[36m378.2343\u001B[0m      \u001B[32m421.8803\u001B[0m  0.0007  0.1097\n",
      "     28      378.2343      \u001B[32m421.8802\u001B[0m  0.0007  0.1017\n",
      "     29      \u001B[36m378.2343\u001B[0m      \u001B[32m421.8802\u001B[0m  0.0007  0.1109\n",
      "     30      378.2343      \u001B[32m421.8801\u001B[0m  0.0007  0.1300\n",
      "     31      \u001B[36m378.2343\u001B[0m      \u001B[32m421.8800\u001B[0m  0.0007  0.1051\n",
      "     32      378.2343      \u001B[32m421.8800\u001B[0m  0.0007  0.1107\n",
      "     33      378.2343      \u001B[32m421.8800\u001B[0m  0.0007  0.1048\n",
      "     34      378.2343      \u001B[32m421.8799\u001B[0m  0.0007  0.1136\n",
      "     35      \u001B[36m378.2342\u001B[0m      \u001B[32m421.8799\u001B[0m  0.0007  0.1038\n",
      "     36      378.2343      \u001B[32m421.8798\u001B[0m  0.0005  0.1170\n",
      "     37      \u001B[36m378.2342\u001B[0m      \u001B[32m421.8798\u001B[0m  0.0005  0.1346\n",
      "     38      378.2342      \u001B[32m421.8798\u001B[0m  0.0005  0.1352\n",
      "     39      378.2342      \u001B[32m421.8797\u001B[0m  0.0005  0.1210\n",
      "     40      \u001B[36m378.2342\u001B[0m      \u001B[32m421.8797\u001B[0m  0.0005  0.1298\n",
      "     41      378.2342      \u001B[32m421.8797\u001B[0m  0.0005  0.1440\n",
      "     42      \u001B[36m378.2342\u001B[0m      \u001B[32m421.8797\u001B[0m  0.0005  0.1467\n",
      "     43      \u001B[36m378.2342\u001B[0m      \u001B[32m421.8797\u001B[0m  0.0005  0.1113\n",
      "     44      378.2342      \u001B[32m421.8796\u001B[0m  0.0005  0.1014\n",
      "     45      378.2342      \u001B[32m421.8796\u001B[0m  0.0005  0.1420\n",
      "     46      378.2342      \u001B[32m421.8796\u001B[0m  0.0005  0.1087\n",
      "     47      \u001B[36m378.2342\u001B[0m      \u001B[32m421.8796\u001B[0m  0.0005  0.1132\n",
      "     48      378.2342      \u001B[32m421.8796\u001B[0m  0.0005  0.1031\n",
      "     49      378.2342      \u001B[32m421.8796\u001B[0m  0.0005  0.1189\n",
      "     50      \u001B[36m378.2342\u001B[0m      \u001B[32m421.8795\u001B[0m  0.0005  0.1085\n",
      "     51      378.2342      \u001B[32m421.8795\u001B[0m  0.0005  0.0997\n",
      "     52      378.2342      421.8795  0.0003  0.1147\n",
      "     53      378.2342      421.8795  0.0003  0.1059\n",
      "     54      378.2342      \u001B[32m421.8795\u001B[0m  0.0003  0.1170\n",
      "     55      378.2342      \u001B[32m421.8795\u001B[0m  0.0003  0.1127\n",
      "     56      378.2342      \u001B[32m421.8795\u001B[0m  0.0003  0.1233\n",
      "     57      378.2342      \u001B[32m421.8794\u001B[0m  0.0003  0.1014\n",
      "     58      378.2342      \u001B[32m421.8794\u001B[0m  0.0003  0.1011\n",
      "     59      \u001B[36m378.2342\u001B[0m      \u001B[32m421.8794\u001B[0m  0.0003  0.1193\n",
      "     60      378.2342      \u001B[32m421.8794\u001B[0m  0.0003  0.1175\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m378.6895\u001B[0m      \u001B[32m442.3096\u001B[0m  0.0010  0.1012\n",
      "      2      \u001B[36m378.5136\u001B[0m      \u001B[32m442.1859\u001B[0m  0.0010  0.0859\n",
      "      3      \u001B[36m378.4337\u001B[0m      \u001B[32m442.1474\u001B[0m  0.0010  0.0955\n",
      "      4      \u001B[36m378.4157\u001B[0m      \u001B[32m442.1348\u001B[0m  0.0010  0.1170\n",
      "      5      \u001B[36m378.4120\u001B[0m      \u001B[32m442.1297\u001B[0m  0.0010  0.0951\n",
      "      6      \u001B[36m378.4102\u001B[0m      \u001B[32m442.1271\u001B[0m  0.0010  0.1194\n",
      "      7      \u001B[36m378.4097\u001B[0m      \u001B[32m442.1258\u001B[0m  0.0010  0.1220\n",
      "      8      \u001B[36m378.4094\u001B[0m      \u001B[32m442.1247\u001B[0m  0.0010  0.1039\n",
      "      9      \u001B[36m378.4093\u001B[0m      \u001B[32m442.1239\u001B[0m  0.0010  0.1037\n",
      "     10      \u001B[36m378.4092\u001B[0m      \u001B[32m442.1232\u001B[0m  0.0010  0.0862\n",
      "     11      \u001B[36m378.4090\u001B[0m      \u001B[32m442.1226\u001B[0m  0.0010  0.1042\n",
      "     12      \u001B[36m378.4088\u001B[0m      \u001B[32m442.1220\u001B[0m  0.0010  0.0978\n",
      "     13      \u001B[36m378.4087\u001B[0m      \u001B[32m442.1216\u001B[0m  0.0010  0.0901\n",
      "     14      \u001B[36m378.4087\u001B[0m      \u001B[32m442.1213\u001B[0m  0.0010  0.1140\n",
      "     15      \u001B[36m378.4086\u001B[0m      \u001B[32m442.1210\u001B[0m  0.0010  0.1022\n",
      "     16      378.4086      \u001B[32m442.1208\u001B[0m  0.0010  0.1134\n",
      "     17      \u001B[36m378.4085\u001B[0m      \u001B[32m442.1206\u001B[0m  0.0010  0.1013\n",
      "     18      \u001B[36m378.4085\u001B[0m      \u001B[32m442.1204\u001B[0m  0.0010  0.1012\n",
      "     19      378.4085      \u001B[32m442.1202\u001B[0m  0.0010  0.1087\n",
      "     20      \u001B[36m378.4085\u001B[0m      \u001B[32m442.1200\u001B[0m  0.0010  0.0879\n",
      "     21      378.4085      \u001B[32m442.1199\u001B[0m  0.0007  0.0934\n",
      "     22      \u001B[36m378.4085\u001B[0m      \u001B[32m442.1198\u001B[0m  0.0007  0.0939\n",
      "     23      \u001B[36m378.4084\u001B[0m      \u001B[32m442.1197\u001B[0m  0.0007  0.0924\n",
      "     24      378.4085      \u001B[32m442.1196\u001B[0m  0.0007  0.1372\n",
      "     25      378.4084      \u001B[32m442.1195\u001B[0m  0.0007  0.1031\n",
      "     26      378.4084      \u001B[32m442.1195\u001B[0m  0.0007  0.1113\n",
      "     27      \u001B[36m378.4084\u001B[0m      \u001B[32m442.1194\u001B[0m  0.0007  0.1080\n",
      "     28      378.4084      \u001B[32m442.1193\u001B[0m  0.0007  0.1059\n",
      "     29      378.4084      \u001B[32m442.1193\u001B[0m  0.0007  0.1227\n",
      "     30      378.4084      \u001B[32m442.1192\u001B[0m  0.0007  0.1155\n",
      "     31      378.4084      \u001B[32m442.1191\u001B[0m  0.0007  0.1102\n",
      "     32      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1191\u001B[0m  0.0007  0.0944\n",
      "     33      378.4084      \u001B[32m442.1190\u001B[0m  0.0007  0.1171\n",
      "     34      378.4084      \u001B[32m442.1190\u001B[0m  0.0007  0.1103\n",
      "     35      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1190\u001B[0m  0.0007  0.1082\n",
      "     36      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1189\u001B[0m  0.0007  0.1131\n",
      "     37      378.4084      \u001B[32m442.1189\u001B[0m  0.0005  0.0970\n",
      "     38      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1188\u001B[0m  0.0005  0.1081\n",
      "     39      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1188\u001B[0m  0.0005  0.1187\n",
      "     40      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1188\u001B[0m  0.0005  0.1022\n",
      "     41      378.4084      \u001B[32m442.1187\u001B[0m  0.0005  0.1205\n",
      "     42      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1187\u001B[0m  0.0005  0.1086\n",
      "     43      378.4083      \u001B[32m442.1187\u001B[0m  0.0005  0.1230\n",
      "     44      378.4083      \u001B[32m442.1187\u001B[0m  0.0005  0.1072\n",
      "     45      378.4083      \u001B[32m442.1186\u001B[0m  0.0005  0.1127\n",
      "     46      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1186\u001B[0m  0.0005  0.0996\n",
      "     47      378.4083      \u001B[32m442.1186\u001B[0m  0.0005  0.0978\n",
      "     48      378.4083      \u001B[32m442.1186\u001B[0m  0.0005  0.1095\n",
      "     49      378.4083      \u001B[32m442.1185\u001B[0m  0.0005  0.1019\n",
      "     50      378.4083      \u001B[32m442.1185\u001B[0m  0.0005  0.1035\n",
      "     51      378.4083      \u001B[32m442.1185\u001B[0m  0.0005  0.0986\n",
      "     52      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1185\u001B[0m  0.0005  0.0926\n",
      "     53      378.4083      442.1185  0.0003  0.1127\n",
      "     54      378.4083      \u001B[32m442.1184\u001B[0m  0.0003  0.0965\n",
      "     55      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1184\u001B[0m  0.0003  0.1164\n",
      "     56      378.4083      \u001B[32m442.1184\u001B[0m  0.0003  0.0995\n",
      "     57      378.4083      \u001B[32m442.1184\u001B[0m  0.0003  0.0928\n",
      "     58      378.4083      \u001B[32m442.1184\u001B[0m  0.0003  0.1032\n",
      "     59      378.4083      442.1184  0.0003  0.0892\n",
      "     60      378.4083      \u001B[32m442.1183\u001B[0m  0.0003  0.0945\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m379.6574\u001B[0m      \u001B[32m430.4726\u001B[0m  0.0010  0.0936\n",
      "      2      \u001B[36m379.4487\u001B[0m      \u001B[32m430.3439\u001B[0m  0.0010  0.0855\n",
      "      3      \u001B[36m379.3621\u001B[0m      \u001B[32m430.2914\u001B[0m  0.0010  0.0807\n",
      "      4      \u001B[36m379.3370\u001B[0m      \u001B[32m430.2751\u001B[0m  0.0010  0.1409\n",
      "      5      \u001B[36m379.3324\u001B[0m      \u001B[32m430.2685\u001B[0m  0.0010  0.1081\n",
      "      6      \u001B[36m379.3304\u001B[0m      \u001B[32m430.2652\u001B[0m  0.0010  0.0985\n",
      "      7      \u001B[36m379.3294\u001B[0m      \u001B[32m430.2628\u001B[0m  0.0010  0.0922\n",
      "      8      \u001B[36m379.3286\u001B[0m      \u001B[32m430.2613\u001B[0m  0.0010  0.0895\n",
      "      9      \u001B[36m379.3284\u001B[0m      \u001B[32m430.2604\u001B[0m  0.0010  0.1065\n",
      "     10      \u001B[36m379.3284\u001B[0m      \u001B[32m430.2596\u001B[0m  0.0010  0.0965\n",
      "     11      \u001B[36m379.3281\u001B[0m      \u001B[32m430.2589\u001B[0m  0.0010  0.1090\n",
      "     12      \u001B[36m379.3279\u001B[0m      \u001B[32m430.2583\u001B[0m  0.0010  0.0951\n",
      "     13      \u001B[36m379.3277\u001B[0m      \u001B[32m430.2578\u001B[0m  0.0010  0.0880\n",
      "     14      379.3278      \u001B[32m430.2574\u001B[0m  0.0010  0.1016\n",
      "     15      \u001B[36m379.3276\u001B[0m      \u001B[32m430.2570\u001B[0m  0.0010  0.0924\n",
      "     16      \u001B[36m379.3276\u001B[0m      \u001B[32m430.2567\u001B[0m  0.0010  0.0822\n",
      "     17      \u001B[36m379.3275\u001B[0m      \u001B[32m430.2564\u001B[0m  0.0010  0.1059\n",
      "     18      \u001B[36m379.3275\u001B[0m      \u001B[32m430.2561\u001B[0m  0.0010  0.0858\n",
      "     19      379.3276      \u001B[32m430.2559\u001B[0m  0.0010  0.1013\n",
      "     20      \u001B[36m379.3274\u001B[0m      \u001B[32m430.2557\u001B[0m  0.0007  0.1269\n",
      "     21      \u001B[36m379.3274\u001B[0m      \u001B[32m430.2555\u001B[0m  0.0007  0.1251\n",
      "     22      379.3274      \u001B[32m430.2554\u001B[0m  0.0007  0.1054\n",
      "     23      \u001B[36m379.3273\u001B[0m      \u001B[32m430.2553\u001B[0m  0.0007  0.0945\n",
      "     24      \u001B[36m379.3273\u001B[0m      \u001B[32m430.2552\u001B[0m  0.0007  0.1109\n",
      "     25      379.3274      \u001B[32m430.2550\u001B[0m  0.0007  0.1043\n",
      "     26      \u001B[36m379.3272\u001B[0m      \u001B[32m430.2550\u001B[0m  0.0007  0.1036\n",
      "     27      379.3273      \u001B[32m430.2549\u001B[0m  0.0007  0.1295\n",
      "     28      379.3272      \u001B[32m430.2548\u001B[0m  0.0007  0.1285\n",
      "     29      379.3273      \u001B[32m430.2547\u001B[0m  0.0007  0.1437\n",
      "     30      \u001B[36m379.3272\u001B[0m      \u001B[32m430.2546\u001B[0m  0.0007  0.1318\n",
      "     31      379.3273      \u001B[32m430.2546\u001B[0m  0.0007  0.1465\n",
      "     32      379.3272      \u001B[32m430.2545\u001B[0m  0.0007  0.1422\n",
      "     33      \u001B[36m379.3272\u001B[0m      \u001B[32m430.2545\u001B[0m  0.0007  0.1669\n",
      "     34      379.3272      \u001B[32m430.2544\u001B[0m  0.0007  0.1464\n",
      "     35      379.3272      \u001B[32m430.2544\u001B[0m  0.0007  0.1296\n",
      "     36      \u001B[36m379.3272\u001B[0m      \u001B[32m430.2544\u001B[0m  0.0005  0.1751\n",
      "     37      379.3272      \u001B[32m430.2543\u001B[0m  0.0005  0.1603\n",
      "     38      379.3272      \u001B[32m430.2543\u001B[0m  0.0005  0.1272\n",
      "     39      379.3272      \u001B[32m430.2543\u001B[0m  0.0005  0.1377\n",
      "     40      379.3272      \u001B[32m430.2542\u001B[0m  0.0005  0.1595\n",
      "     41      \u001B[36m379.3272\u001B[0m      \u001B[32m430.2542\u001B[0m  0.0005  0.1328\n",
      "     42      379.3273      \u001B[32m430.2541\u001B[0m  0.0005  0.1183\n",
      "     43      379.3272      \u001B[32m430.2541\u001B[0m  0.0005  0.1501\n",
      "     44      \u001B[36m379.3271\u001B[0m      \u001B[32m430.2541\u001B[0m  0.0005  0.1360\n",
      "     45      379.3272      \u001B[32m430.2541\u001B[0m  0.0005  0.1257\n",
      "     46      379.3272      \u001B[32m430.2540\u001B[0m  0.0005  0.1105\n",
      "     47      \u001B[36m379.3271\u001B[0m      \u001B[32m430.2540\u001B[0m  0.0005  0.1418\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m372.4671\u001B[0m      \u001B[32m436.7631\u001B[0m  0.0010  0.0804\n",
      "      2      \u001B[36m372.3062\u001B[0m      \u001B[32m436.6348\u001B[0m  0.0010  0.0995\n",
      "      3      \u001B[36m372.1777\u001B[0m      \u001B[32m436.5509\u001B[0m  0.0010  0.1075\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m368.8241\u001B[0m      \u001B[32m441.4078\u001B[0m  0.0001  0.1102\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m383.3907\u001B[0m      \u001B[32m422.7329\u001B[0m  0.0001  0.0743\n",
      "      2      \u001B[36m383.3581\u001B[0m      \u001B[32m422.7051\u001B[0m  0.0001  0.1064\n",
      "      3      \u001B[36m383.3270\u001B[0m      \u001B[32m422.6775\u001B[0m  0.0001  0.2087\n",
      "      4      \u001B[36m383.3009\u001B[0m      \u001B[32m422.6508\u001B[0m  0.0001  0.1405\n",
      "      5      \u001B[36m383.2699\u001B[0m      \u001B[32m422.6264\u001B[0m  0.0001  0.1007\n",
      "      6      \u001B[36m383.2444\u001B[0m      \u001B[32m422.6029\u001B[0m  0.0001  0.1164\n",
      "      7      \u001B[36m383.2171\u001B[0m      \u001B[32m422.5800\u001B[0m  0.0001  0.1091\n",
      "      8      \u001B[36m383.1906\u001B[0m      \u001B[32m422.5578\u001B[0m  0.0001  0.1282\n",
      "      9      \u001B[36m383.1624\u001B[0m      \u001B[32m422.5369\u001B[0m  0.0001  0.1088\n",
      "     10      \u001B[36m383.1435\u001B[0m      \u001B[32m422.5173\u001B[0m  0.0001  0.1330\n",
      "     11      \u001B[36m383.1240\u001B[0m      \u001B[32m422.4982\u001B[0m  0.0001  0.1249\n",
      "     12      \u001B[36m383.1010\u001B[0m      \u001B[32m422.4802\u001B[0m  0.0001  0.1449\n",
      "     13      \u001B[36m383.0896\u001B[0m      \u001B[32m422.4642\u001B[0m  0.0001  0.0999\n",
      "     14      \u001B[36m383.0680\u001B[0m      \u001B[32m422.4493\u001B[0m  0.0001  0.1089\n",
      "     15      \u001B[36m383.0565\u001B[0m      \u001B[32m422.4353\u001B[0m  0.0001  0.1069\n",
      "     16      \u001B[36m383.0468\u001B[0m      \u001B[32m422.4235\u001B[0m  0.0001  0.1076\n",
      "     17      \u001B[36m383.0372\u001B[0m      \u001B[32m422.4130\u001B[0m  0.0001  0.1656\n",
      "     18      \u001B[36m383.0273\u001B[0m      \u001B[32m422.4037\u001B[0m  0.0001  0.1509\n",
      "     19      \u001B[36m383.0200\u001B[0m      \u001B[32m422.3954\u001B[0m  0.0001  0.1542\n",
      "     20      \u001B[36m383.0105\u001B[0m      \u001B[32m422.3877\u001B[0m  0.0001  0.1801\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m379.0064\u001B[0m      \u001B[32m433.0838\u001B[0m  0.0001  0.0945\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m375.2871\u001B[0m      \u001B[32m458.9200\u001B[0m  0.0001  0.0866\n",
      "      2      \u001B[36m375.2648\u001B[0m      \u001B[32m458.9010\u001B[0m  0.0001  0.1030\n",
      "      3      \u001B[36m375.2435\u001B[0m      \u001B[32m458.8840\u001B[0m  0.0001  0.0951\n",
      "      4      \u001B[36m375.2279\u001B[0m      \u001B[32m458.8686\u001B[0m  0.0001  0.1025\n",
      "      5      \u001B[36m375.2041\u001B[0m      \u001B[32m458.8541\u001B[0m  0.0001  0.0992\n",
      "      6      \u001B[36m375.1840\u001B[0m      \u001B[32m458.8398\u001B[0m  0.0001  0.1011\n",
      "      7      \u001B[36m375.1656\u001B[0m      \u001B[32m458.8254\u001B[0m  0.0001  0.1145\n",
      "      8      \u001B[36m375.1516\u001B[0m      \u001B[32m458.8110\u001B[0m  0.0001  0.1020\n",
      "      9      \u001B[36m375.1382\u001B[0m      \u001B[32m458.7961\u001B[0m  0.0001  0.0976\n",
      "     10      \u001B[36m375.1212\u001B[0m      \u001B[32m458.7816\u001B[0m  0.0001  0.1080\n",
      "     11      \u001B[36m375.1053\u001B[0m      \u001B[32m458.7673\u001B[0m  0.0001  0.0982\n",
      "     12      \u001B[36m375.0917\u001B[0m      \u001B[32m458.7537\u001B[0m  0.0001  0.1149\n",
      "     13      \u001B[36m375.0763\u001B[0m      \u001B[32m458.7412\u001B[0m  0.0001  0.0956\n",
      "     14      \u001B[36m375.0647\u001B[0m      \u001B[32m458.7290\u001B[0m  0.0001  0.0973\n",
      "     15      \u001B[36m375.0533\u001B[0m      \u001B[32m458.7175\u001B[0m  0.0001  0.1016\n",
      "     16      \u001B[36m375.0427\u001B[0m      \u001B[32m458.7067\u001B[0m  0.0001  0.0949\n",
      "     17      \u001B[36m375.0265\u001B[0m      \u001B[32m458.6970\u001B[0m  0.0001  0.1069\n",
      "     18      \u001B[36m375.0224\u001B[0m      \u001B[32m458.6874\u001B[0m  0.0001  0.0941\n",
      "     19      \u001B[36m375.0128\u001B[0m      \u001B[32m458.6785\u001B[0m  0.0001  0.0886\n",
      "     20      \u001B[36m375.0052\u001B[0m      \u001B[32m458.6706\u001B[0m  0.0001  0.1172\n",
      "     21      \u001B[36m375.0006\u001B[0m      \u001B[32m458.6633\u001B[0m  0.0001  0.1013\n",
      "     22      \u001B[36m374.9938\u001B[0m      \u001B[32m458.6561\u001B[0m  0.0001  0.1167\n",
      "     23      \u001B[36m374.9848\u001B[0m      \u001B[32m458.6499\u001B[0m  0.0001  0.1035\n",
      "     24      \u001B[36m374.9842\u001B[0m      \u001B[32m458.6446\u001B[0m  0.0001  0.0943\n",
      "     25      \u001B[36m374.9773\u001B[0m      \u001B[32m458.6398\u001B[0m  0.0001  0.1078\n",
      "     26      \u001B[36m374.9755\u001B[0m      \u001B[32m458.6352\u001B[0m  0.0001  0.0929\n",
      "     27      \u001B[36m374.9702\u001B[0m      \u001B[32m458.6308\u001B[0m  0.0001  0.1064\n",
      "     28      \u001B[36m374.9671\u001B[0m      \u001B[32m458.6270\u001B[0m  0.0001  0.1257\n",
      "     29      \u001B[36m374.9670\u001B[0m      \u001B[32m458.6237\u001B[0m  0.0001  0.0932\n",
      "     30      \u001B[36m374.9649\u001B[0m      \u001B[32m458.6203\u001B[0m  0.0001  0.1044\n",
      "     31      \u001B[36m374.9611\u001B[0m      \u001B[32m458.6171\u001B[0m  0.0001  0.0962\n",
      "     32      \u001B[36m374.9602\u001B[0m      \u001B[32m458.6145\u001B[0m  0.0001  0.1196\n",
      "     33      \u001B[36m374.9584\u001B[0m      \u001B[32m458.6122\u001B[0m  0.0001  0.1125\n",
      "     34      \u001B[36m374.9578\u001B[0m      \u001B[32m458.6100\u001B[0m  0.0001  0.0986\n",
      "     35      \u001B[36m374.9556\u001B[0m      \u001B[32m458.6080\u001B[0m  0.0001  0.1099\n",
      "     36      \u001B[36m374.9539\u001B[0m      \u001B[32m458.6062\u001B[0m  0.0001  0.1065\n",
      "     37      \u001B[36m374.9516\u001B[0m      \u001B[32m458.6046\u001B[0m  0.0001  0.1419\n",
      "     38      374.9523      \u001B[32m458.6032\u001B[0m  0.0001  0.1096\n",
      "     39      \u001B[36m374.9506\u001B[0m      \u001B[32m458.6019\u001B[0m  0.0001  0.1025\n",
      "     40      \u001B[36m374.9502\u001B[0m      \u001B[32m458.6006\u001B[0m  0.0001  0.1073\n",
      "     41      \u001B[36m374.9496\u001B[0m      \u001B[32m458.5995\u001B[0m  0.0001  0.1143\n",
      "     42      \u001B[36m374.9480\u001B[0m      \u001B[32m458.5986\u001B[0m  0.0001  0.1157\n",
      "     43      374.9488      \u001B[32m458.5977\u001B[0m  0.0001  0.1027\n",
      "     44      374.9486      \u001B[32m458.5967\u001B[0m  0.0001  0.1257\n",
      "     45      \u001B[36m374.9472\u001B[0m      \u001B[32m458.5958\u001B[0m  0.0001  0.1273\n",
      "     46      \u001B[36m374.9468\u001B[0m      \u001B[32m458.5950\u001B[0m  0.0001  0.1208\n",
      "     47      374.9472      \u001B[32m458.5942\u001B[0m  0.0001  0.1034\n",
      "     48      \u001B[36m374.9459\u001B[0m      \u001B[32m458.5935\u001B[0m  0.0001  0.1153\n",
      "     49      374.9462      \u001B[32m458.5928\u001B[0m  0.0001  0.1047\n",
      "     50      \u001B[36m374.9453\u001B[0m      \u001B[32m458.5920\u001B[0m  0.0001  0.1016\n",
      "     51      \u001B[36m374.9452\u001B[0m      \u001B[32m458.5915\u001B[0m  0.0001  0.1144\n",
      "     52      \u001B[36m374.9442\u001B[0m      \u001B[32m458.5910\u001B[0m  0.0001  0.1042\n",
      "     53      \u001B[36m374.9441\u001B[0m      \u001B[32m458.5907\u001B[0m  0.0001  0.1246\n",
      "     54      374.9443      \u001B[32m458.5903\u001B[0m  0.0001  0.1270\n",
      "     55      374.9442      \u001B[32m458.5900\u001B[0m  0.0001  0.1095\n",
      "     56      374.9447      \u001B[32m458.5896\u001B[0m  0.0001  0.1146\n",
      "     57      \u001B[36m374.9437\u001B[0m      \u001B[32m458.5894\u001B[0m  0.0001  0.1085\n",
      "     58      374.9440      \u001B[32m458.5890\u001B[0m  0.0001  0.1192\n",
      "     59      \u001B[36m374.9435\u001B[0m      \u001B[32m458.5887\u001B[0m  0.0001  0.1013\n",
      "     60      \u001B[36m374.9434\u001B[0m      \u001B[32m458.5885\u001B[0m  0.0001  0.1200\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m377.8382\u001B[0m      \u001B[32m437.1175\u001B[0m  0.0001  0.1066\n",
      "      2      \u001B[36m377.8148\u001B[0m      \u001B[32m437.0988\u001B[0m  0.0001  0.1315\n",
      "      3      \u001B[36m377.7929\u001B[0m      \u001B[32m437.0800\u001B[0m  0.0001  0.1151\n",
      "      4      \u001B[36m377.7718\u001B[0m      \u001B[32m437.0615\u001B[0m  0.0001  0.1271\n",
      "      5      \u001B[36m377.7474\u001B[0m      \u001B[32m437.0436\u001B[0m  0.0001  0.1154\n",
      "      6      \u001B[36m377.7296\u001B[0m      \u001B[32m437.0261\u001B[0m  0.0001  0.0966\n",
      "      7      \u001B[36m377.7094\u001B[0m      \u001B[32m437.0096\u001B[0m  0.0001  0.1088\n",
      "      8      \u001B[36m377.6890\u001B[0m      \u001B[32m436.9934\u001B[0m  0.0001  0.1035\n",
      "      9      \u001B[36m377.6739\u001B[0m      \u001B[32m436.9777\u001B[0m  0.0001  0.1276\n",
      "     10      \u001B[36m377.6538\u001B[0m      \u001B[32m436.9620\u001B[0m  0.0001  0.1104\n",
      "     11      \u001B[36m377.6328\u001B[0m      \u001B[32m436.9462\u001B[0m  0.0001  0.0997\n",
      "     12      \u001B[36m377.6194\u001B[0m      \u001B[32m436.9309\u001B[0m  0.0001  0.1134\n",
      "     13      \u001B[36m377.6048\u001B[0m      \u001B[32m436.9165\u001B[0m  0.0001  0.0964\n",
      "     14      \u001B[36m377.5829\u001B[0m      \u001B[32m436.9019\u001B[0m  0.0001  0.1323\n",
      "     15      \u001B[36m377.5731\u001B[0m      \u001B[32m436.8878\u001B[0m  0.0001  0.1027\n",
      "     16      \u001B[36m377.5539\u001B[0m      \u001B[32m436.8741\u001B[0m  0.0001  0.1053\n",
      "     17      \u001B[36m377.5419\u001B[0m      \u001B[32m436.8611\u001B[0m  0.0001  0.0949\n",
      "     18      \u001B[36m377.5309\u001B[0m      \u001B[32m436.8485\u001B[0m  0.0001  0.1043\n",
      "     19      \u001B[36m377.5190\u001B[0m      \u001B[32m436.8370\u001B[0m  0.0001  0.1038\n",
      "     20      \u001B[36m377.5088\u001B[0m      \u001B[32m436.8266\u001B[0m  0.0001  0.0935\n",
      "     21      \u001B[36m377.4966\u001B[0m      \u001B[32m436.8169\u001B[0m  0.0001  0.0888\n",
      "     22      \u001B[36m377.4907\u001B[0m      \u001B[32m436.8077\u001B[0m  0.0001  0.1107\n",
      "     23      \u001B[36m377.4830\u001B[0m      \u001B[32m436.7996\u001B[0m  0.0001  0.0987\n",
      "     24      \u001B[36m377.4701\u001B[0m      \u001B[32m436.7926\u001B[0m  0.0001  0.1341\n",
      "     25      \u001B[36m377.4676\u001B[0m      \u001B[32m436.7863\u001B[0m  0.0001  0.1307\n",
      "     26      \u001B[36m377.4633\u001B[0m      \u001B[32m436.7809\u001B[0m  0.0001  0.1411\n",
      "     27      \u001B[36m377.4594\u001B[0m      \u001B[32m436.7759\u001B[0m  0.0001  0.1501\n",
      "     28      \u001B[36m377.4531\u001B[0m      \u001B[32m436.7716\u001B[0m  0.0001  0.1642\n",
      "     29      \u001B[36m377.4522\u001B[0m      \u001B[32m436.7673\u001B[0m  0.0001  0.1304\n",
      "     30      \u001B[36m377.4500\u001B[0m      \u001B[32m436.7634\u001B[0m  0.0001  0.1329\n",
      "     31      \u001B[36m377.4450\u001B[0m      \u001B[32m436.7600\u001B[0m  0.0001  0.1234\n",
      "     32      \u001B[36m377.4442\u001B[0m      \u001B[32m436.7572\u001B[0m  0.0001  0.1600\n",
      "     33      \u001B[36m377.4421\u001B[0m      \u001B[32m436.7547\u001B[0m  0.0001  0.1752\n",
      "     34      \u001B[36m377.4401\u001B[0m      \u001B[32m436.7524\u001B[0m  0.0001  0.1668\n",
      "     35      \u001B[36m377.4381\u001B[0m      \u001B[32m436.7500\u001B[0m  0.0001  0.1762\n",
      "     36      \u001B[36m377.4364\u001B[0m      \u001B[32m436.7480\u001B[0m  0.0001  0.1591\n",
      "     37      \u001B[36m377.4351\u001B[0m      \u001B[32m436.7460\u001B[0m  0.0001  0.1622\n",
      "     38      \u001B[36m377.4335\u001B[0m      \u001B[32m436.7444\u001B[0m  0.0001  0.1767\n",
      "     39      377.4339      \u001B[32m436.7429\u001B[0m  0.0001  0.1892\n",
      "     40      \u001B[36m377.4320\u001B[0m      \u001B[32m436.7417\u001B[0m  0.0001  0.1801\n",
      "     41      \u001B[36m377.4315\u001B[0m      \u001B[32m436.7405\u001B[0m  0.0001  0.1867\n",
      "     42      \u001B[36m377.4303\u001B[0m      \u001B[32m436.7394\u001B[0m  0.0001  0.1980\n",
      "     43      \u001B[36m377.4288\u001B[0m      \u001B[32m436.7382\u001B[0m  0.0001  0.3371\n",
      "     44      \u001B[36m377.4284\u001B[0m      \u001B[32m436.7372\u001B[0m  0.0001  0.5022\n",
      "     45      377.4287      \u001B[32m436.7366\u001B[0m  0.0001  0.2166\n",
      "     46      377.4287      \u001B[32m436.7359\u001B[0m  0.0001  0.1761\n",
      "     47      \u001B[36m377.4268\u001B[0m      \u001B[32m436.7353\u001B[0m  0.0001  0.1555\n",
      "     48      377.4278      \u001B[32m436.7348\u001B[0m  0.0001  0.1419\n",
      "     49      377.4273      \u001B[32m436.7342\u001B[0m  0.0001  0.1489\n",
      "     50      377.4269      \u001B[32m436.7337\u001B[0m  0.0001  0.1377\n",
      "     51      \u001B[36m377.4263\u001B[0m      \u001B[32m436.7332\u001B[0m  0.0001  0.1260\n",
      "     52      \u001B[36m377.4257\u001B[0m      \u001B[32m436.7328\u001B[0m  0.0001  0.1310\n",
      "     53      377.4261      \u001B[32m436.7323\u001B[0m  0.0001  0.1490\n",
      "     54      377.4265      \u001B[32m436.7318\u001B[0m  0.0001  0.1368\n",
      "     55      377.4258      \u001B[32m436.7313\u001B[0m  0.0001  0.1163\n",
      "     56      \u001B[36m377.4252\u001B[0m      \u001B[32m436.7309\u001B[0m  0.0001  0.1335\n",
      "     57      377.4256      \u001B[32m436.7305\u001B[0m  0.0001  0.1149\n",
      "     58      \u001B[36m377.4249\u001B[0m      \u001B[32m436.7300\u001B[0m  0.0001  0.1350\n",
      "     59      377.4251      \u001B[32m436.7296\u001B[0m  0.0001  0.1199\n",
      "     60      \u001B[36m377.4248\u001B[0m      \u001B[32m436.7293\u001B[0m  0.0001  0.1209\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m377.1580\u001B[0m      \u001B[32m427.0566\u001B[0m  0.0001  0.1161\n",
      "      2      \u001B[36m377.1322\u001B[0m      \u001B[32m427.0272\u001B[0m  0.0001  0.1340\n",
      "      3      \u001B[36m377.1095\u001B[0m      \u001B[32m427.0039\u001B[0m  0.0001  0.1083\n",
      "      4      \u001B[36m377.0857\u001B[0m      \u001B[32m426.9847\u001B[0m  0.0001  0.1438\n",
      "      5      \u001B[36m377.0651\u001B[0m      \u001B[32m426.9666\u001B[0m  0.0001  0.1064\n",
      "      6      \u001B[36m377.0431\u001B[0m      \u001B[32m426.9496\u001B[0m  0.0001  0.1207\n",
      "      7      \u001B[36m377.0188\u001B[0m      \u001B[32m426.9339\u001B[0m  0.0001  0.1341\n",
      "      8      \u001B[36m377.0071\u001B[0m      \u001B[32m426.9190\u001B[0m  0.0001  0.1266\n",
      "      9      \u001B[36m376.9884\u001B[0m      \u001B[32m426.9047\u001B[0m  0.0001  0.1284\n",
      "     10      \u001B[36m376.9727\u001B[0m      \u001B[32m426.8906\u001B[0m  0.0001  0.1261\n",
      "     11      \u001B[36m376.9552\u001B[0m      \u001B[32m426.8772\u001B[0m  0.0001  0.1483\n",
      "     12      \u001B[36m376.9400\u001B[0m      \u001B[32m426.8643\u001B[0m  0.0001  0.1251\n",
      "     13      \u001B[36m376.9300\u001B[0m      \u001B[32m426.8523\u001B[0m  0.0001  0.1835\n",
      "     14      \u001B[36m376.9157\u001B[0m      \u001B[32m426.8410\u001B[0m  0.0001  0.1784\n",
      "     15      \u001B[36m376.9025\u001B[0m      \u001B[32m426.8303\u001B[0m  0.0001  0.1627\n",
      "     16      \u001B[36m376.8961\u001B[0m      \u001B[32m426.8209\u001B[0m  0.0001  0.1463\n",
      "     17      \u001B[36m376.8843\u001B[0m      \u001B[32m426.8119\u001B[0m  0.0001  0.1525\n",
      "     18      \u001B[36m376.8750\u001B[0m      \u001B[32m426.8041\u001B[0m  0.0001  0.1357\n",
      "     19      \u001B[36m376.8702\u001B[0m      \u001B[32m426.7971\u001B[0m  0.0001  0.1555\n",
      "     20      \u001B[36m376.8640\u001B[0m      \u001B[32m426.7907\u001B[0m  0.0001  0.1409\n",
      "     21      \u001B[36m376.8578\u001B[0m      \u001B[32m426.7848\u001B[0m  0.0001  0.1532\n",
      "     22      \u001B[36m376.8533\u001B[0m      \u001B[32m426.7795\u001B[0m  0.0001  0.1527\n",
      "     23      \u001B[36m376.8480\u001B[0m      \u001B[32m426.7749\u001B[0m  0.0001  0.1524\n",
      "     24      \u001B[36m376.8431\u001B[0m      \u001B[32m426.7709\u001B[0m  0.0001  0.1474\n",
      "     25      376.8434      \u001B[32m426.7672\u001B[0m  0.0001  0.1352\n",
      "     26      \u001B[36m376.8404\u001B[0m      \u001B[32m426.7634\u001B[0m  0.0001  0.1523\n",
      "     27      \u001B[36m376.8386\u001B[0m      \u001B[32m426.7602\u001B[0m  0.0001  0.1408\n",
      "     28      \u001B[36m376.8345\u001B[0m      \u001B[32m426.7573\u001B[0m  0.0001  0.1385\n",
      "     29      \u001B[36m376.8329\u001B[0m      \u001B[32m426.7548\u001B[0m  0.0001  0.1278\n",
      "     30      \u001B[36m376.8308\u001B[0m      \u001B[32m426.7526\u001B[0m  0.0001  0.1601\n",
      "     31      \u001B[36m376.8299\u001B[0m      \u001B[32m426.7505\u001B[0m  0.0001  0.1170\n",
      "     32      \u001B[36m376.8285\u001B[0m      \u001B[32m426.7488\u001B[0m  0.0001  0.1317\n",
      "     33      \u001B[36m376.8268\u001B[0m      \u001B[32m426.7471\u001B[0m  0.0001  0.1118\n",
      "     34      \u001B[36m376.8256\u001B[0m      \u001B[32m426.7454\u001B[0m  0.0001  0.1294\n",
      "     35      \u001B[36m376.8239\u001B[0m      \u001B[32m426.7441\u001B[0m  0.0001  0.1224\n",
      "     36      \u001B[36m376.8236\u001B[0m      \u001B[32m426.7428\u001B[0m  0.0001  0.1352\n",
      "     37      \u001B[36m376.8233\u001B[0m      \u001B[32m426.7416\u001B[0m  0.0001  0.1180\n",
      "     38      \u001B[36m376.8220\u001B[0m      \u001B[32m426.7404\u001B[0m  0.0001  0.1378\n",
      "     39      376.8223      \u001B[32m426.7394\u001B[0m  0.0001  0.1117\n",
      "     40      \u001B[36m376.8207\u001B[0m      \u001B[32m426.7385\u001B[0m  0.0001  0.1420\n",
      "     41      \u001B[36m376.8199\u001B[0m      \u001B[32m426.7376\u001B[0m  0.0001  0.1477\n",
      "     42      \u001B[36m376.8195\u001B[0m      \u001B[32m426.7369\u001B[0m  0.0001  0.1569\n",
      "     43      \u001B[36m376.8193\u001B[0m      \u001B[32m426.7362\u001B[0m  0.0001  0.1420\n",
      "     44      \u001B[36m376.8193\u001B[0m      \u001B[32m426.7357\u001B[0m  0.0001  0.1678\n",
      "     45      \u001B[36m376.8190\u001B[0m      \u001B[32m426.7352\u001B[0m  0.0001  0.1204\n",
      "     46      \u001B[36m376.8184\u001B[0m      \u001B[32m426.7348\u001B[0m  0.0001  0.1311\n",
      "     47      \u001B[36m376.8177\u001B[0m      \u001B[32m426.7344\u001B[0m  0.0001  0.1182\n",
      "     48      \u001B[36m376.8175\u001B[0m      \u001B[32m426.7340\u001B[0m  0.0001  0.1418\n",
      "     49      376.8176      \u001B[32m426.7336\u001B[0m  0.0001  0.1201\n",
      "     50      376.8180      \u001B[32m426.7333\u001B[0m  0.0001  0.1271\n",
      "     51      \u001B[36m376.8169\u001B[0m      \u001B[32m426.7329\u001B[0m  0.0001  0.1132\n",
      "     52      376.8174      \u001B[32m426.7325\u001B[0m  0.0001  0.1370\n",
      "     53      376.8170      \u001B[32m426.7321\u001B[0m  0.0001  0.1556\n",
      "     54      \u001B[36m376.8168\u001B[0m      \u001B[32m426.7318\u001B[0m  0.0001  0.1223\n",
      "     55      376.8171      \u001B[32m426.7315\u001B[0m  0.0001  0.1221\n",
      "     56      \u001B[36m376.8165\u001B[0m      \u001B[32m426.7312\u001B[0m  0.0001  0.1361\n",
      "     57      376.8167      \u001B[32m426.7309\u001B[0m  0.0001  0.1124\n",
      "     58      \u001B[36m376.8158\u001B[0m      \u001B[32m426.7306\u001B[0m  0.0001  0.1182\n",
      "     59      \u001B[36m376.8155\u001B[0m      \u001B[32m426.7303\u001B[0m  0.0001  0.1355\n",
      "     60      \u001B[36m376.8154\u001B[0m      \u001B[32m426.7302\u001B[0m  0.0000  0.1549\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m378.6114\u001B[0m      \u001B[32m422.2612\u001B[0m  0.0001  0.1482\n",
      "      2      \u001B[36m378.5828\u001B[0m      \u001B[32m422.2352\u001B[0m  0.0001  0.1373\n",
      "      3      \u001B[36m378.5572\u001B[0m      \u001B[32m422.2109\u001B[0m  0.0001  0.1124\n",
      "      4      \u001B[36m378.5302\u001B[0m      \u001B[32m422.1885\u001B[0m  0.0001  0.1187\n",
      "      5      \u001B[36m378.5064\u001B[0m      \u001B[32m422.1674\u001B[0m  0.0001  0.1170\n",
      "      6      \u001B[36m378.4807\u001B[0m      \u001B[32m422.1473\u001B[0m  0.0001  0.1079\n",
      "      7      \u001B[36m378.4587\u001B[0m      \u001B[32m422.1272\u001B[0m  0.0001  0.1004\n",
      "      8      \u001B[36m378.4330\u001B[0m      \u001B[32m422.1072\u001B[0m  0.0001  0.1138\n",
      "      9      \u001B[36m378.4183\u001B[0m      \u001B[32m422.0888\u001B[0m  0.0001  0.1041\n",
      "     10      \u001B[36m378.3997\u001B[0m      \u001B[32m422.0719\u001B[0m  0.0001  0.1038\n",
      "     11      \u001B[36m378.3763\u001B[0m      \u001B[32m422.0557\u001B[0m  0.0001  0.1094\n",
      "     12      \u001B[36m378.3651\u001B[0m      \u001B[32m422.0403\u001B[0m  0.0001  0.1021\n",
      "     13      \u001B[36m378.3536\u001B[0m      \u001B[32m422.0260\u001B[0m  0.0001  0.1446\n",
      "     14      \u001B[36m378.3363\u001B[0m      \u001B[32m422.0126\u001B[0m  0.0001  0.1239\n",
      "     15      \u001B[36m378.3225\u001B[0m      \u001B[32m422.0009\u001B[0m  0.0001  0.1323\n",
      "     16      \u001B[36m378.3160\u001B[0m      \u001B[32m421.9902\u001B[0m  0.0001  0.1010\n",
      "     17      \u001B[36m378.3024\u001B[0m      \u001B[32m421.9807\u001B[0m  0.0001  0.1045\n",
      "     18      \u001B[36m378.2956\u001B[0m      \u001B[32m421.9721\u001B[0m  0.0001  0.0962\n",
      "     19      \u001B[36m378.2899\u001B[0m      \u001B[32m421.9644\u001B[0m  0.0001  0.0884\n",
      "     20      \u001B[36m378.2846\u001B[0m      \u001B[32m421.9576\u001B[0m  0.0001  0.0971\n",
      "     21      \u001B[36m378.2826\u001B[0m      \u001B[32m421.9516\u001B[0m  0.0001  0.0954\n",
      "     22      \u001B[36m378.2740\u001B[0m      \u001B[32m421.9460\u001B[0m  0.0001  0.1300\n",
      "     23      \u001B[36m378.2673\u001B[0m      \u001B[32m421.9411\u001B[0m  0.0001  0.1369\n",
      "     24      \u001B[36m378.2663\u001B[0m      \u001B[32m421.9368\u001B[0m  0.0001  0.1195\n",
      "     25      \u001B[36m378.2638\u001B[0m      \u001B[32m421.9327\u001B[0m  0.0001  0.1153\n",
      "     26      \u001B[36m378.2588\u001B[0m      \u001B[32m421.9294\u001B[0m  0.0001  0.1005\n",
      "     27      \u001B[36m378.2584\u001B[0m      \u001B[32m421.9264\u001B[0m  0.0001  0.1180\n",
      "     28      \u001B[36m378.2547\u001B[0m      \u001B[32m421.9237\u001B[0m  0.0001  0.1194\n",
      "     29      \u001B[36m378.2535\u001B[0m      \u001B[32m421.9213\u001B[0m  0.0001  0.1338\n",
      "     30      \u001B[36m378.2533\u001B[0m      \u001B[32m421.9190\u001B[0m  0.0001  0.1034\n",
      "     31      \u001B[36m378.2515\u001B[0m      \u001B[32m421.9168\u001B[0m  0.0001  0.1056\n",
      "     32      378.2520      \u001B[32m421.9146\u001B[0m  0.0001  0.1019\n",
      "     33      \u001B[36m378.2494\u001B[0m      \u001B[32m421.9128\u001B[0m  0.0001  0.0958\n",
      "     34      \u001B[36m378.2482\u001B[0m      \u001B[32m421.9111\u001B[0m  0.0001  0.1125\n",
      "     35      \u001B[36m378.2472\u001B[0m      \u001B[32m421.9096\u001B[0m  0.0001  0.1019\n",
      "     36      \u001B[36m378.2458\u001B[0m      \u001B[32m421.9082\u001B[0m  0.0001  0.0942\n",
      "     37      \u001B[36m378.2453\u001B[0m      \u001B[32m421.9069\u001B[0m  0.0001  0.1058\n",
      "     38      \u001B[36m378.2447\u001B[0m      \u001B[32m421.9057\u001B[0m  0.0001  0.1014\n",
      "     39      \u001B[36m378.2440\u001B[0m      \u001B[32m421.9047\u001B[0m  0.0001  0.1079\n",
      "     40      378.2440      \u001B[32m421.9035\u001B[0m  0.0001  0.0946\n",
      "     41      \u001B[36m378.2425\u001B[0m      \u001B[32m421.9026\u001B[0m  0.0001  0.0963\n",
      "     42      378.2425      \u001B[32m421.9016\u001B[0m  0.0001  0.1290\n",
      "     43      \u001B[36m378.2418\u001B[0m      \u001B[32m421.9008\u001B[0m  0.0001  0.1042\n",
      "     44      378.2424      \u001B[32m421.9001\u001B[0m  0.0001  0.0997\n",
      "     45      \u001B[36m378.2413\u001B[0m      \u001B[32m421.8994\u001B[0m  0.0001  0.0980\n",
      "     46      \u001B[36m378.2411\u001B[0m      \u001B[32m421.8988\u001B[0m  0.0001  0.1244\n",
      "     47      \u001B[36m378.2407\u001B[0m      \u001B[32m421.8982\u001B[0m  0.0001  0.1253\n",
      "     48      \u001B[36m378.2404\u001B[0m      \u001B[32m421.8978\u001B[0m  0.0001  0.1249\n",
      "     49      378.2405      \u001B[32m421.8974\u001B[0m  0.0001  0.1132\n",
      "     50      378.2405      \u001B[32m421.8970\u001B[0m  0.0001  0.0965\n",
      "     51      \u001B[36m378.2399\u001B[0m      \u001B[32m421.8965\u001B[0m  0.0001  0.1389\n",
      "     52      378.2403      \u001B[32m421.8961\u001B[0m  0.0001  0.1296\n",
      "     53      378.2405      \u001B[32m421.8957\u001B[0m  0.0001  0.1316\n",
      "     54      \u001B[36m378.2393\u001B[0m      \u001B[32m421.8952\u001B[0m  0.0001  0.1119\n",
      "     55      378.2393      \u001B[32m421.8949\u001B[0m  0.0001  0.1431\n",
      "     56      \u001B[36m378.2389\u001B[0m      \u001B[32m421.8946\u001B[0m  0.0001  0.1070\n",
      "     57      378.2392      \u001B[32m421.8942\u001B[0m  0.0001  0.1087\n",
      "     58      378.2389      \u001B[32m421.8938\u001B[0m  0.0001  0.0963\n",
      "     59      \u001B[36m378.2384\u001B[0m      \u001B[32m421.8935\u001B[0m  0.0001  0.0939\n",
      "     60      378.2384      \u001B[32m421.8933\u001B[0m  0.0001  0.1135\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m378.7403\u001B[0m      \u001B[32m442.4489\u001B[0m  0.0001  0.0890\n",
      "      2      \u001B[36m378.7077\u001B[0m      \u001B[32m442.4242\u001B[0m  0.0001  0.0993\n",
      "      3      \u001B[36m378.6827\u001B[0m      \u001B[32m442.4006\u001B[0m  0.0001  0.0929\n",
      "      4      \u001B[36m378.6593\u001B[0m      \u001B[32m442.3800\u001B[0m  0.0001  0.0896\n",
      "      5      \u001B[36m378.6377\u001B[0m      \u001B[32m442.3619\u001B[0m  0.0001  0.0977\n",
      "      6      \u001B[36m378.6172\u001B[0m      \u001B[32m442.3448\u001B[0m  0.0001  0.0894\n",
      "      7      \u001B[36m378.5982\u001B[0m      \u001B[32m442.3285\u001B[0m  0.0001  0.0886\n",
      "      8      \u001B[36m378.5773\u001B[0m      \u001B[32m442.3132\u001B[0m  0.0001  0.0943\n",
      "      9      \u001B[36m378.5601\u001B[0m      \u001B[32m442.2991\u001B[0m  0.0001  0.0903\n",
      "     10      \u001B[36m378.5497\u001B[0m      \u001B[32m442.2856\u001B[0m  0.0001  0.0838\n",
      "     11      \u001B[36m378.5363\u001B[0m      \u001B[32m442.2725\u001B[0m  0.0001  0.1024\n",
      "     12      \u001B[36m378.5246\u001B[0m      \u001B[32m442.2607\u001B[0m  0.0001  0.0940\n",
      "     13      \u001B[36m378.5066\u001B[0m      \u001B[32m442.2492\u001B[0m  0.0001  0.0924\n",
      "     14      \u001B[36m378.4968\u001B[0m      \u001B[32m442.2389\u001B[0m  0.0001  0.0989\n",
      "     15      \u001B[36m378.4903\u001B[0m      \u001B[32m442.2294\u001B[0m  0.0001  0.0863\n",
      "     16      \u001B[36m378.4833\u001B[0m      \u001B[32m442.2207\u001B[0m  0.0001  0.1165\n",
      "     17      \u001B[36m378.4750\u001B[0m      \u001B[32m442.2129\u001B[0m  0.0001  0.1198\n",
      "     18      \u001B[36m378.4628\u001B[0m      \u001B[32m442.2056\u001B[0m  0.0001  0.1127\n",
      "     19      \u001B[36m378.4627\u001B[0m      \u001B[32m442.1988\u001B[0m  0.0001  0.1221\n",
      "     20      \u001B[36m378.4567\u001B[0m      \u001B[32m442.1925\u001B[0m  0.0001  0.1166\n",
      "     21      \u001B[36m378.4506\u001B[0m      \u001B[32m442.1871\u001B[0m  0.0001  0.1246\n",
      "     22      \u001B[36m378.4484\u001B[0m      \u001B[32m442.1821\u001B[0m  0.0001  0.1124\n",
      "     23      \u001B[36m378.4449\u001B[0m      \u001B[32m442.1775\u001B[0m  0.0001  0.1010\n",
      "     24      \u001B[36m378.4401\u001B[0m      \u001B[32m442.1732\u001B[0m  0.0001  0.1107\n",
      "     25      \u001B[36m378.4365\u001B[0m      \u001B[32m442.1694\u001B[0m  0.0001  0.1192\n",
      "     26      \u001B[36m378.4341\u001B[0m      \u001B[32m442.1660\u001B[0m  0.0001  0.1030\n",
      "     27      \u001B[36m378.4313\u001B[0m      \u001B[32m442.1630\u001B[0m  0.0001  0.0919\n",
      "     28      \u001B[36m378.4303\u001B[0m      \u001B[32m442.1603\u001B[0m  0.0001  0.0956\n",
      "     29      \u001B[36m378.4271\u001B[0m      \u001B[32m442.1579\u001B[0m  0.0001  0.0919\n",
      "     30      378.4274      \u001B[32m442.1555\u001B[0m  0.0001  0.0889\n",
      "     31      \u001B[36m378.4251\u001B[0m      \u001B[32m442.1532\u001B[0m  0.0001  0.1162\n",
      "     32      \u001B[36m378.4235\u001B[0m      \u001B[32m442.1510\u001B[0m  0.0001  0.0981\n",
      "     33      \u001B[36m378.4228\u001B[0m      \u001B[32m442.1494\u001B[0m  0.0001  0.1023\n",
      "     34      \u001B[36m378.4220\u001B[0m      \u001B[32m442.1478\u001B[0m  0.0001  0.1007\n",
      "     35      \u001B[36m378.4215\u001B[0m      \u001B[32m442.1462\u001B[0m  0.0001  0.1030\n",
      "     36      \u001B[36m378.4208\u001B[0m      \u001B[32m442.1447\u001B[0m  0.0001  0.1489\n",
      "     37      \u001B[36m378.4192\u001B[0m      \u001B[32m442.1434\u001B[0m  0.0001  0.1018\n",
      "     38      \u001B[36m378.4178\u001B[0m      \u001B[32m442.1422\u001B[0m  0.0001  0.1061\n",
      "     39      378.4178      \u001B[32m442.1411\u001B[0m  0.0001  0.1007\n",
      "     40      \u001B[36m378.4174\u001B[0m      \u001B[32m442.1400\u001B[0m  0.0001  0.1181\n",
      "     41      \u001B[36m378.4161\u001B[0m      \u001B[32m442.1390\u001B[0m  0.0001  0.1034\n",
      "     42      378.4163      \u001B[32m442.1381\u001B[0m  0.0001  0.1084\n",
      "     43      \u001B[36m378.4156\u001B[0m      \u001B[32m442.1372\u001B[0m  0.0001  0.1380\n",
      "     44      \u001B[36m378.4154\u001B[0m      \u001B[32m442.1364\u001B[0m  0.0001  0.1422\n",
      "     45      \u001B[36m378.4151\u001B[0m      \u001B[32m442.1356\u001B[0m  0.0001  0.1454\n",
      "     46      \u001B[36m378.4146\u001B[0m      \u001B[32m442.1349\u001B[0m  0.0001  0.1105\n",
      "     47      \u001B[36m378.4144\u001B[0m      \u001B[32m442.1343\u001B[0m  0.0001  0.1011\n",
      "     48      \u001B[36m378.4144\u001B[0m      \u001B[32m442.1338\u001B[0m  0.0001  0.0994\n",
      "     49      \u001B[36m378.4142\u001B[0m      \u001B[32m442.1333\u001B[0m  0.0001  0.1029\n",
      "     50      \u001B[36m378.4135\u001B[0m      \u001B[32m442.1329\u001B[0m  0.0001  0.1124\n",
      "     51      \u001B[36m378.4130\u001B[0m      \u001B[32m442.1325\u001B[0m  0.0001  0.0964\n",
      "     52      378.4134      \u001B[32m442.1321\u001B[0m  0.0001  0.1114\n",
      "     53      \u001B[36m378.4127\u001B[0m      \u001B[32m442.1317\u001B[0m  0.0001  0.0966\n",
      "     54      378.4131      \u001B[32m442.1314\u001B[0m  0.0001  0.1027\n",
      "     55      378.4128      \u001B[32m442.1310\u001B[0m  0.0001  0.0936\n",
      "     56      \u001B[36m378.4125\u001B[0m      \u001B[32m442.1307\u001B[0m  0.0001  0.0918\n",
      "     57      378.4125      \u001B[32m442.1304\u001B[0m  0.0001  0.1055\n",
      "     58      \u001B[36m378.4118\u001B[0m      \u001B[32m442.1302\u001B[0m  0.0001  0.0989\n",
      "     59      378.4118      \u001B[32m442.1299\u001B[0m  0.0001  0.1076\n",
      "     60      378.4122      \u001B[32m442.1295\u001B[0m  0.0001  0.1152\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m379.8619\u001B[0m      \u001B[32m430.7678\u001B[0m  0.0001  0.0926\n",
      "      2      \u001B[36m379.8355\u001B[0m      \u001B[32m430.7581\u001B[0m  0.0001  0.0940\n",
      "      3      \u001B[36m379.8115\u001B[0m      \u001B[32m430.7404\u001B[0m  0.0001  0.0933\n",
      "      4      \u001B[36m379.7876\u001B[0m      \u001B[32m430.7202\u001B[0m  0.0001  0.0853\n",
      "      5      \u001B[36m379.7650\u001B[0m      \u001B[32m430.6993\u001B[0m  0.0001  0.1006\n",
      "      6      \u001B[36m379.7411\u001B[0m      \u001B[32m430.6781\u001B[0m  0.0001  0.0919\n",
      "      7      \u001B[36m379.7192\u001B[0m      \u001B[32m430.6570\u001B[0m  0.0001  0.0960\n",
      "      8      \u001B[36m379.6977\u001B[0m      \u001B[32m430.6360\u001B[0m  0.0001  0.1119\n",
      "      9      \u001B[36m379.6748\u001B[0m      \u001B[32m430.6153\u001B[0m  0.0001  0.1021\n",
      "     10      \u001B[36m379.6521\u001B[0m      \u001B[32m430.5944\u001B[0m  0.0001  0.1179\n",
      "     11      \u001B[36m379.6259\u001B[0m      \u001B[32m430.5736\u001B[0m  0.0001  0.0899\n",
      "     12      \u001B[36m379.6111\u001B[0m      \u001B[32m430.5528\u001B[0m  0.0001  0.1062\n",
      "     13      \u001B[36m379.5887\u001B[0m      \u001B[32m430.5317\u001B[0m  0.0001  0.1186\n",
      "     14      \u001B[36m379.5591\u001B[0m      \u001B[32m430.5115\u001B[0m  0.0001  0.1141\n",
      "     15      \u001B[36m379.5403\u001B[0m      \u001B[32m430.4922\u001B[0m  0.0001  0.1686\n",
      "     16      \u001B[36m379.5208\u001B[0m      \u001B[32m430.4734\u001B[0m  0.0001  0.1309\n",
      "     17      \u001B[36m379.4997\u001B[0m      \u001B[32m430.4554\u001B[0m  0.0001  0.1253\n",
      "     18      \u001B[36m379.4865\u001B[0m      \u001B[32m430.4384\u001B[0m  0.0001  0.1221\n",
      "     19      \u001B[36m379.4669\u001B[0m      \u001B[32m430.4230\u001B[0m  0.0001  0.1175\n",
      "     20      \u001B[36m379.4515\u001B[0m      \u001B[32m430.4090\u001B[0m  0.0001  0.1047\n",
      "     21      \u001B[36m379.4371\u001B[0m      \u001B[32m430.3957\u001B[0m  0.0001  0.1118\n",
      "     22      \u001B[36m379.4266\u001B[0m      \u001B[32m430.3838\u001B[0m  0.0001  0.1002\n",
      "     23      \u001B[36m379.4104\u001B[0m      \u001B[32m430.3730\u001B[0m  0.0001  0.1033\n",
      "     24      \u001B[36m379.4044\u001B[0m      \u001B[32m430.3638\u001B[0m  0.0001  0.1013\n",
      "     25      \u001B[36m379.3938\u001B[0m      \u001B[32m430.3552\u001B[0m  0.0001  0.0883\n",
      "     26      \u001B[36m379.3872\u001B[0m      \u001B[32m430.3473\u001B[0m  0.0001  0.1001\n",
      "     27      \u001B[36m379.3795\u001B[0m      \u001B[32m430.3404\u001B[0m  0.0001  0.0933\n",
      "     28      \u001B[36m379.3775\u001B[0m      \u001B[32m430.3342\u001B[0m  0.0001  0.0839\n",
      "     29      \u001B[36m379.3707\u001B[0m      \u001B[32m430.3285\u001B[0m  0.0001  0.1064\n",
      "     30      \u001B[36m379.3669\u001B[0m      \u001B[32m430.3235\u001B[0m  0.0001  0.0917\n",
      "     31      \u001B[36m379.3640\u001B[0m      \u001B[32m430.3190\u001B[0m  0.0001  0.0943\n",
      "     32      \u001B[36m379.3604\u001B[0m      \u001B[32m430.3149\u001B[0m  0.0001  0.1080\n",
      "     33      \u001B[36m379.3566\u001B[0m      \u001B[32m430.3113\u001B[0m  0.0001  0.1016\n",
      "     34      \u001B[36m379.3560\u001B[0m      \u001B[32m430.3084\u001B[0m  0.0001  0.1131\n",
      "     35      \u001B[36m379.3517\u001B[0m      \u001B[32m430.3054\u001B[0m  0.0001  0.1098\n",
      "     36      \u001B[36m379.3499\u001B[0m      \u001B[32m430.3025\u001B[0m  0.0001  0.1023\n",
      "     37      \u001B[36m379.3489\u001B[0m      \u001B[32m430.2999\u001B[0m  0.0001  0.1118\n",
      "     38      \u001B[36m379.3470\u001B[0m      \u001B[32m430.2977\u001B[0m  0.0001  0.0971\n",
      "     39      \u001B[36m379.3470\u001B[0m      \u001B[32m430.2957\u001B[0m  0.0001  0.1051\n",
      "     40      \u001B[36m379.3451\u001B[0m      \u001B[32m430.2936\u001B[0m  0.0001  0.1016\n",
      "     41      \u001B[36m379.3435\u001B[0m      \u001B[32m430.2917\u001B[0m  0.0001  0.0921\n",
      "     42      379.3447      \u001B[32m430.2899\u001B[0m  0.0001  0.1313\n",
      "     43      \u001B[36m379.3417\u001B[0m      \u001B[32m430.2883\u001B[0m  0.0001  0.1173\n",
      "     44      \u001B[36m379.3413\u001B[0m      \u001B[32m430.2867\u001B[0m  0.0001  0.1179\n",
      "     45      \u001B[36m379.3412\u001B[0m      \u001B[32m430.2854\u001B[0m  0.0001  0.1012\n",
      "     46      \u001B[36m379.3388\u001B[0m      \u001B[32m430.2841\u001B[0m  0.0001  0.1095\n",
      "     47      \u001B[36m379.3379\u001B[0m      \u001B[32m430.2828\u001B[0m  0.0001  0.1009\n",
      "     48      379.3387      \u001B[32m430.2817\u001B[0m  0.0001  0.1063\n",
      "     49      \u001B[36m379.3371\u001B[0m      \u001B[32m430.2806\u001B[0m  0.0001  0.1133\n",
      "     50      \u001B[36m379.3366\u001B[0m      \u001B[32m430.2798\u001B[0m  0.0001  0.0972\n",
      "     51      \u001B[36m379.3365\u001B[0m      \u001B[32m430.2790\u001B[0m  0.0001  0.1097\n",
      "     52      \u001B[36m379.3354\u001B[0m      \u001B[32m430.2782\u001B[0m  0.0001  0.0913\n",
      "     53      379.3360      \u001B[32m430.2775\u001B[0m  0.0001  0.0948\n",
      "     54      \u001B[36m379.3347\u001B[0m      \u001B[32m430.2767\u001B[0m  0.0001  0.1848\n",
      "     55      \u001B[36m379.3347\u001B[0m      \u001B[32m430.2760\u001B[0m  0.0001  0.1770\n",
      "     56      379.3350      \u001B[32m430.2752\u001B[0m  0.0001  0.1455\n",
      "     57      \u001B[36m379.3341\u001B[0m      \u001B[32m430.2746\u001B[0m  0.0001  0.1367\n",
      "     58      \u001B[36m379.3336\u001B[0m      \u001B[32m430.2742\u001B[0m  0.0001  0.1243\n",
      "     59      \u001B[36m379.3331\u001B[0m      \u001B[32m430.2737\u001B[0m  0.0001  0.1216\n",
      "     60      379.3337      \u001B[32m430.2730\u001B[0m  0.0001  0.1849\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m372.4976\u001B[0m      \u001B[32m436.8952\u001B[0m  0.0001  0.1862\n",
      "      2      \u001B[36m372.4774\u001B[0m      \u001B[32m436.8723\u001B[0m  0.0001  0.1510\n",
      "      3      \u001B[36m372.4507\u001B[0m      \u001B[32m436.8517\u001B[0m  0.0001  0.1338\n",
      "      4      \u001B[36m372.4313\u001B[0m      \u001B[32m436.8332\u001B[0m  0.0001  0.1154\n",
      "      5      \u001B[36m372.4071\u001B[0m      \u001B[32m436.8149\u001B[0m  0.0001  0.0974\n",
      "      6      \u001B[36m372.3855\u001B[0m      \u001B[32m436.7965\u001B[0m  0.0001  0.1070\n",
      "      7      \u001B[36m372.3613\u001B[0m      \u001B[32m436.7770\u001B[0m  0.0001  0.0947\n",
      "      8      \u001B[36m372.3408\u001B[0m      \u001B[32m436.7577\u001B[0m  0.0001  0.0993\n",
      "      9      \u001B[36m372.3179\u001B[0m      \u001B[32m436.7390\u001B[0m  0.0001  0.1257\n",
      "     10      \u001B[36m372.2948\u001B[0m      \u001B[32m436.7199\u001B[0m  0.0001  0.1216\n",
      "     11      \u001B[36m372.2704\u001B[0m      \u001B[32m436.7012\u001B[0m  0.0001  0.1309\n",
      "     12      \u001B[36m372.2504\u001B[0m      \u001B[32m436.6822\u001B[0m  0.0001  0.1136\n",
      "     13      \u001B[36m372.2340\u001B[0m      \u001B[32m436.6644\u001B[0m  0.0001  0.1104\n",
      "     14      \u001B[36m372.2136\u001B[0m      \u001B[32m436.6477\u001B[0m  0.0001  0.1064\n",
      "     15      \u001B[36m372.1984\u001B[0m      \u001B[32m436.6330\u001B[0m  0.0001  0.1035\n",
      "     16      \u001B[36m372.1809\u001B[0m      \u001B[32m436.6184\u001B[0m  0.0001  0.1077\n",
      "     17      \u001B[36m372.1675\u001B[0m      \u001B[32m436.6053\u001B[0m  0.0001  0.0958\n",
      "     18      \u001B[36m372.1577\u001B[0m      \u001B[32m436.5937\u001B[0m  0.0001  0.1156\n",
      "     19      \u001B[36m372.1491\u001B[0m      \u001B[32m436.5836\u001B[0m  0.0001  0.0926\n",
      "     20      \u001B[36m372.1384\u001B[0m      \u001B[32m436.5751\u001B[0m  0.0001  0.0884\n",
      "     21      \u001B[36m372.1348\u001B[0m      \u001B[32m436.5672\u001B[0m  0.0001  0.1016\n",
      "     22      \u001B[36m372.1272\u001B[0m      \u001B[32m436.5601\u001B[0m  0.0001  0.0913\n",
      "     23      \u001B[36m372.1206\u001B[0m      \u001B[32m436.5537\u001B[0m  0.0001  0.0917\n",
      "     24      \u001B[36m372.1148\u001B[0m      \u001B[32m436.5485\u001B[0m  0.0001  0.1035\n",
      "     25      \u001B[36m372.1130\u001B[0m      \u001B[32m436.5437\u001B[0m  0.0001  0.0933\n",
      "     26      \u001B[36m372.1096\u001B[0m      \u001B[32m436.5391\u001B[0m  0.0001  0.0971\n",
      "     27      \u001B[36m372.1061\u001B[0m      \u001B[32m436.5348\u001B[0m  0.0001  0.1019\n",
      "     28      \u001B[36m372.1047\u001B[0m      \u001B[32m436.5313\u001B[0m  0.0001  0.1012\n",
      "     29      \u001B[36m372.1038\u001B[0m      \u001B[32m436.5281\u001B[0m  0.0001  0.1427\n",
      "     30      \u001B[36m372.1015\u001B[0m      \u001B[32m436.5254\u001B[0m  0.0001  0.0981\n",
      "     31      \u001B[36m372.0998\u001B[0m      \u001B[32m436.5228\u001B[0m  0.0001  0.1128\n",
      "     32      \u001B[36m372.0980\u001B[0m      \u001B[32m436.5203\u001B[0m  0.0001  0.0960\n",
      "     33      \u001B[36m372.0966\u001B[0m      \u001B[32m436.5180\u001B[0m  0.0001  0.0922\n",
      "     34      \u001B[36m372.0951\u001B[0m      \u001B[32m436.5160\u001B[0m  0.0001  0.1025\n",
      "     35      \u001B[36m372.0932\u001B[0m      \u001B[32m436.5143\u001B[0m  0.0001  0.0941\n",
      "     36      372.0934      \u001B[32m436.5125\u001B[0m  0.0001  0.1072\n",
      "     37      \u001B[36m372.0916\u001B[0m      \u001B[32m436.5110\u001B[0m  0.0001  0.1006\n",
      "     38      \u001B[36m372.0914\u001B[0m      \u001B[32m436.5095\u001B[0m  0.0001  0.0929\n",
      "     39      \u001B[36m372.0907\u001B[0m      \u001B[32m436.5082\u001B[0m  0.0001  0.1078\n",
      "     40      \u001B[36m372.0902\u001B[0m      \u001B[32m436.5070\u001B[0m  0.0001  0.0933\n",
      "     41      \u001B[36m372.0899\u001B[0m      \u001B[32m436.5060\u001B[0m  0.0001  0.0961\n",
      "     42      \u001B[36m372.0894\u001B[0m      \u001B[32m436.5050\u001B[0m  0.0001  0.1059\n",
      "     43      \u001B[36m372.0890\u001B[0m      \u001B[32m436.5041\u001B[0m  0.0001  0.1065\n",
      "     44      \u001B[36m372.0883\u001B[0m      \u001B[32m436.5031\u001B[0m  0.0001  0.1125\n",
      "     45      \u001B[36m372.0880\u001B[0m      \u001B[32m436.5024\u001B[0m  0.0001  0.0986\n",
      "     46      \u001B[36m372.0876\u001B[0m      \u001B[32m436.5016\u001B[0m  0.0001  0.1091\n",
      "     47      \u001B[36m372.0867\u001B[0m      \u001B[32m436.5009\u001B[0m  0.0001  0.0970\n",
      "     48      \u001B[36m372.0866\u001B[0m      \u001B[32m436.5005\u001B[0m  0.0001  0.1008\n",
      "     49      \u001B[36m372.0865\u001B[0m      \u001B[32m436.5000\u001B[0m  0.0001  0.1099\n",
      "     50      372.0867      \u001B[32m436.4996\u001B[0m  0.0001  0.1015\n",
      "     51      \u001B[36m372.0863\u001B[0m      \u001B[32m436.4992\u001B[0m  0.0001  0.1021\n",
      "     52      \u001B[36m372.0861\u001B[0m      \u001B[32m436.4987\u001B[0m  0.0001  0.1097\n",
      "     53      \u001B[36m372.0859\u001B[0m      \u001B[32m436.4983\u001B[0m  0.0001  0.0969\n",
      "     54      \u001B[36m372.0850\u001B[0m      \u001B[32m436.4979\u001B[0m  0.0001  0.1131\n",
      "     55      372.0854      \u001B[32m436.4975\u001B[0m  0.0001  0.0983\n",
      "     56      372.0856      \u001B[32m436.4972\u001B[0m  0.0001  0.0959\n",
      "     57      \u001B[36m372.0847\u001B[0m      \u001B[32m436.4969\u001B[0m  0.0001  0.1131\n",
      "     58      372.0850      \u001B[32m436.4966\u001B[0m  0.0001  0.0955\n",
      "     59      \u001B[36m372.0847\u001B[0m      \u001B[32m436.4962\u001B[0m  0.0001  0.1110\n",
      "     60      372.0847      \u001B[32m436.4959\u001B[0m  0.0001  0.0942\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m368.8273\u001B[0m      \u001B[32m441.3108\u001B[0m  0.0010  0.0897\n",
      "      2      \u001B[36m368.6455\u001B[0m      \u001B[32m441.1554\u001B[0m  0.0010  0.1031\n",
      "      3      \u001B[36m368.5104\u001B[0m      \u001B[32m441.0731\u001B[0m  0.0010  0.0896\n",
      "      4      \u001B[36m368.4428\u001B[0m      \u001B[32m441.0396\u001B[0m  0.0010  0.0907\n",
      "      5      \u001B[36m368.4253\u001B[0m      \u001B[32m441.0275\u001B[0m  0.0010  0.1001\n",
      "      6      \u001B[36m368.4190\u001B[0m      \u001B[32m441.0222\u001B[0m  0.0010  0.0871\n",
      "      7      \u001B[36m368.4179\u001B[0m      \u001B[32m441.0191\u001B[0m  0.0010  0.0913\n",
      "      8      \u001B[36m368.4165\u001B[0m      \u001B[32m441.0170\u001B[0m  0.0010  0.0925\n",
      "      9      \u001B[36m368.4160\u001B[0m      \u001B[32m441.0155\u001B[0m  0.0010  0.0920\n",
      "     10      \u001B[36m368.4146\u001B[0m      \u001B[32m441.0145\u001B[0m  0.0010  0.1157\n",
      "     11      \u001B[36m368.4144\u001B[0m      \u001B[32m441.0139\u001B[0m  0.0010  0.1070\n",
      "     12      \u001B[36m368.4143\u001B[0m      \u001B[32m441.0135\u001B[0m  0.0010  0.0970\n",
      "     13      \u001B[36m368.4141\u001B[0m      \u001B[32m441.0130\u001B[0m  0.0010  0.1126\n",
      "     14      \u001B[36m368.4138\u001B[0m      \u001B[32m441.0127\u001B[0m  0.0010  0.1065\n",
      "     15      \u001B[36m368.4136\u001B[0m      \u001B[32m441.0124\u001B[0m  0.0010  0.1064\n",
      "     16      368.4137      \u001B[32m441.0122\u001B[0m  0.0010  0.1075\n",
      "     17      \u001B[36m368.4134\u001B[0m      \u001B[32m441.0119\u001B[0m  0.0010  0.0917\n",
      "     18      \u001B[36m368.4134\u001B[0m      \u001B[32m441.0117\u001B[0m  0.0010  0.1037\n",
      "     19      \u001B[36m368.4133\u001B[0m      \u001B[32m441.0115\u001B[0m  0.0010  0.0976\n",
      "     20      \u001B[36m368.4132\u001B[0m      \u001B[32m441.0114\u001B[0m  0.0010  0.1167\n",
      "     21      368.4133      \u001B[32m441.0113\u001B[0m  0.0010  0.1019\n",
      "     22      368.4134      \u001B[32m441.0112\u001B[0m  0.0007  0.0885\n",
      "     23      368.4132      \u001B[32m441.0111\u001B[0m  0.0007  0.0969\n",
      "     24      368.4132      \u001B[32m441.0111\u001B[0m  0.0007  0.0959\n",
      "     25      368.4132      \u001B[32m441.0110\u001B[0m  0.0007  0.1236\n",
      "     26      \u001B[36m368.4131\u001B[0m      \u001B[32m441.0110\u001B[0m  0.0007  0.1112\n",
      "     27      \u001B[36m368.4130\u001B[0m      \u001B[32m441.0109\u001B[0m  0.0007  0.0938\n",
      "     28      368.4132      \u001B[32m441.0109\u001B[0m  0.0007  0.0954\n",
      "     29      368.4133      \u001B[32m441.0108\u001B[0m  0.0007  0.0961\n",
      "     30      368.4131      \u001B[32m441.0107\u001B[0m  0.0007  0.0873\n",
      "     31      368.4130      \u001B[32m441.0106\u001B[0m  0.0007  0.1183\n",
      "     32      368.4131      \u001B[32m441.0106\u001B[0m  0.0007  0.1287\n",
      "     33      368.4130      \u001B[32m441.0105\u001B[0m  0.0007  0.1336\n",
      "     34      368.4130      \u001B[32m441.0105\u001B[0m  0.0007  0.1119\n",
      "     35      \u001B[36m368.4129\u001B[0m      \u001B[32m441.0105\u001B[0m  0.0007  0.1165\n",
      "     36      \u001B[36m368.4129\u001B[0m      \u001B[32m441.0104\u001B[0m  0.0007  0.1106\n",
      "     37      368.4130      \u001B[32m441.0104\u001B[0m  0.0007  0.1145\n",
      "     38      368.4130      \u001B[32m441.0104\u001B[0m  0.0005  0.1024\n",
      "     39      \u001B[36m368.4129\u001B[0m      \u001B[32m441.0103\u001B[0m  0.0005  0.0991\n",
      "     40      368.4130      \u001B[32m441.0103\u001B[0m  0.0005  0.1693\n",
      "     41      368.4129      \u001B[32m441.0103\u001B[0m  0.0005  0.1521\n",
      "     42      368.4130      \u001B[32m441.0103\u001B[0m  0.0005  0.1263\n",
      "     43      368.4129      \u001B[32m441.0103\u001B[0m  0.0005  0.1244\n",
      "     44      368.4129      \u001B[32m441.0103\u001B[0m  0.0005  0.1243\n",
      "     45      \u001B[36m368.4129\u001B[0m      \u001B[32m441.0102\u001B[0m  0.0005  0.1236\n",
      "     46      368.4129      \u001B[32m441.0102\u001B[0m  0.0005  0.1096\n",
      "     47      368.4130      \u001B[32m441.0102\u001B[0m  0.0005  0.1096\n",
      "     48      368.4129      \u001B[32m441.0102\u001B[0m  0.0005  0.1256\n",
      "     49      368.4129      441.0102  0.0005  0.1129\n",
      "     50      \u001B[36m368.4129\u001B[0m      441.0102  0.0005  0.1117\n",
      "     51      \u001B[36m368.4128\u001B[0m      \u001B[32m441.0101\u001B[0m  0.0005  0.0989\n",
      "     52      368.4129      441.0101  0.0005  0.0998\n",
      "     53      368.4129      \u001B[32m441.0101\u001B[0m  0.0005  0.1250\n",
      "     54      \u001B[36m368.4128\u001B[0m      441.0101  0.0003  0.1237\n",
      "     55      \u001B[36m368.4128\u001B[0m      441.0101  0.0003  0.1315\n",
      "     56      368.4130      \u001B[32m441.0101\u001B[0m  0.0003  0.1035\n",
      "     57      368.4128      441.0101  0.0003  0.1199\n",
      "     58      368.4129      \u001B[32m441.0101\u001B[0m  0.0003  0.1082\n",
      "     59      368.4128      \u001B[32m441.0101\u001B[0m  0.0003  0.1102\n",
      "     60      368.4128      441.0101  0.0003  0.1005\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m383.2551\u001B[0m      \u001B[32m422.5106\u001B[0m  0.0010  0.0824\n",
      "      2      \u001B[36m383.0889\u001B[0m      \u001B[32m422.3863\u001B[0m  0.0010  0.1152\n",
      "      3      \u001B[36m383.0025\u001B[0m      \u001B[32m422.3396\u001B[0m  0.0010  0.0987\n",
      "      4      \u001B[36m382.9737\u001B[0m      \u001B[32m422.3241\u001B[0m  0.0010  0.1124\n",
      "      5      \u001B[36m382.9668\u001B[0m      \u001B[32m422.3181\u001B[0m  0.0010  0.0917\n",
      "      6      \u001B[36m382.9645\u001B[0m      \u001B[32m422.3153\u001B[0m  0.0010  0.0937\n",
      "      7      \u001B[36m382.9629\u001B[0m      \u001B[32m422.3137\u001B[0m  0.0010  0.1182\n",
      "      8      \u001B[36m382.9618\u001B[0m      \u001B[32m422.3128\u001B[0m  0.0010  0.1044\n",
      "      9      \u001B[36m382.9612\u001B[0m      \u001B[32m422.3121\u001B[0m  0.0010  0.1196\n",
      "     10      382.9613      \u001B[32m422.3117\u001B[0m  0.0010  0.0996\n",
      "     11      382.9615      \u001B[32m422.3113\u001B[0m  0.0010  0.0924\n",
      "     12      \u001B[36m382.9608\u001B[0m      \u001B[32m422.3109\u001B[0m  0.0010  0.1058\n",
      "     13      382.9609      \u001B[32m422.3106\u001B[0m  0.0010  0.1069\n",
      "     14      \u001B[36m382.9606\u001B[0m      \u001B[32m422.3103\u001B[0m  0.0010  0.1220\n",
      "     15      \u001B[36m382.9606\u001B[0m      \u001B[32m422.3102\u001B[0m  0.0010  0.1020\n",
      "     16      \u001B[36m382.9606\u001B[0m      \u001B[32m422.3100\u001B[0m  0.0010  0.0985\n",
      "     17      \u001B[36m382.9603\u001B[0m      \u001B[32m422.3099\u001B[0m  0.0010  0.1425\n",
      "     18      382.9604      \u001B[32m422.3098\u001B[0m  0.0010  0.1075\n",
      "     19      382.9606      \u001B[32m422.3097\u001B[0m  0.0010  0.1083\n",
      "     20      382.9605      \u001B[32m422.3096\u001B[0m  0.0007  0.0871\n",
      "     21      382.9604      \u001B[32m422.3095\u001B[0m  0.0007  0.1006\n",
      "     22      \u001B[36m382.9602\u001B[0m      \u001B[32m422.3095\u001B[0m  0.0007  0.1312\n",
      "     23      382.9603      \u001B[32m422.3094\u001B[0m  0.0007  0.1005\n",
      "     24      382.9604      \u001B[32m422.3094\u001B[0m  0.0007  0.1086\n",
      "     25      382.9603      \u001B[32m422.3093\u001B[0m  0.0007  0.1098\n",
      "     26      382.9603      \u001B[32m422.3093\u001B[0m  0.0007  0.1281\n",
      "     27      382.9603      \u001B[32m422.3093\u001B[0m  0.0007  0.1260\n",
      "     28      382.9603      \u001B[32m422.3092\u001B[0m  0.0007  0.1329\n",
      "     29      \u001B[36m382.9602\u001B[0m      \u001B[32m422.3092\u001B[0m  0.0007  0.1212\n",
      "     30      \u001B[36m382.9602\u001B[0m      \u001B[32m422.3091\u001B[0m  0.0007  0.1216\n",
      "     31      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3091\u001B[0m  0.0007  0.1022\n",
      "     32      382.9602      \u001B[32m422.3091\u001B[0m  0.0007  0.1037\n",
      "     33      382.9601      \u001B[32m422.3090\u001B[0m  0.0007  0.1333\n",
      "     34      382.9602      422.3090  0.0007  0.1198\n",
      "     35      382.9602      \u001B[32m422.3090\u001B[0m  0.0007  0.1253\n",
      "     36      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3090\u001B[0m  0.0005  0.1156\n",
      "     37      382.9601      422.3090  0.0005  0.1213\n",
      "     38      382.9602      \u001B[32m422.3090\u001B[0m  0.0005  0.1258\n",
      "     39      382.9602      \u001B[32m422.3090\u001B[0m  0.0005  0.1210\n",
      "     40      382.9602      \u001B[32m422.3089\u001B[0m  0.0005  0.1119\n",
      "     41      382.9602      \u001B[32m422.3089\u001B[0m  0.0005  0.1301\n",
      "     42      382.9602      \u001B[32m422.3089\u001B[0m  0.0005  0.1106\n",
      "     43      382.9602      \u001B[32m422.3089\u001B[0m  0.0005  0.1037\n",
      "     44      382.9602      \u001B[32m422.3089\u001B[0m  0.0005  0.1554\n",
      "     45      382.9601      \u001B[32m422.3089\u001B[0m  0.0005  0.1212\n",
      "     46      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3089\u001B[0m  0.0005  0.1120\n",
      "     47      382.9601      422.3089  0.0005  0.1099\n",
      "     48      382.9601      \u001B[32m422.3088\u001B[0m  0.0005  0.1187\n",
      "     49      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3088\u001B[0m  0.0005  0.1197\n",
      "     50      382.9602      \u001B[32m422.3088\u001B[0m  0.0005  0.1306\n",
      "     51      \u001B[36m382.9601\u001B[0m      \u001B[32m422.3088\u001B[0m  0.0005  0.1159\n",
      "     52      382.9601      422.3088  0.0003  0.1119\n",
      "     53      382.9601      \u001B[32m422.3088\u001B[0m  0.0003  0.1016\n",
      "     54      382.9601      \u001B[32m422.3088\u001B[0m  0.0003  0.0925\n",
      "     55      382.9601      422.3088  0.0003  0.1325\n",
      "     56      382.9601      \u001B[32m422.3088\u001B[0m  0.0003  0.1028\n",
      "     57      382.9601      \u001B[32m422.3087\u001B[0m  0.0003  0.1154\n",
      "     58      382.9602      422.3087  0.0003  0.1074\n",
      "     59      382.9601      422.3087  0.0003  0.1096\n",
      "     60      382.9601      422.3087  0.0003  0.1068\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m378.9541\u001B[0m      \u001B[32m432.9456\u001B[0m  0.0010  0.0884\n",
      "      2      \u001B[36m378.7788\u001B[0m      \u001B[32m432.8097\u001B[0m  0.0010  0.1253\n",
      "      3      \u001B[36m378.6726\u001B[0m      \u001B[32m432.7534\u001B[0m  0.0010  0.1017\n",
      "      4      \u001B[36m378.6261\u001B[0m      \u001B[32m432.7327\u001B[0m  0.0010  0.1048\n",
      "      5      \u001B[36m378.6152\u001B[0m      \u001B[32m432.7245\u001B[0m  0.0010  0.1119\n",
      "      6      \u001B[36m378.6108\u001B[0m      \u001B[32m432.7206\u001B[0m  0.0010  0.0944\n",
      "      7      \u001B[36m378.6096\u001B[0m      \u001B[32m432.7184\u001B[0m  0.0010  0.1185\n",
      "      8      \u001B[36m378.6079\u001B[0m      \u001B[32m432.7170\u001B[0m  0.0010  0.1025\n",
      "      9      \u001B[36m378.6068\u001B[0m      \u001B[32m432.7160\u001B[0m  0.0010  0.1199\n",
      "     10      \u001B[36m378.6065\u001B[0m      \u001B[32m432.7152\u001B[0m  0.0010  0.1176\n",
      "     11      \u001B[36m378.6064\u001B[0m      \u001B[32m432.7145\u001B[0m  0.0010  0.1159\n",
      "     12      \u001B[36m378.6057\u001B[0m      \u001B[32m432.7140\u001B[0m  0.0010  0.0989\n",
      "     13      378.6060      \u001B[32m432.7136\u001B[0m  0.0010  0.0911\n",
      "     14      \u001B[36m378.6056\u001B[0m      \u001B[32m432.7134\u001B[0m  0.0010  0.1018\n",
      "     15      \u001B[36m378.6055\u001B[0m      \u001B[32m432.7131\u001B[0m  0.0010  0.1021\n",
      "     16      \u001B[36m378.6054\u001B[0m      \u001B[32m432.7129\u001B[0m  0.0010  0.0952\n",
      "     17      \u001B[36m378.6053\u001B[0m      \u001B[32m432.7128\u001B[0m  0.0010  0.1129\n",
      "     18      378.6053      \u001B[32m432.7127\u001B[0m  0.0010  0.0907\n",
      "     19      \u001B[36m378.6052\u001B[0m      \u001B[32m432.7125\u001B[0m  0.0010  0.0994\n",
      "     20      378.6052      \u001B[32m432.7124\u001B[0m  0.0007  0.0986\n",
      "     21      \u001B[36m378.6051\u001B[0m      \u001B[32m432.7122\u001B[0m  0.0007  0.0886\n",
      "     22      378.6051      \u001B[32m432.7122\u001B[0m  0.0007  0.1018\n",
      "     23      \u001B[36m378.6050\u001B[0m      \u001B[32m432.7121\u001B[0m  0.0007  0.0890\n",
      "     24      378.6051      \u001B[32m432.7120\u001B[0m  0.0007  0.0831\n",
      "     25      378.6051      \u001B[32m432.7119\u001B[0m  0.0007  0.1004\n",
      "     26      \u001B[36m378.6050\u001B[0m      \u001B[32m432.7119\u001B[0m  0.0007  0.0878\n",
      "     27      \u001B[36m378.6050\u001B[0m      \u001B[32m432.7118\u001B[0m  0.0007  0.0866\n",
      "     28      \u001B[36m378.6049\u001B[0m      \u001B[32m432.7117\u001B[0m  0.0007  0.1076\n",
      "     29      378.6050      \u001B[32m432.7117\u001B[0m  0.0007  0.0892\n",
      "     30      378.6049      \u001B[32m432.7116\u001B[0m  0.0007  0.0950\n",
      "     31      \u001B[36m378.6049\u001B[0m      \u001B[32m432.7116\u001B[0m  0.0007  0.1063\n",
      "     32      \u001B[36m378.6049\u001B[0m      \u001B[32m432.7116\u001B[0m  0.0007  0.0966\n",
      "     33      378.6049      \u001B[32m432.7115\u001B[0m  0.0007  0.1150\n",
      "     34      378.6050      \u001B[32m432.7115\u001B[0m  0.0007  0.1057\n",
      "     35      378.6050      \u001B[32m432.7114\u001B[0m  0.0007  0.1139\n",
      "     36      \u001B[36m378.6049\u001B[0m      \u001B[32m432.7113\u001B[0m  0.0005  0.1067\n",
      "     37      378.6049      \u001B[32m432.7113\u001B[0m  0.0005  0.1078\n",
      "     38      378.6049      \u001B[32m432.7113\u001B[0m  0.0005  0.1250\n",
      "     39      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7113\u001B[0m  0.0005  0.1015\n",
      "     40      378.6049      \u001B[32m432.7113\u001B[0m  0.0005  0.1174\n",
      "     41      378.6048      \u001B[32m432.7112\u001B[0m  0.0005  0.1263\n",
      "     42      378.6048      \u001B[32m432.7112\u001B[0m  0.0005  0.1532\n",
      "     43      378.6048      \u001B[32m432.7112\u001B[0m  0.0005  0.1274\n",
      "     44      378.6049      \u001B[32m432.7112\u001B[0m  0.0005  0.1234\n",
      "     45      378.6048      \u001B[32m432.7111\u001B[0m  0.0005  0.1095\n",
      "     46      378.6048      \u001B[32m432.7111\u001B[0m  0.0005  0.1302\n",
      "     47      378.6048      \u001B[32m432.7111\u001B[0m  0.0005  0.1214\n",
      "     48      378.6048      \u001B[32m432.7111\u001B[0m  0.0005  0.1337\n",
      "     49      378.6048      432.7111  0.0005  0.1273\n",
      "     50      378.6048      \u001B[32m432.7111\u001B[0m  0.0005  0.1446\n",
      "     51      378.6049      \u001B[32m432.7111\u001B[0m  0.0005  0.1066\n",
      "     52      378.6049      \u001B[32m432.7111\u001B[0m  0.0003  0.1112\n",
      "     53      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7111\u001B[0m  0.0003  0.1029\n",
      "     54      378.6048      \u001B[32m432.7110\u001B[0m  0.0003  0.1085\n",
      "     55      \u001B[36m378.6048\u001B[0m      \u001B[32m432.7110\u001B[0m  0.0003  0.1248\n",
      "     56      378.6048      432.7110  0.0003  0.1030\n",
      "     57      378.6048      432.7110  0.0003  0.1219\n",
      "     58      378.6048      432.7110  0.0003  0.1203\n",
      "     59      378.6048      \u001B[32m432.7110\u001B[0m  0.0003  0.1475\n",
      "     60      378.6048      432.7110  0.0003  0.1226\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m375.2274\u001B[0m      \u001B[32m458.7751\u001B[0m  0.0010  0.1201\n",
      "      2      \u001B[36m375.0500\u001B[0m      \u001B[32m458.6456\u001B[0m  0.0010  0.1197\n",
      "      3      \u001B[36m374.9702\u001B[0m      \u001B[32m458.6028\u001B[0m  0.0010  0.1158\n",
      "      4      \u001B[36m374.9498\u001B[0m      \u001B[32m458.5901\u001B[0m  0.0010  0.1139\n",
      "      5      \u001B[36m374.9438\u001B[0m      \u001B[32m458.5856\u001B[0m  0.0010  0.1274\n",
      "      6      \u001B[36m374.9424\u001B[0m      \u001B[32m458.5832\u001B[0m  0.0010  0.1240\n",
      "      7      \u001B[36m374.9411\u001B[0m      \u001B[32m458.5817\u001B[0m  0.0010  0.1228\n",
      "      8      \u001B[36m374.9406\u001B[0m      \u001B[32m458.5807\u001B[0m  0.0010  0.1365\n",
      "      9      \u001B[36m374.9403\u001B[0m      \u001B[32m458.5800\u001B[0m  0.0010  0.0977\n",
      "     10      \u001B[36m374.9402\u001B[0m      \u001B[32m458.5794\u001B[0m  0.0010  0.1031\n",
      "     11      \u001B[36m374.9400\u001B[0m      \u001B[32m458.5789\u001B[0m  0.0010  0.0940\n",
      "     12      \u001B[36m374.9396\u001B[0m      \u001B[32m458.5784\u001B[0m  0.0010  0.0958\n",
      "     13      374.9397      \u001B[32m458.5781\u001B[0m  0.0010  0.1375\n",
      "     14      \u001B[36m374.9394\u001B[0m      \u001B[32m458.5778\u001B[0m  0.0010  0.1141\n",
      "     15      374.9395      \u001B[32m458.5777\u001B[0m  0.0010  0.1089\n",
      "     16      \u001B[36m374.9394\u001B[0m      \u001B[32m458.5774\u001B[0m  0.0010  0.1000\n",
      "     17      \u001B[36m374.9393\u001B[0m      \u001B[32m458.5773\u001B[0m  0.0010  0.1040\n",
      "     18      \u001B[36m374.9392\u001B[0m      \u001B[32m458.5771\u001B[0m  0.0010  0.0937\n",
      "     19      374.9393      \u001B[32m458.5770\u001B[0m  0.0010  0.0973\n",
      "     20      \u001B[36m374.9392\u001B[0m      \u001B[32m458.5768\u001B[0m  0.0010  0.1374\n",
      "     21      374.9393      \u001B[32m458.5767\u001B[0m  0.0007  0.1732\n",
      "     22      \u001B[36m374.9392\u001B[0m      \u001B[32m458.5766\u001B[0m  0.0007  0.1494\n",
      "     23      \u001B[36m374.9391\u001B[0m      \u001B[32m458.5766\u001B[0m  0.0007  0.1579\n",
      "     24      \u001B[36m374.9391\u001B[0m      \u001B[32m458.5765\u001B[0m  0.0007  0.1241\n",
      "     25      374.9392      \u001B[32m458.5765\u001B[0m  0.0007  0.1201\n",
      "     26      \u001B[36m374.9391\u001B[0m      \u001B[32m458.5764\u001B[0m  0.0007  0.1010\n",
      "     27      374.9392      \u001B[32m458.5764\u001B[0m  0.0007  0.0976\n",
      "     28      374.9391      \u001B[32m458.5763\u001B[0m  0.0007  0.1122\n",
      "     29      \u001B[36m374.9391\u001B[0m      \u001B[32m458.5762\u001B[0m  0.0007  0.1016\n",
      "     30      374.9391      \u001B[32m458.5762\u001B[0m  0.0007  0.1168\n",
      "     31      \u001B[36m374.9390\u001B[0m      \u001B[32m458.5761\u001B[0m  0.0007  0.1103\n",
      "     32      \u001B[36m374.9390\u001B[0m      \u001B[32m458.5761\u001B[0m  0.0007  0.1193\n",
      "     33      374.9390      \u001B[32m458.5761\u001B[0m  0.0007  0.1088\n",
      "     34      374.9390      \u001B[32m458.5760\u001B[0m  0.0007  0.1090\n",
      "     35      374.9390      \u001B[32m458.5760\u001B[0m  0.0007  0.1247\n",
      "     36      \u001B[36m374.9389\u001B[0m      \u001B[32m458.5760\u001B[0m  0.0007  0.1181\n",
      "     37      374.9389      \u001B[32m458.5759\u001B[0m  0.0005  0.1488\n",
      "     38      374.9390      \u001B[32m458.5759\u001B[0m  0.0005  0.1389\n",
      "     39      374.9390      \u001B[32m458.5759\u001B[0m  0.0005  0.1302\n",
      "     40      374.9389      \u001B[32m458.5759\u001B[0m  0.0005  0.1344\n",
      "     41      374.9389      \u001B[32m458.5758\u001B[0m  0.0005  0.1425\n",
      "     42      374.9390      \u001B[32m458.5758\u001B[0m  0.0005  0.1210\n",
      "     43      374.9390      \u001B[32m458.5758\u001B[0m  0.0005  0.1277\n",
      "     44      374.9390      \u001B[32m458.5758\u001B[0m  0.0005  0.1059\n",
      "     45      374.9390      \u001B[32m458.5757\u001B[0m  0.0005  0.1173\n",
      "     46      374.9390      \u001B[32m458.5757\u001B[0m  0.0005  0.0990\n",
      "     47      \u001B[36m374.9389\u001B[0m      \u001B[32m458.5757\u001B[0m  0.0005  0.1085\n",
      "     48      \u001B[36m374.9389\u001B[0m      \u001B[32m458.5757\u001B[0m  0.0005  0.1268\n",
      "     49      374.9389      \u001B[32m458.5757\u001B[0m  0.0005  0.1101\n",
      "     50      374.9390      \u001B[32m458.5757\u001B[0m  0.0005  0.1129\n",
      "     51      \u001B[36m374.9389\u001B[0m      \u001B[32m458.5757\u001B[0m  0.0005  0.1075\n",
      "     52      \u001B[36m374.9389\u001B[0m      458.5757  0.0005  0.1216\n",
      "     53      374.9389      \u001B[32m458.5757\u001B[0m  0.0003  0.1119\n",
      "     54      374.9389      458.5757  0.0003  0.1246\n",
      "     55      374.9389      \u001B[32m458.5757\u001B[0m  0.0003  0.1022\n",
      "     56      374.9389      458.5757  0.0003  0.1063\n",
      "     57      374.9389      \u001B[32m458.5756\u001B[0m  0.0003  0.1065\n",
      "     58      374.9389      458.5756  0.0003  0.0996\n",
      "     59      374.9389      458.5756  0.0003  0.1242\n",
      "     60      374.9389      \u001B[32m458.5756\u001B[0m  0.0003  0.1002\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m377.7557\u001B[0m      \u001B[32m436.9452\u001B[0m  0.0010  0.1046\n",
      "      2      \u001B[36m377.5871\u001B[0m      \u001B[32m436.8243\u001B[0m  0.0010  0.0944\n",
      "      3      \u001B[36m377.4822\u001B[0m      \u001B[32m436.7680\u001B[0m  0.0010  0.0855\n",
      "      4      \u001B[36m377.4446\u001B[0m      \u001B[32m436.7427\u001B[0m  0.0010  0.1070\n",
      "      5      \u001B[36m377.4330\u001B[0m      \u001B[32m436.7326\u001B[0m  0.0010  0.0962\n",
      "      6      \u001B[36m377.4270\u001B[0m      \u001B[32m436.7272\u001B[0m  0.0010  0.1116\n",
      "      7      \u001B[36m377.4246\u001B[0m      \u001B[32m436.7244\u001B[0m  0.0010  0.1314\n",
      "      8      \u001B[36m377.4229\u001B[0m      \u001B[32m436.7228\u001B[0m  0.0010  0.1146\n",
      "      9      \u001B[36m377.4215\u001B[0m      \u001B[32m436.7217\u001B[0m  0.0010  0.1003\n",
      "     10      377.4220      \u001B[32m436.7208\u001B[0m  0.0010  0.1001\n",
      "     11      \u001B[36m377.4210\u001B[0m      \u001B[32m436.7199\u001B[0m  0.0010  0.1038\n",
      "     12      \u001B[36m377.4207\u001B[0m      \u001B[32m436.7194\u001B[0m  0.0010  0.0982\n",
      "     13      \u001B[36m377.4201\u001B[0m      \u001B[32m436.7188\u001B[0m  0.0010  0.0883\n",
      "     14      377.4207      \u001B[32m436.7184\u001B[0m  0.0010  0.1003\n",
      "     15      \u001B[36m377.4200\u001B[0m      \u001B[32m436.7182\u001B[0m  0.0010  0.1009\n",
      "     16      377.4202      \u001B[32m436.7179\u001B[0m  0.0010  0.0870\n",
      "     17      \u001B[36m377.4199\u001B[0m      \u001B[32m436.7176\u001B[0m  0.0010  0.1123\n",
      "     18      \u001B[36m377.4196\u001B[0m      \u001B[32m436.7174\u001B[0m  0.0010  0.0937\n",
      "     19      377.4197      \u001B[32m436.7171\u001B[0m  0.0010  0.1049\n",
      "     20      377.4196      \u001B[32m436.7170\u001B[0m  0.0010  0.1019\n",
      "     21      377.4197      \u001B[32m436.7168\u001B[0m  0.0010  0.0862\n",
      "     22      377.4196      \u001B[32m436.7166\u001B[0m  0.0010  0.1031\n",
      "     23      \u001B[36m377.4193\u001B[0m      \u001B[32m436.7165\u001B[0m  0.0010  0.0970\n",
      "     24      \u001B[36m377.4193\u001B[0m      \u001B[32m436.7164\u001B[0m  0.0010  0.0879\n",
      "     25      377.4195      \u001B[32m436.7163\u001B[0m  0.0007  0.0969\n",
      "     26      \u001B[36m377.4193\u001B[0m      \u001B[32m436.7163\u001B[0m  0.0007  0.1043\n",
      "     27      \u001B[36m377.4192\u001B[0m      \u001B[32m436.7162\u001B[0m  0.0007  0.1220\n",
      "     28      377.4192      \u001B[32m436.7162\u001B[0m  0.0007  0.1187\n",
      "     29      \u001B[36m377.4191\u001B[0m      \u001B[32m436.7161\u001B[0m  0.0007  0.1102\n",
      "     30      377.4193      \u001B[32m436.7161\u001B[0m  0.0007  0.1068\n",
      "     31      \u001B[36m377.4191\u001B[0m      \u001B[32m436.7160\u001B[0m  0.0007  0.1052\n",
      "     32      377.4193      \u001B[32m436.7160\u001B[0m  0.0007  0.1150\n",
      "     33      377.4192      \u001B[32m436.7160\u001B[0m  0.0007  0.1058\n",
      "     34      \u001B[36m377.4191\u001B[0m      \u001B[32m436.7159\u001B[0m  0.0007  0.1047\n",
      "     35      \u001B[36m377.4191\u001B[0m      \u001B[32m436.7159\u001B[0m  0.0007  0.1015\n",
      "     36      377.4192      \u001B[32m436.7159\u001B[0m  0.0007  0.1075\n",
      "     37      \u001B[36m377.4191\u001B[0m      \u001B[32m436.7158\u001B[0m  0.0007  0.1136\n",
      "     38      377.4192      \u001B[32m436.7158\u001B[0m  0.0007  0.0987\n",
      "     39      \u001B[36m377.4190\u001B[0m      \u001B[32m436.7158\u001B[0m  0.0007  0.1092\n",
      "     40      \u001B[36m377.4190\u001B[0m      \u001B[32m436.7157\u001B[0m  0.0007  0.1056\n",
      "     41      377.4193      \u001B[32m436.7157\u001B[0m  0.0005  0.1062\n",
      "     42      377.4191      436.7157  0.0005  0.1063\n",
      "     43      377.4192      \u001B[32m436.7156\u001B[0m  0.0005  0.1115\n",
      "     44      377.4190      \u001B[32m436.7156\u001B[0m  0.0005  0.1243\n",
      "     45      377.4190      \u001B[32m436.7156\u001B[0m  0.0005  0.1343\n",
      "     46      377.4190      436.7156  0.0005  0.1431\n",
      "     47      377.4190      \u001B[32m436.7156\u001B[0m  0.0005  0.1058\n",
      "     48      377.4190      \u001B[32m436.7156\u001B[0m  0.0005  0.1190\n",
      "     49      377.4191      \u001B[32m436.7156\u001B[0m  0.0005  0.0980\n",
      "     50      377.4190      \u001B[32m436.7156\u001B[0m  0.0005  0.1100\n",
      "     51      377.4190      \u001B[32m436.7156\u001B[0m  0.0005  0.1095\n",
      "     52      377.4190      436.7156  0.0005  0.1023\n",
      "     53      377.4190      \u001B[32m436.7155\u001B[0m  0.0005  0.1102\n",
      "     54      \u001B[36m377.4189\u001B[0m      436.7155  0.0005  0.0971\n",
      "     55      377.4191      \u001B[32m436.7155\u001B[0m  0.0005  0.0968\n",
      "     56      377.4190      436.7155  0.0005  0.1040\n",
      "     57      377.4192      \u001B[32m436.7155\u001B[0m  0.0003  0.0980\n",
      "     58      377.4190      \u001B[32m436.7155\u001B[0m  0.0003  0.1041\n",
      "     59      377.4190      436.7155  0.0003  0.0980\n",
      "     60      377.4190      \u001B[32m436.7154\u001B[0m  0.0003  0.0980\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m377.2040\u001B[0m      \u001B[32m427.0060\u001B[0m  0.0010  0.1023\n",
      "      2      \u001B[36m377.0065\u001B[0m      \u001B[32m426.8493\u001B[0m  0.0010  0.0843\n",
      "      3      \u001B[36m376.8820\u001B[0m      \u001B[32m426.7718\u001B[0m  0.0010  0.0832\n",
      "      4      \u001B[36m376.8325\u001B[0m      \u001B[32m426.7443\u001B[0m  0.0010  0.0983\n",
      "      5      \u001B[36m376.8204\u001B[0m      \u001B[32m426.7345\u001B[0m  0.0010  0.0909\n",
      "      6      \u001B[36m376.8172\u001B[0m      \u001B[32m426.7305\u001B[0m  0.0010  0.0957\n",
      "      7      \u001B[36m376.8154\u001B[0m      \u001B[32m426.7280\u001B[0m  0.0010  0.0966\n",
      "      8      \u001B[36m376.8141\u001B[0m      \u001B[32m426.7264\u001B[0m  0.0010  0.0829\n",
      "      9      \u001B[36m376.8136\u001B[0m      \u001B[32m426.7253\u001B[0m  0.0010  0.0911\n",
      "     10      \u001B[36m376.8133\u001B[0m      \u001B[32m426.7245\u001B[0m  0.0010  0.0934\n",
      "     11      \u001B[36m376.8130\u001B[0m      \u001B[32m426.7238\u001B[0m  0.0010  0.0868\n",
      "     12      \u001B[36m376.8127\u001B[0m      \u001B[32m426.7234\u001B[0m  0.0010  0.1046\n",
      "     13      \u001B[36m376.8126\u001B[0m      \u001B[32m426.7230\u001B[0m  0.0010  0.1031\n",
      "     14      \u001B[36m376.8124\u001B[0m      \u001B[32m426.7228\u001B[0m  0.0010  0.0914\n",
      "     15      376.8125      \u001B[32m426.7225\u001B[0m  0.0010  0.1202\n",
      "     16      \u001B[36m376.8122\u001B[0m      \u001B[32m426.7223\u001B[0m  0.0010  0.0955\n",
      "     17      376.8122      \u001B[32m426.7221\u001B[0m  0.0010  0.1416\n",
      "     18      376.8124      \u001B[32m426.7219\u001B[0m  0.0010  0.1305\n",
      "     19      \u001B[36m376.8121\u001B[0m      \u001B[32m426.7217\u001B[0m  0.0010  0.1317\n",
      "     20      376.8123      \u001B[32m426.7215\u001B[0m  0.0010  0.1206\n",
      "     21      \u001B[36m376.8121\u001B[0m      \u001B[32m426.7214\u001B[0m  0.0010  0.1348\n",
      "     22      \u001B[36m376.8120\u001B[0m      \u001B[32m426.7212\u001B[0m  0.0010  0.1222\n",
      "     23      376.8122      \u001B[32m426.7212\u001B[0m  0.0010  0.1118\n",
      "     24      376.8121      \u001B[32m426.7211\u001B[0m  0.0007  0.1032\n",
      "     25      376.8122      \u001B[32m426.7210\u001B[0m  0.0007  0.1035\n",
      "     26      376.8121      \u001B[32m426.7210\u001B[0m  0.0007  0.1354\n",
      "     27      376.8121      \u001B[32m426.7209\u001B[0m  0.0007  0.1197\n",
      "     28      \u001B[36m376.8120\u001B[0m      \u001B[32m426.7209\u001B[0m  0.0007  0.1025\n",
      "     29      \u001B[36m376.8119\u001B[0m      \u001B[32m426.7208\u001B[0m  0.0007  0.0974\n",
      "     30      376.8119      \u001B[32m426.7208\u001B[0m  0.0007  0.1027\n",
      "     31      376.8120      \u001B[32m426.7208\u001B[0m  0.0007  0.1003\n",
      "     32      376.8121      \u001B[32m426.7207\u001B[0m  0.0007  0.1182\n",
      "     33      376.8120      426.7207  0.0007  0.1240\n",
      "     34      \u001B[36m376.8119\u001B[0m      \u001B[32m426.7207\u001B[0m  0.0007  0.1165\n",
      "     35      376.8120      \u001B[32m426.7207\u001B[0m  0.0007  0.1438\n",
      "     36      376.8120      \u001B[32m426.7206\u001B[0m  0.0007  0.1364\n",
      "     37      \u001B[36m376.8119\u001B[0m      \u001B[32m426.7206\u001B[0m  0.0007  0.1209\n",
      "     38      376.8119      \u001B[32m426.7205\u001B[0m  0.0007  0.1078\n",
      "     39      376.8120      \u001B[32m426.7205\u001B[0m  0.0007  0.1491\n",
      "     40      376.8119      \u001B[32m426.7205\u001B[0m  0.0005  0.1356\n",
      "     41      376.8120      \u001B[32m426.7205\u001B[0m  0.0005  0.1437\n",
      "     42      376.8119      \u001B[32m426.7205\u001B[0m  0.0005  0.1223\n",
      "     43      376.8119      426.7205  0.0005  0.1279\n",
      "     44      376.8119      \u001B[32m426.7204\u001B[0m  0.0005  0.1015\n",
      "     45      376.8119      \u001B[32m426.7204\u001B[0m  0.0005  0.1051\n",
      "     46      376.8120      \u001B[32m426.7204\u001B[0m  0.0005  0.1078\n",
      "     47      376.8119      \u001B[32m426.7204\u001B[0m  0.0005  0.1034\n",
      "     48      376.8119      \u001B[32m426.7204\u001B[0m  0.0005  0.1201\n",
      "     49      376.8119      426.7204  0.0005  0.0979\n",
      "     50      376.8119      \u001B[32m426.7203\u001B[0m  0.0005  0.1285\n",
      "     51      376.8119      \u001B[32m426.7203\u001B[0m  0.0005  0.1236\n",
      "     52      376.8119      426.7203  0.0005  0.1346\n",
      "     53      376.8119      426.7203  0.0005  0.1311\n",
      "     54      \u001B[36m376.8118\u001B[0m      \u001B[32m426.7203\u001B[0m  0.0005  0.1331\n",
      "     55      \u001B[36m376.8118\u001B[0m      \u001B[32m426.7203\u001B[0m  0.0005  0.1108\n",
      "     56      376.8119      426.7203  0.0003  0.1291\n",
      "     57      376.8119      \u001B[32m426.7202\u001B[0m  0.0003  0.0969\n",
      "     58      \u001B[36m376.8118\u001B[0m      \u001B[32m426.7202\u001B[0m  0.0003  0.1032\n",
      "     59      \u001B[36m376.8118\u001B[0m      \u001B[32m426.7202\u001B[0m  0.0003  0.1121\n",
      "     60      376.8119      \u001B[32m426.7202\u001B[0m  0.0003  0.0967\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m378.6157\u001B[0m      \u001B[32m422.1464\u001B[0m  0.0010  0.0953\n",
      "      2      \u001B[36m378.4210\u001B[0m      \u001B[32m422.0000\u001B[0m  0.0010  0.0944\n",
      "      3      \u001B[36m378.3038\u001B[0m      \u001B[32m421.9331\u001B[0m  0.0010  0.0926\n",
      "      4      \u001B[36m378.2592\u001B[0m      \u001B[32m421.9054\u001B[0m  0.0010  0.1101\n",
      "      5      \u001B[36m378.2440\u001B[0m      \u001B[32m421.8948\u001B[0m  0.0010  0.1458\n",
      "      6      \u001B[36m378.2394\u001B[0m      \u001B[32m421.8901\u001B[0m  0.0010  0.1628\n",
      "      7      \u001B[36m378.2379\u001B[0m      \u001B[32m421.8874\u001B[0m  0.0010  0.1219\n",
      "      8      \u001B[36m378.2369\u001B[0m      \u001B[32m421.8857\u001B[0m  0.0010  0.1106\n",
      "      9      \u001B[36m378.2365\u001B[0m      \u001B[32m421.8845\u001B[0m  0.0010  0.1043\n",
      "     10      \u001B[36m378.2356\u001B[0m      \u001B[32m421.8838\u001B[0m  0.0010  0.1098\n",
      "     11      \u001B[36m378.2356\u001B[0m      \u001B[32m421.8832\u001B[0m  0.0010  0.1101\n",
      "     12      \u001B[36m378.2353\u001B[0m      \u001B[32m421.8828\u001B[0m  0.0010  0.1020\n",
      "     13      \u001B[36m378.2352\u001B[0m      \u001B[32m421.8825\u001B[0m  0.0010  0.1222\n",
      "     14      \u001B[36m378.2350\u001B[0m      \u001B[32m421.8822\u001B[0m  0.0010  0.1023\n",
      "     15      378.2351      \u001B[32m421.8819\u001B[0m  0.0010  0.1493\n",
      "     16      \u001B[36m378.2348\u001B[0m      \u001B[32m421.8817\u001B[0m  0.0010  0.1175\n",
      "     17      378.2349      \u001B[32m421.8814\u001B[0m  0.0010  0.1165\n",
      "     18      \u001B[36m378.2347\u001B[0m      \u001B[32m421.8812\u001B[0m  0.0010  0.1064\n",
      "     19      \u001B[36m378.2346\u001B[0m      \u001B[32m421.8810\u001B[0m  0.0010  0.1160\n",
      "     20      \u001B[36m378.2346\u001B[0m      \u001B[32m421.8809\u001B[0m  0.0010  0.1076\n",
      "     21      378.2346      \u001B[32m421.8807\u001B[0m  0.0010  0.1067\n",
      "     22      \u001B[36m378.2344\u001B[0m      \u001B[32m421.8806\u001B[0m  0.0010  0.1062\n",
      "     23      378.2345      \u001B[32m421.8805\u001B[0m  0.0007  0.0899\n",
      "     24      378.2345      \u001B[32m421.8805\u001B[0m  0.0007  0.1247\n",
      "     25      378.2346      \u001B[32m421.8804\u001B[0m  0.0007  0.1160\n",
      "     26      \u001B[36m378.2344\u001B[0m      \u001B[32m421.8803\u001B[0m  0.0007  0.1122\n",
      "     27      \u001B[36m378.2344\u001B[0m      \u001B[32m421.8803\u001B[0m  0.0007  0.0992\n",
      "     28      \u001B[36m378.2343\u001B[0m      \u001B[32m421.8802\u001B[0m  0.0007  0.0860\n",
      "     29      378.2345      \u001B[32m421.8802\u001B[0m  0.0007  0.1206\n",
      "     30      378.2344      \u001B[32m421.8801\u001B[0m  0.0007  0.1121\n",
      "     31      378.2345      \u001B[32m421.8800\u001B[0m  0.0007  0.1054\n",
      "     32      378.2343      \u001B[32m421.8800\u001B[0m  0.0007  0.1055\n",
      "     33      378.2343      \u001B[32m421.8799\u001B[0m  0.0007  0.1035\n",
      "     34      378.2343      \u001B[32m421.8799\u001B[0m  0.0007  0.1158\n",
      "     35      378.2343      \u001B[32m421.8798\u001B[0m  0.0007  0.1014\n",
      "     36      378.2344      \u001B[32m421.8798\u001B[0m  0.0007  0.1077\n",
      "     37      378.2343      \u001B[32m421.8798\u001B[0m  0.0007  0.1040\n",
      "     38      \u001B[36m378.2343\u001B[0m      \u001B[32m421.8797\u001B[0m  0.0007  0.1037\n",
      "     39      378.2343      \u001B[32m421.8797\u001B[0m  0.0005  0.1173\n",
      "     40      378.2345      \u001B[32m421.8797\u001B[0m  0.0005  0.1127\n",
      "     41      378.2344      \u001B[32m421.8797\u001B[0m  0.0005  0.1113\n",
      "     42      378.2343      \u001B[32m421.8797\u001B[0m  0.0005  0.1041\n",
      "     43      378.2343      \u001B[32m421.8796\u001B[0m  0.0005  0.1009\n",
      "     44      \u001B[36m378.2342\u001B[0m      421.8796  0.0005  0.1073\n",
      "     45      378.2343      \u001B[32m421.8796\u001B[0m  0.0005  0.0951\n",
      "     46      378.2343      \u001B[32m421.8795\u001B[0m  0.0005  0.1002\n",
      "     47      378.2343      421.8795  0.0005  0.0933\n",
      "     48      378.2343      \u001B[32m421.8795\u001B[0m  0.0005  0.0968\n",
      "     49      378.2342      \u001B[32m421.8795\u001B[0m  0.0005  0.1131\n",
      "     50      378.2342      421.8795  0.0005  0.0964\n",
      "     51      \u001B[36m378.2342\u001B[0m      \u001B[32m421.8795\u001B[0m  0.0005  0.0998\n",
      "     52      378.2342      \u001B[32m421.8794\u001B[0m  0.0005  0.1144\n",
      "     53      378.2343      \u001B[32m421.8794\u001B[0m  0.0005  0.1012\n",
      "     54      378.2343      \u001B[32m421.8794\u001B[0m  0.0005  0.1479\n",
      "     55      378.2343      \u001B[32m421.8794\u001B[0m  0.0003  0.1067\n",
      "     56      378.2342      421.8794  0.0003  0.1170\n",
      "     57      \u001B[36m378.2342\u001B[0m      421.8794  0.0003  0.1226\n",
      "     58      378.2342      \u001B[32m421.8794\u001B[0m  0.0003  0.1204\n",
      "     59      378.2343      \u001B[32m421.8794\u001B[0m  0.0003  0.1038\n",
      "     60      378.2343      \u001B[32m421.8794\u001B[0m  0.0003  0.1051\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m378.7874\u001B[0m      \u001B[32m442.3918\u001B[0m  0.0010  0.1049\n",
      "      2      \u001B[36m378.5984\u001B[0m      \u001B[32m442.2400\u001B[0m  0.0010  0.1026\n",
      "      3      \u001B[36m378.4787\u001B[0m      \u001B[32m442.1712\u001B[0m  0.0010  0.1086\n",
      "      4      \u001B[36m378.4278\u001B[0m      \u001B[32m442.1450\u001B[0m  0.0010  0.1060\n",
      "      5      \u001B[36m378.4173\u001B[0m      \u001B[32m442.1349\u001B[0m  0.0010  0.1152\n",
      "      6      \u001B[36m378.4125\u001B[0m      \u001B[32m442.1303\u001B[0m  0.0010  0.0897\n",
      "      7      \u001B[36m378.4118\u001B[0m      \u001B[32m442.1276\u001B[0m  0.0010  0.0928\n",
      "      8      \u001B[36m378.4105\u001B[0m      \u001B[32m442.1259\u001B[0m  0.0010  0.1010\n",
      "      9      378.4106      \u001B[32m442.1246\u001B[0m  0.0010  0.0960\n",
      "     10      \u001B[36m378.4104\u001B[0m      \u001B[32m442.1235\u001B[0m  0.0010  0.0828\n",
      "     11      \u001B[36m378.4097\u001B[0m      \u001B[32m442.1229\u001B[0m  0.0010  0.0934\n",
      "     12      \u001B[36m378.4095\u001B[0m      \u001B[32m442.1224\u001B[0m  0.0010  0.0896\n",
      "     13      \u001B[36m378.4094\u001B[0m      \u001B[32m442.1219\u001B[0m  0.0010  0.0842\n",
      "     14      \u001B[36m378.4094\u001B[0m      \u001B[32m442.1214\u001B[0m  0.0010  0.0972\n",
      "     15      \u001B[36m378.4091\u001B[0m      \u001B[32m442.1210\u001B[0m  0.0010  0.0992\n",
      "     16      \u001B[36m378.4088\u001B[0m      \u001B[32m442.1207\u001B[0m  0.0010  0.0951\n",
      "     17      378.4089      \u001B[32m442.1204\u001B[0m  0.0010  0.0864\n",
      "     18      378.4090      \u001B[32m442.1202\u001B[0m  0.0010  0.0867\n",
      "     19      \u001B[36m378.4088\u001B[0m      \u001B[32m442.1201\u001B[0m  0.0010  0.0989\n",
      "     20      378.4088      \u001B[32m442.1198\u001B[0m  0.0010  0.0901\n",
      "     21      \u001B[36m378.4087\u001B[0m      \u001B[32m442.1196\u001B[0m  0.0010  0.1005\n",
      "     22      \u001B[36m378.4086\u001B[0m      \u001B[32m442.1195\u001B[0m  0.0010  0.0982\n",
      "     23      378.4087      \u001B[32m442.1193\u001B[0m  0.0010  0.0931\n",
      "     24      \u001B[36m378.4085\u001B[0m      \u001B[32m442.1192\u001B[0m  0.0010  0.0883\n",
      "     25      \u001B[36m378.4085\u001B[0m      \u001B[32m442.1192\u001B[0m  0.0007  0.1095\n",
      "     26      378.4085      \u001B[32m442.1191\u001B[0m  0.0007  0.0995\n",
      "     27      \u001B[36m378.4084\u001B[0m      \u001B[32m442.1191\u001B[0m  0.0007  0.1011\n",
      "     28      378.4085      \u001B[32m442.1190\u001B[0m  0.0007  0.0940\n",
      "     29      \u001B[36m378.4084\u001B[0m      \u001B[32m442.1189\u001B[0m  0.0007  0.0942\n",
      "     30      378.4084      \u001B[32m442.1189\u001B[0m  0.0007  0.1234\n",
      "     31      378.4085      \u001B[32m442.1189\u001B[0m  0.0007  0.0952\n",
      "     32      378.4085      \u001B[32m442.1188\u001B[0m  0.0007  0.1141\n",
      "     33      378.4085      \u001B[32m442.1187\u001B[0m  0.0007  0.1167\n",
      "     34      378.4084      \u001B[32m442.1187\u001B[0m  0.0007  0.1062\n",
      "     35      378.4085      \u001B[32m442.1186\u001B[0m  0.0007  0.1483\n",
      "     36      378.4085      \u001B[32m442.1186\u001B[0m  0.0007  0.1199\n",
      "     37      \u001B[36m378.4084\u001B[0m      \u001B[32m442.1185\u001B[0m  0.0007  0.1221\n",
      "     38      378.4084      \u001B[32m442.1185\u001B[0m  0.0007  0.1132\n",
      "     39      \u001B[36m378.4084\u001B[0m      \u001B[32m442.1185\u001B[0m  0.0007  0.1213\n",
      "     40      378.4084      \u001B[32m442.1184\u001B[0m  0.0007  0.1028\n",
      "     41      378.4084      \u001B[32m442.1184\u001B[0m  0.0005  0.1120\n",
      "     42      378.4084      \u001B[32m442.1183\u001B[0m  0.0005  0.1040\n",
      "     43      378.4085      \u001B[32m442.1183\u001B[0m  0.0005  0.1231\n",
      "     44      378.4084      \u001B[32m442.1183\u001B[0m  0.0005  0.1278\n",
      "     45      378.4084      \u001B[32m442.1182\u001B[0m  0.0005  0.1056\n",
      "     46      \u001B[36m378.4084\u001B[0m      \u001B[32m442.1182\u001B[0m  0.0005  0.1235\n",
      "     47      378.4084      \u001B[32m442.1182\u001B[0m  0.0005  0.1082\n",
      "     48      \u001B[36m378.4084\u001B[0m      \u001B[32m442.1182\u001B[0m  0.0005  0.1237\n",
      "     49      378.4084      \u001B[32m442.1181\u001B[0m  0.0005  0.1042\n",
      "     50      378.4084      \u001B[32m442.1181\u001B[0m  0.0005  0.1057\n",
      "     51      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1181\u001B[0m  0.0005  0.1093\n",
      "     52      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1181\u001B[0m  0.0005  0.1012\n",
      "     53      378.4083      \u001B[32m442.1180\u001B[0m  0.0005  0.1236\n",
      "     54      378.4084      \u001B[32m442.1180\u001B[0m  0.0005  0.1098\n",
      "     55      378.4083      \u001B[32m442.1179\u001B[0m  0.0005  0.1088\n",
      "     56      378.4084      442.1180  0.0005  0.0981\n",
      "     57      378.4083      442.1180  0.0003  0.0992\n",
      "     58      \u001B[36m378.4083\u001B[0m      \u001B[32m442.1179\u001B[0m  0.0003  0.1076\n",
      "     59      378.4083      \u001B[32m442.1179\u001B[0m  0.0003  0.1030\n",
      "     60      378.4083      \u001B[32m442.1179\u001B[0m  0.0003  0.1061\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001B[36m379.7371\u001B[0m      \u001B[32m430.5806\u001B[0m  0.0010  0.0897\n",
      "      2      \u001B[36m379.5637\u001B[0m      \u001B[32m430.4317\u001B[0m  0.0010  0.0900\n",
      "      3      \u001B[36m379.4401\u001B[0m      \u001B[32m430.3461\u001B[0m  0.0010  0.1008\n",
      "      4      \u001B[36m379.3690\u001B[0m      \u001B[32m430.3015\u001B[0m  0.0010  0.0965\n",
      "      5      \u001B[36m379.3452\u001B[0m      \u001B[32m430.2814\u001B[0m  0.0010  0.1128\n",
      "      6      \u001B[36m379.3377\u001B[0m      \u001B[32m430.2722\u001B[0m  0.0010  0.1195\n",
      "      7      \u001B[36m379.3329\u001B[0m      \u001B[32m430.2676\u001B[0m  0.0010  0.1208\n",
      "      8      \u001B[36m379.3320\u001B[0m      \u001B[32m430.2649\u001B[0m  0.0010  0.1202\n",
      "      9      \u001B[36m379.3313\u001B[0m      \u001B[32m430.2626\u001B[0m  0.0010  0.0975\n",
      "     10      \u001B[36m379.3298\u001B[0m      \u001B[32m430.2612\u001B[0m  0.0010  0.1189\n",
      "     11      \u001B[36m379.3289\u001B[0m      \u001B[32m430.2603\u001B[0m  0.0010  0.1032\n",
      "     12      379.3289      \u001B[32m430.2596\u001B[0m  0.0010  0.1404\n",
      "     13      \u001B[36m379.3286\u001B[0m      \u001B[32m430.2589\u001B[0m  0.0010  0.1235\n",
      "     14      379.3291      \u001B[32m430.2583\u001B[0m  0.0010  0.1085\n",
      "     15      379.3291      \u001B[32m430.2576\u001B[0m  0.0010  0.1107\n",
      "     16      \u001B[36m379.3286\u001B[0m      \u001B[32m430.2571\u001B[0m  0.0010  0.1021\n",
      "     17      \u001B[36m379.3281\u001B[0m      \u001B[32m430.2567\u001B[0m  0.0010  0.1092\n",
      "     18      \u001B[36m379.3280\u001B[0m      \u001B[32m430.2565\u001B[0m  0.0010  0.0988\n",
      "     19      \u001B[36m379.3277\u001B[0m      \u001B[32m430.2562\u001B[0m  0.0010  0.1158\n",
      "     20      379.3278      \u001B[32m430.2560\u001B[0m  0.0010  0.0985\n",
      "     21      \u001B[36m379.3277\u001B[0m      \u001B[32m430.2559\u001B[0m  0.0010  0.0996\n",
      "     22      379.3278      \u001B[32m430.2557\u001B[0m  0.0010  0.1042\n",
      "     23      \u001B[36m379.3277\u001B[0m      \u001B[32m430.2555\u001B[0m  0.0010  0.0955\n",
      "     24      379.3278      \u001B[32m430.2555\u001B[0m  0.0010  0.1015\n",
      "     25      \u001B[36m379.3275\u001B[0m      \u001B[32m430.2554\u001B[0m  0.0010  0.1030\n",
      "     26      379.3276      \u001B[32m430.2551\u001B[0m  0.0010  0.0920\n",
      "     27      379.3277      \u001B[32m430.2549\u001B[0m  0.0010  0.1097\n",
      "     28      379.3275      \u001B[32m430.2548\u001B[0m  0.0010  0.0950\n",
      "     29      \u001B[36m379.3274\u001B[0m      \u001B[32m430.2547\u001B[0m  0.0010  0.0894\n",
      "     30      379.3278      \u001B[32m430.2545\u001B[0m  0.0010  0.1019\n",
      "     31      379.3275      \u001B[32m430.2544\u001B[0m  0.0007  0.1605\n",
      "     32      379.3275      \u001B[32m430.2544\u001B[0m  0.0007  0.2602\n"
     ]
    }
   ],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "\n",
    "# GRID SEARCH\n",
    "net = NeuralNetRegressor(\n",
    "    module=MiRNANet_3,\n",
    "    module__input_dim=X_train_mlp.shape[1],\n",
    "    module__output_dim=y_train_mlp.shape[1],\n",
    "    max_epochs=60,\n",
    "    lr=1e-3,\n",
    "    batch_size=32,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer__weight_decay=1e-5,\n",
    "    optimizer__lr=0.001,\n",
    "    criterion=nn.L1Loss(),\n",
    "    callbacks=[\n",
    "         ('lr_scheduler', LRScheduler(\n",
    "             ReduceLROnPlateau, \n",
    "             mode='min', \n",
    "             factor=0.7, \n",
    "             patience=15, \n",
    "             monitor='valid_loss',\n",
    "             min_lr=1e-6\n",
    "         ))\n",
    "    ],\n",
    ")\n",
    "\n",
    "params = {\n",
    "    #'module__hidden1': [128, 256, 512],\n",
    "    #'module__hidden2': [64, 128, 256],\n",
    "    'module__dropout': [0.2, 0.3, 0.5],\n",
    "    'module__start_lr': [1e-3, 1e-4],\n",
    "    #'module__lr_decay': [0.3, 0.4],\n",
    "    #'optimizer__weight_decay': [0, 1e-5, 1e-4],\n",
    "    #'callbacks__lr_scheduler__factor': [0.8, 0.6, 0.4],\n",
    "    #'callbacks__lr_scheduler__patience': [15, 10, 5],\n",
    "    'lr': [1e-1, 5e-4]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, \n",
    "                  params, \n",
    "                  refit=True, \n",
    "                  cv=kfold,  # cross-validation folds \n",
    "                  scoring='neg_mean_squared_error', \n",
    "                  verbose=1)\n",
    "gs.fit(X_train_mlp, y_train_mlp)\n",
    "\n",
    "best_model = gs.best_estimator_\n",
    "print(\"Best hyperparameters:\", gs.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-10-28T11:29:11.785454Z"
    }
   },
   "id": "ea55aba1dd1cda48",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preds = best_model.predict(X_test_mlp)\n",
    "mae = mean_absolute_error(y_test_mlp, preds)\n",
    "r2 = r2_score(y_test_mlp, preds)\n",
    "print(f\"Test MAE: {mae:.2f} | R2: {r2:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aac7398b06d69f23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elastic net (Lasso-Cox)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbbfc3aa"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "86272243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(coefs, n_highlight):\n",
    "    _, ax = plt.subplots(figsize=(9, 6))\n",
    "    alphas = coefs.columns\n",
    "    for row in coefs.itertuples():\n",
    "        ax.semilogx(alphas, row[1:], \".-\", label=row.Index)\n",
    "\n",
    "    alpha_min = alphas.min()\n",
    "    top_coefs = coefs.loc[:, alpha_min].map(abs).sort_values().tail(n_highlight)\n",
    "    for name in top_coefs.index:\n",
    "        coef = coefs.loc[name, alpha_min]\n",
    "        plt.text(alpha_min, coef, name + \"   \", horizontalalignment=\"right\", verticalalignment=\"center\")\n",
    "\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel(\"alpha\")\n",
    "    ax.set_ylabel(\"coefficient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0667f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-02 1.62377674e-02 2.63665090e-02 4.28133240e-02\n",
      " 6.95192796e-02 1.12883789e-01 1.83298071e-01 2.97635144e-01\n",
      " 4.83293024e-01 7.84759970e-01 1.27427499e+00 2.06913808e+00\n",
      " 3.35981829e+00 5.45559478e+00 8.85866790e+00 1.43844989e+01\n",
      " 2.33572147e+01 3.79269019e+01 6.15848211e+01 1.00000000e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:200: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n",
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:200: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n",
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 0.016237767391887217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:200: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n",
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 0.026366508987303583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:200: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n",
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 0.04281332398719394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:200: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n",
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 0.06951927961775606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:200: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n",
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 0.11288378916846889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n",
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:200: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 0.18329807108324356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n",
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:200: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 0.29763514416313175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n",
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:200: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 0.4832930238571752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 0.7847599703514611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 1.2742749857031335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matteo Bulgarelli\\anaconda3\\envs\\tirocinio-venv\\Lib\\site-packages\\sksurv\\linear_model\\coxph.py:197: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting for alpha coefficient : 2.06913808111479\n",
      "Finished fitting for alpha coefficient : 3.359818286283781\n",
      "Finished fitting for alpha coefficient : 5.455594781168514\n",
      "Finished fitting for alpha coefficient : 8.858667904100823\n",
      "Finished fitting for alpha coefficient : 14.38449888287663\n",
      "Finished fitting for alpha coefficient : 23.357214690901213\n",
      "Finished fitting for alpha coefficient : 37.92690190732246\n",
      "Finished fitting for alpha coefficient : 61.584821106602604\n",
      "Finished fitting for alpha coefficient : 100.0\n"
     ]
    }
   ],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "alphas = 10.0 ** np.linspace(-2, 2, 20)\n",
    "coefficients = {}\n",
    "\n",
    "print(alphas)\n",
    "\n",
    "cph = CoxPHSurvivalAnalysis()\n",
    "for alpha in alphas:\n",
    "    cph.set_params(alpha=alpha)\n",
    "    cph.fit(X_train, y_train)\n",
    "    key = round(alpha, 5)\n",
    "    coefficients[key] = cph.coef_\n",
    "    print(f\"Finished fitting for alpha coefficient : {alpha}\")\n",
    "\n",
    "coefficients = pd.DataFrame.from_dict(coefficients).rename_axis(index=\"feature\", columns=\"alpha\").set_index(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a853d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients.to_csv(os.path.join(DATA_PATH, 'Cox_coefficients.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af6fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "gcv = GridSearchCV(\n",
    "    make_pipeline(StandardScaler(), CoxnetSurvivalAnalysis(l1_ratio=0.9)),\n",
    "    param_grid={\"coxnetsurvivalanalysis__alphas\": [[v] for v in map(float, estimated_alphas)]},\n",
    "    cv=cv,\n",
    "    error_score=0.5,\n",
    "    n_jobs=1,\n",
    ").fit(Xt, y)\n",
    "\n",
    "cv_results = pd.DataFrame(gcv.cv_results_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tirocinio-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
